<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[pytorch-module-and-function]]></title>
    <url>%2F2018%2F10%2F17%2Fpytorch-module-and-function%2F</url>
    <content type="text"><![CDATA[How to custom module, e.g., linear123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import mathimport torchimport torch.nn.init as initfrom torch.autograd import Variablefrom torch.nn.parameter import Parameterclass _Linear(torch.autograd.Function): def __init__(self): super(_Linear, self).__init__() # bias is an optional argument def forward(self, input, weight, bias=None): self.save_for_backward(input, weight, bias) output = input.mm(weight.t()) if bias is not None: output += bias.unsqueeze(0).expand_as(output) return output def backward(self, grad_output): input, weight, bias = self.saved_tensors grad_input = grad_weight = grad_bias = None print("backwarding......") if self.needs_input_grad[0]: grad_input = grad_output.mm(weight) if self.needs_input_grad[1]: grad_weight = grad_output.t().mm(input) if bias is not None and self.needs_input_grad[2]: grad_bias = grad_output.sum(0).squeeze(0) return grad_input, grad_weight, grad_biasclass Linear(torch.nn.Module): def __init__(self, in_features, out_features, bias=True): super(Linear, self).__init__() self.in_features = in_features self.out_features = out_features # init trainable parameters. self.weight = Parameter(torch.Tensor(out_features, in_features)) if bias: self.bias = Parameter(torch.Tensor(out_features)) else: self.register_parameter('bias', None) # reset parameters. self.reset_parameters() def reset_parameters(self): init.kaiming_uniform_(self.weight, a=math.sqrt(5)) if self.bias is not None: fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight) bound = 1 / math.sqrt(fan_in) init.uniform_(self.bias, -bound, bound) def forward(self, input): if self.bias is None: return _Linear()(input, self.weight) else: return _Linear()(input, self.weight, self.bias) How the hook works?We understand how the hook works by running the following script:12345678910111213141516def module_hook(module, grad_input, grad_out): print('module hook') print('grad_out', grad_out)def variable_hook(grad): print('variable hook') print('grad', grad) return grad*.1input = Variable(torch.randn(1, 10), requires_grad=True)linear = Linear(10, 1, bias=False)linear.register_backward_hook(module_hook)output = linear(input)output.register_hook(variable_hook)output.backward() And the output of code above is:1234567variable hookgrad tensor([[1.]])backwarding......module hookgrad_out (tensor([[0.1000]]),),) The two types of hook are all registered at Function object, at backward stage, the calling order ishook registered by variable -&gt; function.backward(..) -&gt; hook registered by module -&gt; update varaible&#39;s grad.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A collection of working tools for mac]]></title>
    <url>%2F2018%2F09%2F01%2Fworking-on-mac%2F</url>
    <content type="text"><![CDATA[Some reference materials could be macOS setup guide, donnemartin/dev-setup and 强迫症的 Mac 设置指南. SoftwaresEverything: Afred Packal Workflows List Alfred-workflows A public Collection of Alfred Workflows Alfred-Workflows Some good workflows Alfred Workflow for Google Apps GitHub Workflow for Alfred 3 Process killer zhihu use atom to open files and folders ZotHero CodeVar 生成可用的代码变量 Editor: AtomTerminalWeb terminal: butterflysshfsmount network file system locally emacsvimtmux使用vim+tmux+zsh+autojump提升效率 VimiumUse keyboard to view chrome coding assistantZotero Zotero 管理文献最佳实践：（1）安装与设置 文献管理软件Zotero基础及进阶示范]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Back prop in PyTorch]]></title>
    <url>%2F2017%2F11%2F08%2Fback-prop-in-pytorch%2F</url>
    <content type="text"><![CDATA[. Some basicsAll optimizers implement a step() method, that updates the parameters. It can be used in two ways: optimizer.step(): The function can be called once the gradients are computed using e.g., backward(). 123456for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() optimizer.step(closure): Some optimization algorithms such as Conjugate Gradient and LBFGS need to reevaluate the function multiple times, so you have to pass in a closure that allows them to recompute your model. The closure should clear the gradients, compute the loss, and return it. 12345678for input, target in dataset: def closure(): optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() return loss optimizer.step(closure) What if we do not zero_grad()?We would like to first try the following attempts:123456output = model(data)loss = F.nll_loss(output, target)optimizer.zero_grad(retain_graph=True)loss.backward()print(list(model.parameters())[0].grad.data) V.S.1234567output = model(data)loss = F.nll_loss(output, target)loss.backward()print(list(model.parameters())[0].grad.data)optimizer.zero_grad()print(list(model.parameters())[0].grad.data) It will have the following error: RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time. It means that To reduce memory usage, during the .backward() call, all the intermediary results are deleted when they are not needed anymore. Hence if you try to call .backward() again, the intermediary results don’t exist and the backward pass cannot be performed (and you get the error you see).You can call .backward(retain_graph=True) to make a backward pass that will not delete intermediary results, and so you will be able to call .backward() again. All but the last call to backward should have the retain_graph=True option. Correct this error, we have the following outputs:123456789101112131415161718192021222324252627282.6675e-01 1.6989e+00 9.0318e-01 ... 1.0405e-01 3.1734e-01 1.9003e+00-1.5445e+00 8.8113e-01 1.3725e+00 ... 2.6960e-01 -2.6543e+00 -2.6381e+00-1.9797e+00 -8.5339e-01 1.4450e+00 ... 3.0385e+00 -4.6786e+00 -1.8889e+00 ... ⋱ ... 2.3236e-01 -5.0679e-03 -1.5525e+00 ... -2.1716e+00 1.1428e+00 -7.1045e-01-1.4500e+00 -8.4586e-01 8.4389e-01 ... -3.1546e-01 -1.1160e+00 -1.8695e+009.9668e-01 -1.7926e+00 -8.9462e-01 ... -2.8506e-01 8.2031e-01 -3.4813e-01[torch.FloatTensor of size 100x1000]5.3350e-01 3.3978e+00 1.8064e+00 ... 2.0809e-01 6.3468e-01 3.8006e+00-3.0890e+00 1.7623e+00 2.7449e+00 ... 5.3920e-01 -5.3087e+00 -5.2763e+00-3.9594e+00 -1.7068e+00 2.8900e+00 ... 6.0771e+00 -9.3571e+00 -3.7778e+00 ... ⋱ ... 4.6472e-01 -1.0136e-02 -3.1050e+00 ... -4.3432e+00 2.2856e+00 -1.4209e+00-2.9000e+00 -1.6917e+00 1.6878e+00 ... -6.3091e-01 -2.2321e+00 -3.7391e+001.9934e+00 -3.5852e+00 -1.7892e+00 ... -5.7012e-01 1.6406e+00 -6.9627e-01[torch.FloatTensor of size 100x1000] 0 0 0 ... 0 0 0 0 0 0 ... 0 0 0 0 0 0 ... 0 0 0 ... ⋱ ... 0 0 0 ... 0 0 0 0 0 0 ... 0 0 0 0 0 0 ... 0 0 0[torch.FloatTensor of size 100x1000] We can witness that if we do not zero the gradient, the gradient will be stored in *.grad.data.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Difference between DataParallel and DistributedDataParallel]]></title>
    <url>%2F2017%2F11%2F07%2Fdifference-between-dataparallel-and-distributeddataparallel%2F</url>
    <content type="text"><![CDATA[. Data ParallelImplements data parallelism at the module level. This container parallelizes the application of the given module by splitting the input across the specified devices by chunking in the batch dimension. In the forward pass, the module is replicated on each device, and each replica handles a portion of the input. During the backwards pass, gradients from each replica are summed into the original module. The batch size should be larger than the number of GPUs used. It should also be an integer multiple of the number of GPUs so that each chunk is the same size (so that each GPU processes the same number of samples). Distributed Data ParallelImplements distributed data parallelism at the module level. This container parallelizes the application of the given module by splitting the input across the specified devices by chunking in the batch dimension. The module is replicated on each machine and each device, and each such replica handles a portion of the input. During the backwards pass, gradients from each node are averaged. The batch size should be larger than the number of GPUs used locally. It should also be an integer multiple of the number of GPUs so that each chunk is the same size (so that each GPU processes the same number of samples).]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A list of ICLR 2018 submission that related to my research]]></title>
    <url>%2F2017%2F10%2F29%2Ficlr-submission-2018-related-to-my-research%2F</url>
    <content type="text"><![CDATA[. Large Scale Training Don’t Decay the Learning Rate, Increase the Batch Size Large Batch Training of Convolutional Networks with Layer-Wise Adaptive Rate Scaling Quantization The High-Dimensional Geometry of Binary Neural Networks Variational Network Quantization Training Wide Residual Networks for Deployment using a Single Bit for Each Weight Espresso: Efficient Forward Propagation for Binary Deep Neural Networks Adaptive Quantization of Neural Networks Towards Binary-Valued Gates for Robust LSTM Training Alternating Multi-Bit Quantization for Recurrent Neural Networks Model Compression via Distillation and Quantization Recursive Binary Neural Network Learning Model with 2-Bit/Weight Storage Requirement Loss-Aware Weight Quantization of Deep Networks Heterogeneous Bitwidth Binarization in Convolutional Neural Networks BinaryFlex: On-the-Fly Kernel Generation in Binary Convolutional Networks DNN Model Compression Under Accuracy Constraints]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Address NVIDIA NVML Driver Library Version Mismatch]]></title>
    <url>%2F2017%2F10%2F25%2Faddress-NVIDIA-NVML-Driver-Library-Version-Mismatch%2F</url>
    <content type="text"><![CDATA[When I run nvidia-smi I get the following message:1Failed to initialize NVML: Driver/library version mismatch This blog borrowed the knowledge from Stackoverflow. The error message NVML: Driver/library version mismatch tell us the Nvidia driver kernel module (kmod) have a wrong version, so we should unload this driver, and then load the correct version of kmod. How to do that?First, we should know which drivers are loaded.1lsmod | grep nvidia I got:1234567lin@iccluster029:/mlodata_container$ lsmod | grep nvidianvidia_uvm 647168 0nvidia_drm 53248 0nvidia_modeset 790528 1 nvidia_drmnvidia 12312576 2 nvidia_modeset,nvidia_uvmdrm_kms_helper 155648 1 nvidia_drmdrm 364544 3 drm_kms_helper,nvidia_drm Our final goal is to unload nvidia mod, so we should unload the module depend on nvidia:123sudo rmmod nvidia_drmsudo rmmod nvidia_modesetsudo rmmod nvidia_uvm then, unload nvidia:1sudo rmmod nvidia TroubleshootingIf you get an error like rmmod: ERROR: Module nvidia is in use, which indicates that the kernel module is in use, you should kill the process that using the kmod:1sudo lsof /dev/nvidia* and then kill those process, then continue to unload the kmods. TestConfirm you successfully unload those kmods:1lsmod | grep nvidia and you shold get nothing. Then, confirm you can load the correct driver by:1nvidia-smi you should get the correct output.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Control users and the corresponding groups]]></title>
    <url>%2F2017%2F10%2F16%2Fadd-users-and-groups%2F</url>
    <content type="text"><![CDATA[. Usage overviewSimply create a user with password. 12345# add user informationuseradd --shell /bin/zsh --create-home $&#123;USER_NAME&#125;# set passwordecho &quot;$&#123;USER_NAME&#125;:$&#123;USER_NAME&#125;&quot; | chpasswdusermod -aG sudo,adm $&#123;USER_NAME&#125; Add userHow to Add a New User in LinuxUse useradd or adduser with username to add/create a new user. Only one user can be added and that username must be unique. For example, to add a new user lin, use the following command:1$ sudo useradd lin When we add a new user in Linux with useradd command it gets created in locked state and to unlock that user account, we need to set a password for that account with passwd command.12345$ # passwd linChanging password for user lin.New UNIX password:Retype new UNIX password:passwd: all authentication tokens updated successfully. Once a new user created, it’s entry automatically added to the /etc/passwd file. The file is used to store users information and the entry should be.1lin:x:504:504:lin:/home/lin:/bin/bash The above entry contains a set of seven colon-separated fields, each field has it’s own meaning: Username Password User ID (UID) Group ID (GID) User Info Home Directory Shell Create a User with Different Home DirectoryBy default useradd command creates a user’s home directory under /home directory with username. However, this action can be changed by using ‘-d’ option along with the location of new home directory:1$ useradd -d /data lin Create a User with Specific User ID1$ useradd -u 666 lin Let’s verify that the user created with a defined userid (999) using following command.1$ cat /etc/passwd | grep lin Create a User with Specific Group IDIn the following example, we will add a user lin with a specific UID and GID simultaneously with the help of -u and -g options.1$ useradd -u 1000 -g 500 lin Add a User to Multiple GroupsThe -G option is used to add a user to additional groups. Each group name is separated by a comma, with no intervening spaces.1$ useradd -G admins,webadmin,developers lin Next, verify that the multiple groups assigned to the user with id command.1$ id lin Add a User without Home DirectoryTo create user’s without their home directories, -M is used. Perhaps for security reasons.1$ useradd -M lin Create a User with Account Expiry DateBy default, when we add user’s with ‘useradd’ command user account never get expires, i.e., their expiry date is set to 0 (means never expired). However, we can set the expiry date using ‘-e’ option, that sets date in YYYY-MM-DD format. This is helpful for creating temporary accounts for a specific period of time.1$ useradd -e 2014-03-27 lin Let’s verify the age of account and password with chage command for user aparna after setting account expiry date.1$ chage -l lin Create a User with Password Expiry DateThe -f argument is used to define the number of days after a password expires. A value of 0 inactive the user account as soon as the password has expired. By default, the password expiry value set to -1 means never expire.1$ useradd -e 2014-04-27 -f 45 lin Add a User with Custom CommentsThe -c option allows you to add custom comments, such as user’s full name, phone number, etc to /etc/passwd file. The comment can be added as a single line without any spaces. 1useradd -c "test" lin Change User Login Shell1useradd -s /sbin/nologin lin Add a User with Specific Home Directory, Default Shell and Custom Comment1useradd -m -d /var/www/ravi -s /bin/bash -c "test" -U lin where -m -d option creates a user with specified home directory, -s option set the user’s default shell, -c option adds the extra information, -U argument create/adds a group with the same name as the user. Add a User with Home Directory, Custom Shell, Custom Comment and UID/GID1useradd -m -d /var/www/tarunika -s /bin/zsh -c "TecMint Technical Writer" -u 1000 -g 1000 lin Add a User without Home Directory, No Shell, No Group and Custom Comment1useradd -M -N -r -s /bin/false -c "Disabled TecMint Member" lin Add groupAdd a New GroupTo add a new group, all you need to do is use the groupadd command like so:1groupadd &lt;groupname&gt; Create new group with a specific groupID1groupadd &lt;groupName&gt; -g &lt;groupID&gt; Check if group exists in /etc/group file1egrep -i "^groupname" /etc/group or1groups Add an Existing User to a GroupNext we’ll add a user to the group, using this syntax:1usermod -a -G &lt;groupname&gt; username Assign the permission of a specific User to a directory.1sudo chown -Rv &lt;user&gt; &lt;dir&gt; Change group ownership of everything inside the directory1chgrp -R &lt;group name&gt; &lt;folder&gt; Change a User’s Primary GroupSometimes you might want to switch out the primary group that a user is assigned to, which you can do with this command:1usermod -g &lt;groupname&gt; username Add a New User and Assign a Group in One CommandSometimes you might need to add a new user that has access to a particular resource or directory, like adding a new FTP user. You can do so with the useradd command:1useradd -g &lt;groupname&gt; username]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to add a gif file to my latex file]]></title>
    <url>%2F2017%2F10%2F12%2Fhow-to-add-a-gif-file-to-my-latex-file%2F</url>
    <content type="text"><![CDATA[From Stackoverflow Use movie15 package. For example: 1234% in preamble\usepackage&#123;movie15&#125;% in documenet\includemovie&#123;1cm&#125;&#123;1cm&#125;&#123;ani.gif&#125; PDFLaTeX is needed, and you must use Adobe Reader with certain media player plug-in. Thus it often fails. Another method is to use animate package. You have to convert the animated gif to separate images first, using ImageMagick: 1convert foo.gif foo.png This would sometimes create a suboptimal result; if the GIF is optimized try 1convert foo.gif -coalesce foo.png You may probably get foo-0.png, foo-1.png, …, foo-18.png. Then include the graphics:1\animategraphics&#123;12&#125;&#123;foo-&#125;&#123;0&#125;&#123;18&#125; See the manual of animate for more options.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ten Good Operations in CNN]]></title>
    <url>%2F2017%2F09%2F11%2Ften-good-operations-in-cnn%2F</url>
    <content type="text"><![CDATA[From Zhihu and for study purpose. 卷积只能在同一组进行吗？ – Group ConvolutionGroup convolution 分组卷积，最早在AlexNet中出现，由于当时的硬件资源有限，训练AlexNet时卷积操作不能全部放在同一个GPU处理，因此作者把feature maps分给多个GPU分别进行处理，最后把多个GPU的结果进行融合。 分组卷积的思想影响比较深远，当前一些轻量级的SOTA（State Of The Art）网络，都用到了分组卷积的操作，以节省计算量。 group conv本身应该就大大减少了参数，比如当input channel为256，output channel也为256，kernel size为3*3，不做group conv参数为 256*3*3*256，若group为8，每个group的input channel和output channel均为32，参数为8*32*3*3*32，是原来的八分之一。 分组卷积最后每一组输出的feature maps应该是以concatenate的方式组合，而不是element-wise add，所以每组输出的channel是 input channels / # groups，这样参数量就大大减少了。 卷积核一定越大越好？ – 3×3卷积核AlexNet中用到了一些非常大的卷积核，比如11×11、5×5卷积核，之前人们的观念是，卷积核越大，receptive field（感受野）越大，看到的图片信息越多，因此获得的特征越好。虽说如此，但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低。于是在VGG（最早使用）、Inception网络中，利用2个3x3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1 VS 5×5×1+1）被降低，因此后来3x3卷积核被广泛应用在各种模型中。 每层卷积只能用一种尺寸的卷积核？ – Inception结构传统的层叠式网络，基本上都是一个个卷积层的堆叠，每层只用一个尺寸的卷积核，例如VGG结构中使用了大量的3×3卷积层。事实上，同一层feature map可以分别使用多个不同尺寸的卷积核，以获得不同尺度的特征，再把这些特征结合起来，得到的特征往往比使用单一卷积核的要好，谷歌的GoogleNet，或者说Inception系列的网络，就使用了多个卷积核的结构: 如上图所示，一个输入的feature map分别同时经过1×1、3×3、5×5的卷积核的处理，得出的特征再组合起来，获得更佳的特征。但这个结构会存在一个严重的问题：参数量比单个卷积核要多很多，如此庞大的计算量会使得模型效率低下。这就引出了一个新的结构: 怎样才能减少卷积层参数量？ – Bottleneck发明GoogleNet的团队发现，如果仅仅引入多个尺寸的卷积核，会带来大量的额外的参数，受到Network In Network中1×1卷积核的启发，为了解决这个问题，他们往Inception结构中加入了一些1×1的卷积核，如图所示： 加入1×1卷积核的Inception结构: 根据上图，我们来做个对比计算，假设输入feature map的维度为256维，要求输出维度也是256维。有以下两种操作： 256维的输入直接经过一个3×3×256的卷积层，输出一个256维的feature map，那么参数量为：256×3×3×256 = 589,824. 256维的输入先经过一个1×1×64的卷积层，再经过一个3×3×64的卷积层，最后经过一个1×1×256的卷积层，输出256维，参数量为：256×1×1×64 + 64×3×3×64 + 64×1×1×256 = 69,632。足足把第一种操作的参数量降低到九分之一！ 1×1卷积核也被认为是影响深远的操作，往后大型的网络为了降低参数量都会应用上1×1卷积核。 越深的网络就越难训练吗？ – Resnet残差网络 传统的卷积层层叠网络会遇到一个问题，当层数加深时，网络的表现越来越差，很大程度上的原因是因为当层数加深时，梯度消散得越来越严重，以至于反向传播很难训练到浅层的网络。为了解决这个问题，何凯明大神想出了一个“残差网络”，使得梯度更容易地流动到浅层的网络当中去，而且这种“skip connection”能带来更多的好处，具体参见 ResNet要解决的问题 极深网络（ResNet/DenseNet）: Skip Connection为何有效及其它 为什么ResNet和DenseNet可以这么深？一文详解残差块为何有助于解决梯度弥散问题 卷积操作时必须同时考虑通道和区域吗？ – DepthWise操作标准的卷积过程可以看上图，一个2×2的卷积核在卷积时，对应图像区域中的所有通道均被同时考虑，问题在于，为什么一定要同时考虑图像区域和通道？我们为什么不能把通道和空间区域分开考虑？ Xception网络就是基于以上的问题发明而来。我们首先对每一个通道进行各自的卷积操作，有多少个通道就有多少个过滤器。得到新的通道feature maps之后，这时再对这批新的通道feature maps进行标准的1×1跨通道卷积操作。这种操作被称为”DepthWise convolution“，缩写”DW”。 这种操作是相当有效的，在imagenet 1000类分类任务中已经超过了InceptionV3的表现，而且也同时减少了大量的参数，我们来算一算，假设输入通道数为3，要求输出通道数为256，两种做法： 直接接一个3×3×256的卷积核，参数量为：3×3×3×256=6,912 DW操作，分两步完成，参数量为：3×3×3+3×1×1×256=795，又把参数量降低到九分之一！ 因此，一个depthwise操作比标准的卷积操作降低不少的参数量，同时论文中指出这个模型得到了更好的分类效果。 Factorized Convolutional Neural Networks是Depthwise和Pointwise的历史工作，而Xception和Mobilenet也引用了这个工作。这篇论文的Depthwise中，每一通道输出的feature map（称为“基层”）可以不止一个，而Xception中的Depthwise separable Convolution正是这篇工作中“单一基层”的情况。可以参见博文介绍. 分组卷积能否对通道进行随机分组？ – ShuffleNet在AlexNet的Group Convolution当中，特征的通道被平均分到不同组里面，最后再通过两个全连接层来融合特征，这样一来，就只能在最后时刻才融合不同组之间的特征，对模型的泛化性是相当不利的。为了解决这个问题，ShuffleNet在每一次层叠这种Group conv层前，都进行一次channel shuffle，shuffle过的通道被分配到不同组当中。进行完一次group conv之后，再一次channel shuffle，然后分到下一层组卷积当中，以此循环。 经过channel shuffle之后，Group conv输出的特征能考虑到更多通道，输出的特征自然代表性就更高。另外，AlexNet的分组卷积，实际上是标准卷积操作，而在ShuffleNet里面的分组卷积操作是depthwise卷积，因此结合了通道洗牌和分组depthwise卷积的ShuffleNet，能得到超少量的参数以及超越mobilenet、媲美AlexNet的准确率！ 另外值得一提的是，微软亚洲研究院MSRA最近也有类似的工作，他们提出了一个IGC单元（Interleaved Group Convolution），即通用卷积神经网络交错组卷积，形式上类似进行了两次组卷积，Xception 模块可以看作交错组卷积的一个特例，特别推荐看看这篇文章：王井东详解ICCV 2017入选论文：通用卷积神经网络交错组卷积. 要注意的是，Group conv是一种channel分组的方式，Depthwise + Pointwise是卷积的方式，只是ShuffleNet里面把两者应用起来了。因此Group conv和Depthwise +Pointwise并不能划等号。 通道间的特征都是平等的吗？ – SEnet无论是在Inception、DenseNet或者ShuffleNet里面，我们对所有通道产生的特征都是不分权重直接结合的，那为什么要认为所有通道的特征对模型的作用就是相等的呢？ 这是一个好问题，于是，ImageNet2017 冠军SEnet就出来了。 一组特征在上一层被输出，这时候分两条路线，第一条直接通过，第二条首先进行Squeeze操作（Global Average Pooling），把每个通道2维的特征压缩成一个1维，从而得到一个特征通道向量（每个数字代表对应通道的特征）。然后进行Excitation操作，把这一列特征通道向量输入两个全连接层和sigmoid，建模出特征通道间的相关性，得到的输出其实就是每个通道对应的权重，把这些权重通过Scale乘法通道加权到原来的特征上（第一条路），这样就完成了特征通道的权重分配。作者详细解释可以看这篇文章：专栏 | Momenta详解ImageNet 2017夺冠架构SENet 能否让固定大小的卷积核看到更大范围的区域？ – Dilated convolution标准的3×3卷积核只能看到对应区域3×3的大小，但是为了能让卷积核看到更大的范围，dilated conv使其成为了可能。dilated conv原论文中的结构如图所示： 上图b可以理解为卷积核大小依然是3×3，但是每个卷积点之间有1个空洞，也就是在绿色7×7区域里面，只有9个红色点位置作了卷积处理，其余点权重为0。这样即使卷积核大小不变，但它看到的区域变得更大了。详细解释可以看这个回答：如何理解空洞卷积（dilated convolution）？ 卷积核形状一定是矩形吗？ – Deformable convolution 可变形卷积核传统的卷积核一般都是长方形或正方形，但MSRA提出了一个相当反直觉的见解，认为卷积核的形状可以是变化的，变形的卷积核能让它只看感兴趣的图像区域 ，这样识别出来的特征更佳。 图来自微软亚洲研究院公众号要做到这个操作，可以直接在原来的过滤器前面再加一层过滤器，这层过滤器学习的是下一层卷积核的位置偏移量（offset），这样只是增加了一层过滤器，或者直接把原网络中的某一层过滤器当成学习offset的过滤器，这样实际增加的计算量是相当少的，但能实现可变形卷积核，识别特征的效果更好。详细MSRA的解读可以看这个链接：可变形卷积网络：计算机新“视”界。 启发与思考现在越来越多的CNN模型从巨型网络到轻量化网络一步步演变，模型准确率也越来越高。现在工业界追求的重点已经不是准确率的提升（因为都已经很高了），都聚焦于速度与准确率的trade off，都希望模型又快又准。因此从原来AlexNet、VGGnet，到体积小一点的Inception、Resnet系列，到目前能移植到移动端的mobilenet、ShuffleNet（体积能降低到0.5mb！），我们可以看到这样一些趋势： 卷积核方面： 大卷积核用多个小卷积核代替； 单一尺寸卷积核用多尺寸卷积核代替； 固定形状卷积核趋于使用可变形卷积核； 使用1×1卷积核（bottleneck结构）。 卷积层通道方面： 标准卷积用depthwise卷积代替； 使用分组卷积； 分组卷积前使用channel shuffle； 通道加权计算。 卷积层连接方面： 使用skip connection，让模型更深； densely connection，使每一层都融合上其它层的特征输出（DenseNet）]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intuitional Explanation for CNN]]></title>
    <url>%2F2017%2F09%2F11%2Fintuitional-explanation-for-cnn%2F</url>
    <content type="text"><![CDATA[From Zhihu. Version 1Introduction对二维数字信号（图像）的操作，可以写成矩阵形式。 比如对图像做平滑，一个典型的8领域平滑，其结果中的每个值都来源于原对应位置和其周边8个元素与一个3X3矩阵的乘积：也就相当于对原矩阵，按照顺序将各区域元素与W矩阵相乘，W 矩阵为 这也被称作核(Kernel, 3X3), 其处理效果如下：也就是，这个核对图像进行操作，相当于对图像进行了低通滤波。因此这个核也被称为滤波器，整个操作过程按照概念称为卷积。 扩展来讲，对二维图像的滤波操作可以写成卷积，比如常见的高斯滤波、拉普拉斯滤波（算子）等。 滤波器和卷积神经网络的关系我们要识别图像中某种特定曲线，也就是说，这个滤波器对这种曲线有很高的输出，对其他形状则输出很低。这就像是神经元的激活。 我们设计的滤波器和想要识别的曲线如下：假设上面的核（滤波器）按照卷积顺序沿着下图移动：那么当它移动到上面的位置时，按照矩阵操作，将这个区域的图像像素值与滤波器相乘，我们得到一个很大的值（6600）：而当这个滤波器移动到其他区域时，我们得到一个相对很小的值： 因此，我们对整个原图进行一次卷积，得到的结果中，在那个特定曲线和周边区域，值就很高，在其他区域，值相对低。这就是一张激活图,对应的高值区域就是我们所要检测曲线的位置。 在训练CNN的某一个卷积层时，我们实际上是在训练一系列的滤波器filter。比如，对于一个32x32x3的图像，如果我们在CNN的第一个卷积层定义训练12个滤波器，那就这一层的输出便是32x32x12。按照不同的任务，我们可以对这个输出做进一步的处理，这包括激活函数，池化，全连接等。 简单来说，训练CNN在相当意义上是在训练每一个卷积层的滤波器。让这些滤波器组成特定的模式，具有高的激活，以达到CNN网络的分类/检测等目的。 卷积神经网络的第一个卷积层的滤波器用来检测低阶特征，比如边、角、曲线等。随着卷积层的增加，对应滤波器检测的特征就更加复杂（理性情况下，也是我们想要的情况）。比如第二个卷积层的输入实际上是第一层的输出(滤波器激活图)，这一层的滤波器便是用来检测低价特征的组合等情况(半圆，四边形等)，如此积累，以检测越來越复杂的特征。实际上，我们的人类大脑的视觉信息处理也遵循这样的低阶特征的模式。最后一层的滤波器按照训练CNN目的的不同，可能是在检测人脸，手写字体等时候被激活。 所以，在相当程度上，构建卷积神经网络的任务就在于构建这些滤波器。也就是，将这些滤波器变成这样（改变滤波器矩阵的值，即weight）的 – 能识别特定的特征。 在训练开始之时，卷积层的滤波器是完全随机的，它们不会对任何特征激活（不能检测任何特征）。把一个空白的滤波其，修改其权重(weights)以使它能检测特定的模式，整个过程就如工程里面的反馈。 Version 2基于 Visualizing and Understanding Convolutional Networks，通过反卷积(De-convolution)的方法，看每一层卷积神经网络的具体工作。 首先第一层的返卷积（上面是反卷积的图片，下面对于第一层来说，激活值最大的图片）。我们看到，第一个卷积层只是表达了简单的图片的边缘而已。 我们来看第二层。可以发现：第二层稍稍复杂了一点点，可以包含的不仅仅是一个边缘，可以是几个边缘的组合。 第三层： 第四层： 第五层： 我们看到，每一层都是对于一张图片从最基础的边缘，不断到最复杂的图片自己本身。 同时在进行反卷积的时候M.D. Zeiler and R. Fergus也发现，对于第一层的alexnet，会得到频度很高的像素（也就是颜色很深），所以他们也提出了应该要减小窗口，这样可以得到频度比较适中的像素： 当图片卷积完之后，会把一个图片对于这一类本身最独特的部分凸显出来，然后来进行判断，这一类到底是什么？有下面的实验截图：最左边的图像是原图像，作者盖住不同的区域，来分析对于一张图片，经过五次卷积之后，到底是如何判断的，我们看到卷积到最后（左三），比较凸显出来的是狗的头部，左二和右二的意思是，当我们遮住不同的区域，判断是狗的几率，红色区域代表概率很高，蓝色区域代表概率很低，我们发现，当我们遮挡住狗的头的地方的时候，我们得到这个物体时狗的概率最低，这个侧面证明了，所谓卷积神经网络，就是会自动的对于一张图片学习出最好的卷积核以及这些卷积核的组合方式，也就是对于一张图片的任务来说，求出最好的图片对于本任务的特征的表达，然后来进行判断。]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning Interview Questions]]></title>
    <url>%2F2017%2F09%2F11%2Finterview-deep-learning%2F</url>
    <content type="text"><![CDATA[Collect deep learning questions/answers from the web,e.g., 深度学习岗位面试问题整理笔记,深度学习相关的职位面试时一般会问什么？会问一些传统的机器学习算法吗？,如果你是面试官，你怎么去判断一个面试者的深度学习水平？. QuestionsQuestion 1CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？ Deep Learning -Yann LeCun, Yoshua Bengio &amp; Geoffrey Hinton. Learn TensorFlow and deep learning, without a Ph.D. The Unreasonable Effectiveness of Deep Learning -LeCun 16 NIPS Keynote 以上几个不相关问题的相关性在于，都存在局部与整体的关系，由低层次的特征经过组合，组成高层次的特征，并且得到不同特征之间的空间相关性。如下图：低层次的直线／曲线等特征，组合成为不同的形状，最后得到汽车的表示。 CNN抓住此共性的手段主要有四个：局部连接／权值共享／池化操作／多层次结构。 局部连接使网络可以提取数据的局部特征 权值共享大大降低了网络的训练难度，一个Filter只提取一个特征，在整个图片（或者语音／文本） 中进行卷积； 池化操作与多层次结构一起，实现了数据的降维，将低层次的局部特征组合成为较高层次的特征，从而对整个图片进行表示。如下图： 上图中，如果每一个点的处理使用相同的Filter，则为全卷积，如果使用不同的Filter，则为Local-Conv。 Question 2为什么很多做人脸的Paper会最后加入一个Local Connected Conv？ DeepFace: Closing the Gap to Human-Level Performance in Face Verification 以FaceBook DeepFace 为例： DeepFace 先进行了两次全卷积＋一次池化，提取了低层次的边缘／纹理等特征。 后接了3个Local-Conv层，这里是用Local-Conv的原因是，人脸在不同的区域存在不同的特征（眼睛／鼻子／嘴的分布位置相对固定），当不存在全局的局部特征分布时，Local-Conv更适合特征的提取。 Question 3什麽样的资料集不适合用深度学习? 数据集太小，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。 数据集没有局部相关特性, 目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理。举个例子：预测一个人的健康状况，相关的参数会有年龄、职业、收入、家庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。 Question 4对所有优化问题来说, 有没有可能找到比現在已知算法更好的算法? 机器学习-周志华 没有免费的午餐定理： 对于训练样本（黑点），不同的算法A/B在不同的测试样本（白点）中有不同的表现，这表示：对于一个学习算法A，若它在某些问题上比学习算法 B更好，则必然存在一些问题，在那里B比A好。 也就是说：对于所有问题，无论学习算法A多聪明，学习算法 B多笨拙，它们的期望性能相同。 但是：没有免费午餐定力假设所有问题出现几率相同，实际应用中，不同的场景，会有不同的问题分布，所以，在优化算法时，针对具体问题进行分析，是算法优化的核心所在。 Question 5用贝叶斯机率说明Dropout的原理 Dropout as a Bayesian Approximation: Insights and Applications To be extended Question 6何为共线性, 跟过拟合有啥关联? Multicollinearity-Wikipedia 共线性：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。 共线性会造成冗余，导致过拟合 解决方法：排除变量的相关性／加入权重正则。 Question 7说明如何用支持向量机实现深度学习(列出相关数学公式) Question 8广义线性模型是怎被应用在深度学习中? A Statistical View of Deep Learning (I): Recursive GLMs 深度学习从统计学角度，可以看做递归的广义线性模型。 广义线性模型相对于经典的线性模型(y=wx+b)，核心在于引入了连接函数g(.)，形式变为：y=g−1(wx+b)。 深度学习时递归的广义线性模型，神经元的激活函数，即为广义线性模型的链接函数。逻辑回归（广义线性模型的一种）的Logistic函数即为神经元激活函数中的Sigmoid函数，很多类似的方法在统计学和神经网络中的名称不一样，容易引起初学者的困惑。下图是一个对照表： Question 9什麽造成梯度消失问题? 推导一下 Yes you should understand backdrop－Andrej Karpathy How does the ReLu solve the vanishing gradient problem? 神经网络的训练中，通过改变神经元的权重，使网络的输出值尽可能逼近标签以降低误差值，训练普遍使用BP算法，核心思想是，计算出输出与标签间的损失函数值，然后计算其相对于每个神经元的梯度，进行权值的迭代。 梯度消失会造成权值更新缓慢，模型训练难度增加。造成梯度消失的一个原因是，许多激活函数将输出值挤压在很小的区间内，在激活函数两端较大范围的定义域内梯度为0。造成学习停止。 Question 10什么是Weights Initialization. 不同的方式，造成的后果。为什么会造成这样的结果。 几种主要的权值初始化方法： lecun_uniform / glorot_normal / he_normal / batch_normal lecun_uniform: Efficient BackProp glorot_normal: Understanding the difficulty of training deep feedforward neural networks he_normal: Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification batch_normal: Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift Question 11为什么网络够深(Neurons 足够多)的时候，总是可以避开较差Local Optima？ The Loss Surfaces of Multilayer Networks Question 12Loss. 有哪些定义方式（基于什么？）， 有哪些优化方式，怎么优化，各自的好处，以及解释。 Cross-Entropy / MSE / KL散度 Question 13Dropout。 怎么做，有什么用处，解释。 How does the dropout method work in deep learning? Improving neural networks by preventing co-adaptation of feature detectors An empirical analysis of dropout in piecewise linear networks Question 14Activation Function. 选用什么，有什么好处，为什么会有这样的好处。 几种主要的激活函数：Sigmond / ReLU ／PReLU Deep Sparse Rectifier Neural Networks Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification Question 15推导一下Softmax Loss]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow, Dynamic Batching]]></title>
    <url>%2F2017%2F09%2F04%2Ftensorflow-dynamic-batching%2F</url>
    <content type="text"><![CDATA[From 以静制动的TensorFlow Fold. 近期各大框架发展的趋势主要有两个，一个是增加对动态图计算的支持，另一个是在主编程语言上适应广大用户的需求。最近比较火热的动态计算图相关的框架主要有DyNet、PyTorch和TensorFlow Fold，就是围绕着这其中一个点或两个点进行的。 当我们说动态计算图的时候，我们指的是什么？首先，我们要搞清楚深度学习框架所谓的“动态”和“静态”究竟是按照什么标准划分的。 静态框架在静态框架使用的是静态声明（static declaration）策略，计算图的声明和执行是分开的。 这个整个声明和执行的过程中涉及到两个图，这里我们分别给它们一个名字： 虚拟计算图: 声明阶段构建的图 在这个过程中框架需要将用户的代码转化为可以一份详细的计算图，这份计算图一般会包含计算执行顺序和内存空间分配的策略，这些策略的制定一般是这个过程最消耗时间的部分。 实体计算图: 执行阶段构建的图 这个过程包括为参数和中间结果实际分配内存空间，并按照当前需求进行计算等，数据就在这张实体计算图中计算和传递。 不过这里要注意一点的是，虚拟计算图中的部件并不需要在每一次执行中都转化为实体计算图。 常见的静态框架有TensorFlow、MXNet、Theano等。 动态框架动态框架则不同，使用的是动态声明（dynamic declaration）策略，声明和执行一起进行的。 这样虚拟计算图和实体计算图的构建就是同步进行的了。因为可以实时的计划，动态框架可以根据实时需求构建对应的计算图，在灵活性上，动态框架会更胜一筹。Torch、DyNet、Chainer等就是动态框架。 静态框架 V.S. 动态框架静态框架将声明和执行分开的好处:是在执行前就知道了所有的需要进行操作，所以可以对图中各节点计算顺序和内存分配进行合理的规划，这样就可以就较快的执行所需的计算。 静态框架的执行效率相对来说就更高一些。这一点是动态框架的劣势，因为它每次规划、分配内存、执行的时候，都只能看到局部的需求，所以并不能做出全局最优的规划和内存分配。 同样道理，动态框架对虚拟计算图的构建速度有较高的要求。当然因为动态框架每步构建和计算只是虚拟计算图的一个局部，需要策略不会太复杂，所以制定策略也快得多。 其他及引言在过去的大部分的深度学习项目中，不管使用的是静态框架还是动态框架，我们实际上都只用到了构建静态实际计算图的能力。 在一般在将数据投入模型进行训练或预测之前，往往会有一个预处理的步奏。在预处理的时候，我们会将图片缩放裁剪，将句子拼接截断，使他们变为同样的形状大小，然后将集成一个个批次（min-batch），等待批次训练或预测。这些不同的输入到模型中其实运行的是同一个计算图。 这样作的好处是可以充分利用GPU和多核CPU的并行计算能力。 建筑施工队里面有很多的砌墙工人，100个人取砌一堵1米的墙并不会比10个人快上10倍（能实际工作的可能还是只有10个人），而让他们同时砌十堵1米的墙，可能所花的时间可能和砌一堵墙几乎一样快。如果有很多可以通过这样并行来加速的工作，那整个工程所需要的时间也就可以大大缩短。GPU能够几十倍上百倍地提高计算速度是现代深度学习发展的一个关键。 然而，并不是所有项目的数据都可以预处理成相同的形状和尺寸。例如自然语言处理中的语法解析树，源代码中的抽象语法树，以及网页中的DOM树等，形状的不同本身就是非常重要的特征，不可剥离。 这样一来，对于每一个样例，我们都需要一个新的计算图，这种问题我们需要使用构建动态计算图的能力才能够解决。这种问题我们可以叫它多结构输入问题，因为这个问题中计算图的动态需求是输入带来的。 不同框架这个问题的求解能力可以分为三个程度: 第一层，无法计算，对于所有样本都要求同样的结构，在TensorFlow Fold出来之前所有正常使用的静态框架处于这个层次。 第二层，能计算但不够高效，不同批次的样本之间可以有不同的结构，但同一个批次样本都是同一个结构，因为无法利用GPU和多核CPU的并行计算能力，不能高效计算，目前所有的动态框架属于这个层次。 第三层，能高效计算，能够在同一个批次里包含不同结构的样本，这个层次的多结构输入问题有些论坛上也叫Dynamic Batching问题， TensorFlow Fold的核心算法Dynamic Batching算法刚好同名，TensorFlow Fold和以后实现Dynamic Batching算法的框架处于这个层次。 多结构输入问题早已存在，可用的模型诸如递归神经网络（Recursive Neural Networks）也提出许久，但因为没有办法高效实现，研究和使用者寥寥无几。因此，当我们说各大框架的动态计算图的时候，我们关心的不仅仅是他们谁更容易做到，更重要的是能不能高效地做到。动态计算图问题之一的多结构输入问题的高效计算问题一旦解决，就会大大促进树状网络甚至更复杂模型和数据集的发展。 但值得注意的是：多结构输入问题并不是唯一的动态图计算问题，这里给大家举另外一个例子，即计算图的结构要依赖于自身的计算结果的情况。 框架竞争的焦点：编程语言与动态计算图在动态计算图争锋下面，还隐含着另外一重较量，编程语言的支持。当前深度学习界最受欢迎的语言莫过于Python了，此外C++也因为其本身的高效在工业界颇得青睐。现在大多主流框架都支持这两种语言，他们是就像机器学习界的中英文。不过Torch是一个例外，它使用的是比较小众的Lua。 这实际上是Lua最大一块短板，因为使用Lua做一些数据处理并不方便，使用者经常要使用Python之类的语言进行数据清洗等操作，然后在转化为Lua可以读取的形式。这一点使得无数使用者在不同语言的切换中纷纷投向TensorFlow、MXNet的怀抱。即使去年年中Facebook推出TorchNet这个Torch升级版也没有挽回太多的人气，因为TorchNet用的也是Lua。 在DyNet出现前，Python和C++上还没有一个比较高效的动态计算框架（如Chainer效率并不高）。DyNet通过对动态声明的图构建流程的优化，大大提高了构建虚拟计算图的速度。该框架在LSTM和BiLSTM等部分测试中超过了Chainer、Theano和TensorFlow，并且在当时Theano和TensorFlow难以实现的树状模型TreeLSTM的测试中也远远打败了Chainer，所以DyNet一出来吸引住了不少使用者。 然而好景不长，Torch不愧是有Facebook支持的公司，很快就推出了据说内部使用已久的PyTorch，将Torch移植到了Python，补足了自己最后一块短板。这下子就厉害了，不仅挽留住了人气，借助Python的力量甚至有机会从TensorFlow这位老大手里夺下一块蛋糕。 但是不管是DyNet还是PyTorch，没有解决多结构输入问题的高效计算。它们虽然对不同的批次（mini-batch）可以给出不同的计算图。但同一个批次内部的样本的形状还是要求一致，并没有一个成熟的解决方案来应对这种情况。 以静制动：巧妙的Dynamic Batching算法通用子图的组成TensorFlow Fold解决问题的核心技术叫Dynamic Batching，这个技术能够构建一个能够模拟任意形状和大小的动态计算图的静态图，原本不同样本的动态计算图都会被重写成能够被这个计算图高效计算的形式。这样就巧妙地解决了动态计算图的高效计算问题。 打比喻就是，建筑公司请了一位计算机科学家写了一个自动化办公软件，每当房地产商提出一个个性社区问题的时候，这个软件就会把一张通用的设计图告诉设计师去设计；然后对于每一批楼的需求这个软件都会生成对应的施工指南，只要按照这个指南的指示，施工就可以通过多次建造通用设计图中的一部分来完成这批楼的建造；在施工指南中软件已经合并每次建造时重复的工作，这样施工队可以并行施工，高效地完成工程。 那为什么用静态计算图模拟动态计算图是可能的？因为虽然动态计算图的形状和大小千变万化，但对于一个模型来说它们的基本组件却可以简单划分为两种：Tensor（张量）和Operation（操作）。 Tensor，可以看做各种各样的数据块，主要包括输入的样本和计算结果，Tensor的类型可以按照shape（形状）和data type（数据类型）划分，具有相同shape和data type的Tensor可以被划分为一类，就像相同大小和材质的砖头；这里的shape并不包括batch size，它就像砖头的个数，一叠不管是十块还是五块，只要砖头的大小材质一样，我们认为是同一个类。 Operation，并不是是指加减乘除这样最底层的操作，而是指一块小的计算子图，一块计算子图接受某种确定类型的Tensor作为输入，并输出某种确定类型的Tensor。这块计算子图在动态构建图的过程中并不会被拆开，而是作为一个整体被适用，比如RNN的Cell或其他用户自己定义的一些固定的操作组合。 对于某一个模型如树状RNN来说，但它只会有限种Operation和Tensor类型，当我们将这些Operation和Tensor类型放到一起，我们就有了一个通用子图，这时候只需要一些控制部件控制这个每次子图执行的部分（上文有提到每次执行的实体计算图可以只是虚拟计算图的一部分）以及组合方式，我们就可以模拟对应模型所有可能的计算图。达成这种控制只需TensorFlow的三个部件：tf.gather、tf.concat和tf.while_loop。 Dynamic Batching如何将不同结构的计算图重写成可以用通用子图计算的形式Dynamic Batching是一个贪婪（greedy）的算法，它接受一个有向无环计算图作为输入: 给图中的每一个节点（操作）标注一个深度，所有没有任何依赖的节点标注为深度0，依赖的节点深度最大为d的节点的深度标注为d+1; 在图中插入pass-through（直通）的操作，使得第d+1层只依赖于第d层; 将同一深度涉及相同操作的节点合并到一起，方便并行计算; 将同一深度的计算结果按Tensor类型（包括Tensor的形状和数值类型）有序拼接在一起; 将输入原始计算图中的每条边标记上（深度，数据类型，序号），对应它们可以获取上一层计算结果的位置。 对于一批不同结构的计算图，我们可以把它们看做不连通的大图同样处理。算法在每次迭代中执行一个深度的计算，使用tf.while_loop从深度0一直执行到最大深度。在每一个深度中，tf.gather根据上面第五步的标记为各个Operation获取当前深度各条输入边的Tensor，如果某个Operation没有获取到任何Tensor，说明当前深度这个Operation不需要执行计算。Operation执行完后tf.concat将相同Tensor类型的计算结果拼接在一起，提供给下一个深度的计算。 在上图中，左边是Dynamic Batching为二叉TreeRNN构建的通用计算图。右边是一颗简单的语法解析树。通用计算图中有两种Tensor，代表单词的编码整数、词向量/hidden向量的128维向量。Operation也只有两个一个词向量查表操作（embed lookup）和一个RNN的Cell。图中gather和concat之间的直连表示直通（pass-through）操作。右边的语法解析树可以分为三层计算被执行：第一层，将1、3、5通过词向量查表操作，输出3个128维的词向量；第二层，1和3对应的词向量通过RNN Cell输出一个128维的隐含层向量，5对应的词向量直通输出；第三层，上一层计算的隐含层向量和5对应的词向量通过RNN Cell，输出一个128维的隐含层向量。计算完毕。(那这个算法的效果怎么样呢？它在TreeLSTM的实验中，8核英特尔CPU的可以加速20多倍，而英伟达GTX-1080上可以加速100倍左右。这个加速比是采用Dynamic Batching算法批处理中平均每个样本执行的平均时间和单个样本不作批处理的执行时间之比。这里不包含构建虚拟图所需要的时间。) TensorFlow Fold：封装在静态框架上的动态接口新推出的TensorFlow Fold就是一个TensorFlow的封装，设计参考了函数式编程的一些思想，目的就是方便用户快速地构建动态计算图。 TensorFlow Fold提供了一些函数专门用来处理序列(x_1,…,x_n): Map(f): 计算[f(x_1) ,…,f(x_n)]将函数f应用到每一个序列的元素，比如将句子中的每一个词转化为词向量; Fold(g, z): 计算g(…,g(z, x_1), x_2), …,x_n)，比如说展开一个RNN（循环神经网络） Reduce(g): 计算g(Reduce(g)[x_1 ,…,x_{n/2}],Reduce(g)[x_{n/2} ,…,x_n]，将函数g应用到一颗平衡二叉树上，比如对序列中的元素作max或sum-pooling。 由于TensorFlow原本的基本单元Tensor不适合用于构建动态图，所以Fold引入新的基本组件Block。Block有明确的一个输入类型和一个输出类型，包括： Input: 来着编程语言如Python中元素，比如字典等; Tensor: 拥有数据类型和形状的TensorFlow基本模块; Tuple(t_1 ,...,t_n): 括号中的每一个t表示对应位置的类型; Sequence(t): 一个不定长的拥有类型为t的元素的序列; Void: 单元类型。这些基本类型可以相互嵌套，比如一个Block的输入类型可以是Input类型的Tuple。 用来创建Block的基本函数有： Scalar: 将Python标量转化为Tensor; Tensor: 将Numpy数组转化为Tensor; Function(h): 创建一个Operation; InputTransform(h): 用于预处理Python类型。 用来组合Block的基本函数有: b1 &gt;&gt; b2，流水线（pipeline): 将b1 的输出作为b2 的输入; Record({l_1:b_1,..., l_n:b_n}): 接受一个Python字典为输入，对字典中key值为l_i的value应用; OneOf (b_1,...,b_n): 根据输入条件应用b_1,…,b_n中的一个; Optional(b): OneOf的特例，如果输入不为None，应用b; AllOf(b_1,...,b_n): 输入应用中的每一个。 用来组合Block的高级函数有： Composition(): 流水线的升级版，流水线只能处理串行的流程，Composition()创建一个Scope对象，在这个Scope的缩进范围内，采用b.reads(b_1,…,b_n)来读取多个数据流，可以用于构建多分支结构; ForwardDeclaration(): 用来创建递归结构，这个函数可以先定义一个预先占位的表达式expr，等这个表达式定义完再用expr.resolve_to(expr_def)，将表达式递归地代入，这是用来创建树结构计算图必不可少的工具。]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Difference between divide and conquer, dynamic programming and greedy algorithm]]></title>
    <url>%2F2017%2F08%2F17%2Fdifference-between-divide-and-conquer-dynamic-programming-greedy-algorithm%2F</url>
    <content type="text"><![CDATA[. 分治法 (divide and conquer)，动态规划法 (dynamic programming)，贪心算法(greedy algorithm)这三者之间有类似之处，比如都需要将问题划分为一个个子问题，然后通过解决这些子问题来解决最终问题。但其实这三者之间的区别还是蛮大的。 分治法分治法（divide-and-conquer）：将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。 分治模式在每一层递归上都有三个步骤： 分解（Divide）：将原问题分解成一系列子问题； 解决（conquer）：递归地解各个子问题。若子问题足够小，则直接求解； 合并（Combine）：将子问题的结果合并成原问题的解。 动态规划法动态规划算法的设计可以分为如下4个步骤： 描述最优解的结构 递归定义最优解的值 按自底向上的方式计算最优解的值 由计算出的结果构造一个最优解 分治法是指将问题划分成一些独立地子问题，递归地求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。 适合采用动态规划方法的最优化问题中的两个要素：最优子结构和重叠子问题。 最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。 重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法课反复地解同样的子问题，而不是总在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。 “分治法：各子问题独立 动态规划：各子问题重叠” 算法导论： 动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。 如果同一个问题的两个子问题不共享资源，则它们就是独立的。 对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠的。 贪心算法贪心算法是使所做的选择看起来都是当前最佳的，期望通过所做的局部最优选择来产生出一个全局最优解。每一步的最优解一定依赖上一步的最优解。贪心算法对大多数优化问题来说能产生最优解，但也不一定总是这样的。 贪心算法只需考虑一个选择（亦即，贪心的选择）；在做贪心选择时，子问题之一必须是空的，因此只留下一个非空子问题。 相似点贪心算法与动态规划与很多相似之处。特别地，贪心算法适用的问题也是最优子结构。贪心算法与动态规划有一个显著的区别，就是贪心算法中，是以自顶向下的方式使用最优子结构的。贪心算法会先做选择，在当时看起来是最优的选择，然后再求解一个结果子问题，而不是先寻找子问题的最优解，然后再做选择。 不同点贪心算法是通过做一系列的选择来给出某一问题的最优解。对算法中的每一个决策点，做一个当时看起来是最佳的选择。这一点是贪心算法不同于动态规划之处。 在动态规划中，每一步都要做出选择，但是这些选择依赖于子问题的解。因此，解动态规划问题一般是自底向上，从小子问题处理至大子问题。 贪心算法所做的当前选择可能要依赖于已经做出的所有选择，但不依赖于有待于做出的选择或子问题的解。因此，贪心算法通常是自顶向下地做出贪心选择，不断地将给定的问题实例归约为更小的问题。 Summary 动态规划 全局最优解中一定包含某个局部最优解，但不一定包含前一个局部最优解，因此需要记录之前的所有最优解。 条件：最优子结构；重叠子问题。 方法：自底向上构造子问题的解。 贪心算法 条件：每一步的最优解一定依赖上一步的最优解。 方法：从问题的某一个初始解出发逐步逼近给定的目标，以尽可能快的地求得更好的解。当达到某算法中的某一步不能再继续前进时，算法停止。 问题： 不能保证求得的最后解是最佳的 不能用来求最大最小解的问题 特性： 它对解空间树的遍历不需要自底向上，而只需要自根开始，选择最优的路，一直走到底就可以了。这样，与动态规划相比，它的代价只取决于子问题的数目，而选择数目总为1。 动态规划与贪心算法的联系 都是一种递推算法； 贪心和动态规划本质上是对子问题树的一种修剪。两种算法要求问题都具有的一个性质就是“子问题最优性”。即组成最优解的每一个子问题的解，对于这个子问题本身肯定也是最优的。]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to use pretrained model]]></title>
    <url>%2F2017%2F08%2F16%2Fhow-to-use-pretrained-model%2F</url>
    <content type="text"><![CDATA[From the course cs231n. Transfer LearningIn practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest. The three major Transfer Learning scenarios look as follows: ConvNet as fixed feature extractor. Take a ConvNet pretrained on ImageNet, remove the last fully-connected layer, then treat the rest of the ConvNet as a fixed feature extractor for the new dataset. We call these features CNN codes. Once you extract the codes for all images, train a linear classifier (e.g. Linear SVM or Softmax classifier) for the new dataset. Fine-tuning the ConvNet. Not only replace and retrain the classifier on top of the ConvNet on the new dataset, but to also fine-tune the weights of the pretrained network by continuing the backpropagation. It is possible to: fine-tune all the layers of the ConvNet keep some of the earlier layers fixed (due to overfitting concerns) and only fine-tune some higher-level portion of the network. This is motivated by the observation that the earlier features of a ConvNet contain more generic features (e.g. edge detectors or color blob detectors) that should be useful to many tasks, but later layers of the ConvNet becomes progressively more specific to the details of the classes contained in the original dataset. Pretrained models. Since modern ConvNets take 2-3 weeks to train across multiple GPUs on ImageNet, it is common to see people release their final ConvNet checkpoints for the benefit of others who can use the networks for fine-tuning. When and how to fine-tune?How do you decide what type of transfer learning you should perform on a new dataset?The two most important facotors are: the size of new dataset (small or big) its similarityto the original dataset. e.g. ImageNet-like in terms of the content of images and the classes, or very different, such as microscope images. Keeping in mind that ConvNet features are more generic in early layers and more original-dataset-specific in later layers, here are some common rules of thumb for navigating the 4 major scenarios: New dataset is small and similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes. New dataset is large and similar to the original dataset. Since we have more data, we can have more confidence that we won’t overfit if we were to try to fine-tune through the full network. New dataset is small but very different from the original dataset. Since the data is small, it is likely best to only train a linear classifier. Since the dataset is very different, it might not be best to train the classifier form the top of the network, which contains more dataset-specific features. Instead, it might work better to train the SVM classifier from activations somewhere earlier in the network. New dataset is large and very different from the original dataset. Since the dataset is very large, we may expect that we can afford to train a ConvNet from scratch. However, in practice it is very often still beneficial to initialize with weights from a pretrained model. In this case, we would have enough data and confidence to fine-tune through the entire network. Practical adviceConstraints from pretrained modelsNote that if you wish to use a pretrained network, you may be slightly constrained in terms of the architecture you can use for your new dataset. For example, you can’t arbitrarily take out Conv layers from the pretrained network. However, some changes are straight-forward: Due to parameter sharing, you can easily run a pretrained network on images of different spatial size.This is clearly evident in the case of Conv/Pool layers because their forward function is independent of the input volume spatial size (as long as the strides “fit”).In case of FC layers, this still holds true because FC layers can be converted to a Convolutional Layer: For example, in an AlexNet, the final pooling volume before the first FC layer is of size [6x6x512]. Therefore, the FC layer looking at this volume is equivalent to having a Convolutional Layer that has receptive field size 6x6, and is applied with padding of 0. Learning ratesIt’s common to use a smaller learning rate for ConvNet weights that are being fine-tuned, in comparison to the (randomly-initialized) weights for the new linear classifier that computes the class scores of your new dataset. This is because we expect that the ConvNet weights are relatively good, so we don’t wish to distort them too quickly and too much (especially while the new Linear Classifier above them is being trained from random initialization).]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A overview of gradient descent optimization algorithms]]></title>
    <url>%2F2017%2F08%2F13%2Fcompare-gradient-descent-algorithm%2F</url>
    <content type="text"><![CDATA[copy and paste. A brief comparison of different gradient descent optimizaiton algorithmsBatch based methodsBatch Gradient Descent使用我们拿到的所有的数据计算梯度, 然后使用这个梯度对参数进行更新. 在凸函数中, 只要学习率足够小, 肯定能够找到全局最优点, 在非凸函数中也可以保证找到局部最优. 优点 方法简单 能够保证收敛到全局最优值(凸函数)/局部最优值(非凸函数) 缺点 训练数据太多的时候无法全部放入内存 训练数据多的时候计算梯度的时间非常久 无法进行 online 的更新 Stochastic Gradient Descent和 Batch Gradient Descent 相反, SGD 又走入了另外一个极端, SGD 拿到一个数据之后, 马上计算梯度, 然后对参数进行更新. 1x += - learning_rate * dx 优点： 收敛速度快(因为在Batch 的方法中, 每次计算梯度会计算很多相似的样本得到的梯度, 这部分是冗余的) 可以 online 更新 有可能逃出一个比较差的局部最优而收敛到一个更好的局部最优甚至是全局最优 缺点： 选择合适的learning rate比较困难 对所有的参数更新使用同样的learning rate.对于稀疏数据或者特征,有时我们可能想更新快一些对于不经常出现的特征,对于常出现的特征更新慢一些,这时候SGD就不太能满足要求了 SGD容易收敛到局部最优,并且容易被困在鞍点. 无法利用矩阵操作加速计算过程 Mini-batch Gradient DescentMini-batch 的方法是batch gradient descent和stochastic gradient descent的折衷, 每次从全部的熟练数据中取一个 mini-batch 的数据计算 Currnet issues上述 3 各方法遇到的问题是: 如何选择一个合适的 learning rate 是非常困难的 目前有一些通过 schedule 的方式来设置 learning rate 的方法, 即预先设计好计算了一定数量的迭代之后减小 learning rate, 但是, 由于是在训练之前就要设置好, 因此, 无法根据训练时的情况进行调整. 实践中也证明这种 schedule 的方法非常不可靠. 上述方法中, 对于每一个参数的 learning rate 都是相同的, 这种做法是不合理的. 试想, 如果训练数据是稀疏的, 而且, 特征数据出现的频率变化很大, 那么, 比较合理的做法是, 对于出现频率低的特征设置较大的学习速率, 对于出现频率较大的特征数据设置较小的学习速率. 近期的的研究表明, 深层神经网络之所以比较难训练, 并不是因为容易进入 local minimum, 相反, 由于网络结构非常复杂, 在绝大多数情况下, 即使是 local minimum 也可以得到非常好的结果. 而之所以难训练是因为学习过程容易陷入到马鞍面中, 即在坡面上, 一部分点是上升的, 一部分点是下降的. 而这种情况比较容易出现在平坦区域, 在这种区域中, 所有方向的梯度值都几乎是 0. Some variants without learning rate decayMomentumSGD方法的一个缺点是其更新方向完全依赖于当前batch计算出的梯度,因而十分不稳定.Momentum算法借用了物理中的动量概念,它模拟的是物体运动时的惯性,即更新的时候在一定程度上保留之前更新的方向,同时利用当前batch的梯度微调最终的更新方向.它在相关方向加速SGD,抑制振荡,可以在一定程度上增加稳定性,从而加快收敛,并且还有一定摆脱局部最优的能力. 他有如下公式：123# Momentum updatev_t = mu * v_&#123;t - 1&#125; - learning_rate * dx # integrate velocityx += v_t # integrate position Momentum算法会观察历史梯度v_{t−1},若当前梯度的方向与历史梯度一致（表明当前样本不太可能为异常点）,则会增强这个方向的梯度,若当前梯度与历史梯方向不一致,则梯度会衰减.一种形象的解释是：我们把一个球推下山,球在下坡时积聚动量,在途中变得越来越快,mu可视为空气阻力,若球的方向发生变化,则动量会衰减.mu一般设置为 0.9, 0.99 等. 然而, 把 mu 理解为摩擦(或者加上其它的因素)更好. mu 的作用是在小球在山坡上滚动的过程中来降低小球的动能. Principle: 在梯度指向同一方向的维度,momentum项增加; 在梯度改变方向的维度,momentum项减少更新. features: 下降初期时,使用上一次参数更新,下降方向一致,乘上较大的mu能够进行很好的加速 下降中后期时,在局部最小值来回震荡的时候,gradient \leftarrow 0,mu使得更新幅度增大,跳出陷阱 在梯度改变方向的时候,mu能够减少更新 总而言之,momentum项能够在相关方向加速SGD,抑制振荡,从而加快收敛. Nesterov Momentum在小球向下滚动的过程中, 我们希望小球能够提前知道在哪些地方坡面会上升, 这样, 在遇到上升坡面之前, 小球就开始减速. 这方法就是 Nesterov Momentum. 与传统的 Momentum 稍有不同的方法, Nesterov Momentum 在凸优化中有较强的理论保证收敛, 并且,在实践中, Nesterov Momentum也比单纯的 Momentum 的效果要好. 核心思想是: 注意到 momentum 方法, 如果只看 mu * v 项, 那么, 当前的 x 经过 momentum 的作用会变成 x + mu * v. 因此, 可以把 x + mu * v 这个位置看做是当前优化的一个”展望”位置, 所以, 可以在 x + mu * v 求导, 而不是原始的x. 1234x_ahead = x + mu * v# evaluate dx_ahead (the gradient at x_ahead instead of at x)v = mu * v - learning_rate * dx_aheadx += v Decay learning rate在优化的过程中, 如果学习率设置的过大, 那么, 小球就会在山谷之间跳来跳去, 无法到达最低点, 如果是非常缓慢地降低学习速率, 那么, 虽然小球跳来跳去的现象会有缓解, 但是, 效果不明显, 浪费了计算资源, 而如果快速降低学习速率, 那么, 小球可能会很快到达一个(不是那么好的)局部最优点, 而不能到达一个更好的局部最优点. 通常, 在实验中有下面三种方法: Step decay: 每隔几个epoch减少一次learning rate, 一般是每运行5个epoch左右把learning rate减少一半, 或者是每隔20个epoch减少为原来的1/10. 然而,具体的learning rate 的调整方法还是要看网络的设计和模型. 另外, 还有一种方法是, 在训练的过程中观察training error和validation error, 当validation error不再减小的时候, 减小learning rate. Exponential decay 1/t decay Some variants with learning rate decaymomentum项是为了使梯度更新更加灵活, 有不同情况有针对性. 但是, 人工设置一些学习率总还是有些生硬, 接下来介绍几种自适应学习率的方法, 如Adagrad. Adagradsgd or Momentum 对于每一个参数w_i的训练都使用了相同的学习率learning rate. Adagrad算法能够在训练中自动的对learning rate进行调整, 对于出现频率较低参数采用较大的learning rate更新; 相反,对于出现频率较高的参数采用较小的learningrate更新. 因此, Adagrad非常适合处理稀疏数据. 123# Assume the gradient dx and parameter vector xcache += dx**2x += - learning_rate * dx / np.sqrt(cache + eps) cache的大小和gradient的大小相同, 记录的是每个参数的梯度的平方和. 之后,cache用来以element-wise的方式normalize参数的更新.我们可以看出：梯度较高的权重的有效 learning rate 会减小, 相应的梯度较低的权重的有效 learning rate 会增大.sqrt 操作非常重要,如果没有 sqrt 操作, 该算法的效果非常差. eps 用来避免出现除 0 错误的,一般设置为 10-4 到 10-8 之间. drawbacks: 因为公式中分母上会累加梯度平方, 这样在训练中持续增大的话, 会使学习率非常小, 甚至趋近无穷小. Adagrad的缺点是在训练的中后期, 分母上梯度平方的累加将会越来越大, 从而梯度趋近于0, 使得训练提前结束. 由公式可以看出, 仍依赖于人工设置一个全局学习率. AdadeltaAdaGrad 方法比较激进, 会过早结束优化过程, AdaDelta 的目的就是为了解决这个问题.在 AdaGrad 中对 learning rate 进行 normalize 的参数是使用之前所有时间得到的梯度的累积, AdaDelta 的思想是通过设置窗口 w, 只使用部分时间的梯度累积.AdaGrad的最初方案依然是对学习率进行自适应约束, 但是进行了计算上的简化. Adagrad会累加之前所有的梯度平方, 而Adadelta只累加固定大小的项, 并且也不直接存储这些项, 仅仅是近似计算对应的平均值:在实际使用中, 其算法并没有存储前 w 个梯度然后计算, 而是类似与 moving average 的方法. 在任意一个时间 t, 当前的 normalize 的参数是 t-1 时刻的参数和当前的梯度做加权求和. 原始Adadelta,还是依赖于全局学习率的,但是作者做了一定处理,经过近似牛顿迭代法之后, Adadelta已经不用依赖于全局学习率了. features: 训练初中期,加速效果不错,很快 训练后期,反复在局部最小值附近抖动 RMSPropRMSProp 对 AdaGrad 稍作改进, 是的算法不再像 AdaGrad 那么激进 它使用的是 moving average of squared gradients. 12cache = decay_rate * cache + (1 - decay_rate) * dx**2x += - learning_rate * dx / (np.sqrt(cache) + eps) AdamAdam(Adaptive Moment Estimation)是另一种自适应学习率的方法.Adam加上了bias校正和momentum,在优化末期,梯度更稀疏时,它比RMSprop稍微好点.它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率.Adam的优点主要在于经过偏置校正后,每一次迭代学习率都有个确定范围,使得参数比较平稳. 123m = beta1*m + (1-beta1)*dxv = beta2*v + (1-beta2)*(dx**2)x += - learning_rate * m / (np.sqrt(v) + eps) 该方法和 RMSProp 唯一的区别是 “smooth” 过程, 这里使用的是 m 来做 smooth 操作, 而不是使用原始的 gradient vector dx. 在实际应用中 ,Adam为最常用的方法,可以比较快地得到一个预估结果. features: 结合了Adagrad善于处理稀疏梯度和RMSprop善于处理非平稳目标的优点 对内存需求较小 为不同的参数计算不同的自适应学习率 也适用于大多非凸优化 - 适用于大数据集和高维空间 A short summary另外, 在数据比较稀疏的时候, adaptive的方法能得到更好的效果, 例如Adagrad, RMSprop, Adam 等. Adam方法也会比RMSprop方法收敛的结果要好一些.另外, 也可以尝试 SGD+Nesterov Momentum.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A Comparison of Distributed Machine Learning Platforms]]></title>
    <url>%2F2017%2F08%2F05%2Fa-comparison-of-distributed-machine%2F</url>
    <content type="text"><![CDATA[A summary from this blogand this paper. We categorize the distributed ML platforms under 3 basic design approaches: basic dataflow parameter-server model advanced dataflow. We talk about each approach in brief: using Apache Spark as an example of the basic dataflow approach PMLS (Petuum) as an example of the parameter-server model TensorFlow and MXNet as examples of the advanced dataflow model. SparkSpark enables in-memory caching of frequently used data and avoids the overhead of writing a lot of intermediate data to disk. For this Spark leverages on Resilient Distributed Datasets (RDD), read-only, partitioned collection of records distributed across a set of machines.RDDs are collection of objects divided in logical partitions that are stored and processed as in-memory, with shuffle/overflow to disk. In Spark, a computation is modeled as a directed acyclic graph (DAG), where each vertex denotes a RDD and each edge denotes an operation on RDD.On a DAG, an edge E from vertex A to vertex B implies that RDD B is a result of performing operation E on RDD A. There are two kinds of operations: transformations and actions. A transformation (e.g., map, filter, join) performs an operation on a RDD and produces a new RDD. A typical Spark job performs a couple of transformations on a sequence of RDDs and thenapplies an action to the latest RDD in the lineage of the whole computation. A Spark application runs multiple jobs in sequence or in parallel. A Spark cluster comprises of a master and multiple worker. A master is responsible for negotiating resource requests made by the Spark driver program corresponding to the submitted Spark application. Worker processes hold Spark executors (each of which is a JVM instance) that are responsible for executing Spark tasks. The driver contains two scheduler components, the DAG scheduler and the task scheduler. The DAG scheduler is responsible for stage-oriented scheduling, and the task scheduler is responsible for submitting tasks produced by the DAG scheduler to the Spark executors. The Spark user models the computation as a DAG which transforms &amp; runs actions on RDDs. The DAG is compiled into stages. Unlike the MapReduce framework that consists of only two computational stages, map and reduce, a Spark job may consist of a DAG of multiple stages. The stages are run in topological order. A stage contains a set of independent tasks which perform computation on partitions of RDDs. These tasks can be executed either in parallel or as pipelined. Spark defines two types of dependency relation that can capture data dependency among a set of RDDs: Narrow dependency. Narrow dependency means each partition of the parent RDD is used by at most one partition of the child RDD. Shuffle dependency (wide dependency). Wide dependency means multiple child partitions of RDD may depend on a single parent RDD partition. Narrow dependencies are good for efficient execution, whereas wide dependencies introduce bottlenecks since they disrupt pipelining and require communication intensive shuffle operations. Fault toleranceSpark uses the DAG to track the lineage of operations on RDDs. For shuffle dependency, the intermediate records from one stage are materialized on the machines holding parent partitions. This intermediate data is used for simplifying failure recovery. If a task fails, the task will be retried as long as its stage’s parents are stillaccessible. If some stages that are required are no longer available, the missing partitions will be re-computed in parallel. Spark is unable to tolerate a scheduler failure of the driver, but this can be addressed by replicating the metadata of the scheduler. The task scheduler monitors the state of running tasks and retries failed tasks. Sometimes, a slow straggler task may drag the progress of a Spark job. Machine learning on SparkSpark was designed for general data processing, and not specifically for machine learning. However, using the MLlib for Spark, it is possible to do ML on Spark. In the basic setup, Spark stores the model parameters in the driver node, and the workers communicate with the driver to update the parameters after each iteration. For large scale deployments, the model parameters may not fit into the driver and would be maintained as an RDD. This introduces a lot of overhead because a new RDD will need to be created in each iteration to hold the updated model parameters. Updating the model involves shuffling data across machines/disks, this limits the scalability of Spark. This is where the basic dataflow model (the DAG) in Spark falls short. Spark does not support iterations needed in ML well. PMLSPMLS was designed specifically for ML with a clean slate. It introduced the parameter-server (PS) abstraction for serving the iteration-intensive ML training process. In PMLS, a worker process/thread is responsible for requesting up to date model parameters and carrying out computation over a partition of data, and a parameter-server thread is responsible for storing and updatingmodel parameters and making response to the request from workers. Figure below shows the architecture of PMLS. The parameter server is implemented as distributed tables. All model parameters are stored via these tables. A PMLS application can register more than one table. These tables are maintained by server threads. Each table consists of multiple rows. Each cell in a row is identified by a column ID and typically stores one parameter. The rows of the tables can be stored across multiple servers on different machines. Workers are responsible for performing computation defined by a user on partitioned dataset in each iteration and need to request up to date parameters for its computation. Each worker may contain multiple working threads. There is no communication across workers. Instead, workers only communicate with servers. ‘’worker’’ and ‘’server’’ are not necessarily separated physically. In fact server threads co-locate with the worker processes/threads in PMLS. Error tolerance of ML algorithm.PMLS exploits the error-tolerant property of many machine learning algorithms to make a trade-off between efficiency and consistency. In order to leverage such error-tolerant property, PMLS follows Staleness Synchronous Parallel (SSP) model. In SSP model, worker threads can proceed without waiting for slow threads. Fast threads may carry out computation using stale model parameters. Performing computation on stale version of model parameter does cause errors, however these errors are bounded. The communication protocol between workers and servers can guarantee that the model parameters that a working thread reads from its local cache is of bounded staleness. Fault toleranceFault tolerance in PMLS is achieved by checkpointing the model parameters in the parameter server periodically. To resume from a failure, the whole system restarts from the last checkpoint. Programing interfacePMLS is written in C++. While PMLS has very little overhead, on the negative side, the users of PMLS need to know how to handle computation using relatively low-level APIs. TensorFlowTensorflow is the first generation distributed parameter-server system.In TensorFlow the computation is abstracted and represented by a directed graph. But unlike traditional dataflow systems, TensorFlow allows nodes to represent computations that own or update mutable state. Variable: a stateful operations, owns mutable buffer, and can be used to store model parameters that need to be updated at each iteration. Node: represents operations, and some operations are control flow operations. Tensors: values that flow along the directed edges in the TensorFlow graph, with arbitrary dimensionality matrices. An operation can take in one or more tensors and produce a result tensor. Edge: special edges called control dependencies can be added into TensorFlow’s dataflow graph with no data flowing along such edges. In summary, TensorFlow is a dataflow system that offers mutable state and allows cyclic computation graph, and as such enables training a machine learning algorithm with parameter-server model. ArchitectureThe Tensorflow runtime consists of three main components: client, master, worker. client: is responsible for holding a session where a user can define computational graph to run. When a client requests the evaluation of a Tensorflow graph via a session object, the request is sent to master service. master: schedules the job over one or more workers and coordinates the execution of the computational graph. worker: Each worker handles requests from the master and schedules the execution of the kernels (The implementation of an operation on a particular device is called a kernel) in the computational graph. The dataflow executor in a worker dispatches the kernels to local devices and runs the kernels in parallel when possible. CharacteristicsNode PlacementIf multiple devices are involved in computation, a procedure called node placement is executed in a Tensorflowruntime. Tensorflow uses a cost model to estimate the cost of executing an operation on all available devices (such as CPUs and GPUs) and assigns an operation to a suitable device to execute, subject to implicit or explicit device constraints in the graph. Sub-graph executionTensorFlow supports sub-graph execution. A single round of executing a graph/sub-graph is called a step. A training application contains two type of jobs: parameter server (ps) job and worker job. Like data parallelism in PMLS, TensorFlow’s data parallelism training involves multiple tasks in a worker job training the same model on different minibatches of data, updating shared parameters hosted in a one or more tasks in a ps job. A typical replicated training structure: between-graph replication There is a separate client for each worker task, typically in the same process as the worker task. Each client builds a similar graph containing the parameters (pinned to ps) and a single copy of the compute-intensive part of the computational graph that is pinned to the local task in the worker job. For example, a compute-intensive part is to compute gradient during each iteration of stochastic gradient descent algorithm. Users can also specify the consistency model in the betweengraph replicated training as either synchronous training or asynchronous training: In asynchronous mode, each replica of the graph has an independent training loop that executes without coordination. In synchronous mode, all of the replicas read the same values for the current parameters, compute gradients in parallel, and then apply them to a stateful accumulators which act as barriers for updating variables. Fault toleranceTensorFlow provides user-controllable checkpointing for fault tolerance via primitive operations: save writes tensors to checkpoint file, and restore reads tensors from a checkpointing file.TensorFlow allows customized fault tolerance mechanism through its primitive operations, which provides users the ability to make a balance between reliability and checkpointing overhead. MXNETSimilar to TensorFlow, MXNet is a dataflow system that allows cyclic computation graphs with mutable states, and supports training with parameter server model. Similar to TensorFlow, MXNet provides good support for data-parallelism on multiple CPU/GPU, and also allows model-parallelism to be implemented.MXNet allows both synchronous and asynchronous training. CharacteristicsFigure below illustrates main components of MXNet. The runtime dependency engine analyzes the dependencies in computation processes and parallelizes the computations that are not dependent. On top of runtime dependency engine, MXNet has a middle layer for graph and memory optimization. Fault toleranceMXNet supports basic fault tolerance through checkpointing, and provides save and load model operations. The save operaton writes the model parameters to the checkpoint file and the load operation reads model parameters from the checkpoint file. Evaluations]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[An Introduction to the Linux Terminal]]></title>
    <url>%2F2017%2F08%2F03%2Funix-introduce-unix%2F</url>
    <content type="text"><![CDATA[. IntroductionThe ShellIn a Linux system, the shell is a command-line interface that interprets a user’s commands and script files, and tells the server’s operating system what to do with them. There are several shells that are widely used, such as Bourne shell (sh) and C shell (csh). Each shell has its own feature set and intricacies, regarding how commands are interpreted, but they all feature input and output redirection, variables, and condition-testing, among other things. The Command PromptWhen you first login to a server, you will typically be greeted by the Message of the Day (MOTD), which is typically an informational message that includes miscellaneous information such as the version of the Linux distribution that the server is running. After the MOTD, you will be dropped into the command prompt, or shell prompt, which is where you can issue commands to the server. The information that is presented at the command prompt can be customized by the user, but here is an example of the default Ubuntu 14.04 command prompt: 1sammy@webapp:~$ Here is a breakdown of the composition of the command prompt: sammy: The username of the current user. webapp: The hostname of the server. ~: The current directory. In bash, which is the default shell, the ~, or tilde, is a special character that expands to the path of the current user’s home directory; in this case, it represents /home/sammy. $: The prompt symbol. This denotes the end of the command prompt, after which the user’s keyboard input will appear. Note that the symbol that ends the command prompt is a #, which is the standard prompt symbol for root. Executing CommandsCommands can be issued at the command prompt by specifying the name of an executable file, which can be a binary program or a script. An instance of a running command is known as a process. When a command is executed in the foreground, which is the default way that commands are executed, the user must wait for the process to finish before being returned to the command prompt, at which point they can continue issuing more commands. Note that almost everything in Linux is case-sensitive, including file and directory names, commands, arguments, and options. Without Arguments or OptionsTo execute a command without any arguments or options, simply type in the name of the command and hit RETURN.If you run a command like this, it will exhibit its default behavior, which varies from command to command. With ArgumentsMany commands accept arguments, or parameters, which can affect the behavior of a command.For example, cd. With OptionsMost commands accept options, also known as flags or switches, that modify the behavior of the command. As they are special arguments, options follow a command, and are indicated by a single - character followed by one or more options, which are represented by individual upper- or lower-case letters. Additionally, some options start with --, followed by a single, multi-character (usually a descriptive word) option. With Options and ArgumentsOptions and arguments can almost always be combined, when running commands. Environment VariablesEnvironment variables are named values that are used to change how commands and processes are executed. When you first log in to a server, several environment variables will be set according to a few configuration files by default. View All Environment VariablesTo view all of the environment variables that are set for a particular terminal session, run the env command:1env There will likely be a lot of output, but try and look for PATH entry:1PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games The PATH environment variable is a colon-delimited list of directories where the shell will look for executable programs or scripts when a command is issued. For example, the env command is located in /usr/bin, and we are able to execute it without specifying its fully-qualified location because its path is in the PATH environment variable. View the Value of a VariableThe value of an environment variable can be retrieved by prefixing the variable name with a $. Doing so will expand the referenced variable to its value. For example, to print out the value of the PATH variable, you may use the echo command:1echo $PATH Setting Environment VariablesNow that you know how to view your environment variables, you should learn how to set them. To set an environment variable, all you need to do is start with a variable name, followed immediately by an = sign, followed immediately by its desired value:1VAR=value Note that if you set an existing variable, the original value will be overwritten. If the variable did not exist in the first place, it will be created. Bash includes a command called export which exports a variable so it will be inherited by child processes. In simple terms, this allows you to use scripts that reference an exported environment variable from your current session. You can also reference existing variables when setting a variable. For example, if you installed an application to /opt/app/bin you could add that directory to the end of your PATH environment variable with this command: 1export PATH=$PATH:/opt/app/bin Now verify that /opt/app/bin has been added to the end of your PATH variable with echo:1echo $PATH Keep in mind that setting environment variables in this way only sets them for your current session. This means if you log out or otherwise change to another session, the changes you made to the environment will not be preserved. Basic Linux Navigation and File Management pwd ls cd viewing files less more head tail File and Directory Manipulation touch mkdir mv cp rm rmdir]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[An Introduction to Linux I/O Redirection]]></title>
    <url>%2F2017%2F08%2F03%2Funix-io-redirection%2F</url>
    <content type="text"><![CDATA[. IntroductionThe redirection capabilities built into Linux provide you with a robust set of tools used to make all sorts of tasks easier to accomplish. Whether you’re writing complex software or performing file management through the command line, knowing how to manipulate the different I/O streams in your environment will greatly increase your productivity. StreamsInput and output in the Linux environment is distributed across three streams. These streams are: standard input (stdin), numbered 0 standard output (stdout), numbered 1 standard error (stderr), numbered 2 During standard interactions between the user and the terminal, standard input is transmitted through the user’s keyboard. Standard output and standard error are displayed on the user’s terminal as text. Collectively, the three streams are referred to as the standard streams. Standard InputThe standard input stream typically carries data from a user to a program. Programs that expect standard input usually receive input from a device, such as a keyboard. Standard input is terminated by reaching EOF (end-of-file). As described by its name, EOF indicates that there is no more data to be read. After opening cat, type a series of numbers as it is running. When you type a number and press enter, you are sending standard input to the running cat program, which is expecting said input. In turn, the cat program is sending your input back to the terminal display as standard output. EOF can be input by the user by pressing ctrl-d. After the cat program receives EOF, it stops. Standard OutputStandard output writes the data that is generated by a program. When the standard output stream is not redirected, it will output text to the terminal. When used without any additional options, the echo command displays any argument that is passed to it on the command line. An argument is something that is received by a program. Run echo without any arguments, and it will return an empty line, since there are no arguments. Standard ErrorStandard error writes the errors generated by a program that has failed at some point in its execution. Like standard output, the default destination for this stream is the terminal display. When a program’s standard error stream is piped to a second program, the piped data (consisting of program errors) is simultaneously sent to the terminal as well. Stream RedirectionLinux includes redirection commands for each stream. These commands write standard output to a file. If a non-existent file is targetted (either by a single-bracket or double-bracket command), a new file with that name will be created prior to writing. overwrite: Commands with a single bracket overwrite the destination’s existing contents. &gt;: standard output &lt;: standard input 2&gt;: Append: Commands with a double bracket do not overwrite the destination’s existing contents. &gt;&gt;: standard output &lt;&lt;: standard input 2&gt;&gt;: standard error PipesPipes are used to redirect a stream from one program to another. When a program’s standard output is sent to another through a pipe, the first program’s data, which is received by the second program, will not be displayed on the terminal. Only the filtered data returned by the second program will be displayed. The Linux pipe is represented by a vertical bar.1*|* An example of a command using a pipe:12345$ ls | lessDataDesktopDocuments(END) This takes the output of ls, which displays the contents of your current directory, and pipes it to the less program. less displays the data sent to it one line at a time. ls normally displays directory contents across multiple rows. When you run it through less, each entry is placed on a new line. Though the functionality of the pipe may appear to be similar to that of &gt; and &gt;&gt; (standard output redirect), the distinction is that pipes redirect data from one command to another, while &gt; and &gt;&gt; are used to redirect exclusively to files. FiltersFilters are commands that alter piped redirection and output. Note that filter commands are also standard Linux commands that can be used without pipes. find: Find returns files with filenames that match the argument passed to find. grep: Grep returns text that matches the string pattern passed to grep. tee: Tee redirects standard input to both standard output and one or more files. tr: tr finds-and-replaces one string with another. wc: wc counts characters, lines, and words. Examplescommand &gt; fileThis pattern redirects the standard output of a command to a file.1ls ~ &gt; root_dir_contents.txt command &gt; /dev/null/dev/null is a special file that is used to trash any data that is redirected to it. It is used to discard standard output that is not needed, and that might otherwise interfere with the functionality of a command or a script. Any output that is sent to /dev/null is discarded. 1ls &gt; /dev/null This command discards the standard output stream returned from the command ls by passing it to /dev/null. command 2&gt; fileThis pattern redirects the standard error stream of a command to a file, overwriting existing contents.1mkdir &apos;&apos; 2&gt; mkdir_log.txt This redirects the error raised by the invalid directory name ‘’, and writes it to log.txt. Note that the error is still sent to the terminal and displayed as text. command &gt;&gt; fileThis pattern redirects the standard output of a command to a file without overwriting the file’s existing contents.12echo Written to a new file &gt; data.txtecho Appended to an existing file&apos;s contents &gt;&gt; data.txt This pair of commands first redirects the text inputted by the user through echo to a new file. It then appends the text received by the second echo command to the existing file, without overwriting its contents. command 2&gt;&gt; fileThe pattern above redirects the standard error stream of a command to a file without overwriting the file’s existing contents. This pattern is useful for creating error logs for a program or service, as the log file will not have its previous content wiped each time the file is written to.12find &apos;&apos; 2&gt; stderr_log.txtwc &apos;&apos; 2&gt;&gt; stderr_log.txt The above command redirects the error message caused by an invalid find argument to a file named stderr_log.txt. It then appends the error message caused by an invalid wc argument to the same file. command | commandRedirects the standard output from the first command to the standard input of the second command.1find /var lib | grep deb This command searches through /var and its subfolders for filenames and extensions that match the string deb, and returns the file paths for the files, with the matching portion in each path highlighted in red. command | tee fileThis pattern (which includes the tee command) redirects the standard output of the command to a file and overwrites its contents. Then, it displays the redirected output in the terminal. It creates a new file if the file does not already exist. In the context of this pattern, tee is typically used to view a program’s output while simultaneously saving it to a file.1wc /etc/magic | tee magic_count.txt This pipes the counts for characters, lines, and words in the magic file (used by the Linux shell to determine file types) to the tee command, which then splits wc’s output in two directions, and sends it to the terminal display and the magic_count.txt file. command | command | command &gt;&gt; fileThis pattern predirects the standard output of the first command and filters it through the next two commands. It then appends the final result to a file.1ls ~ | grep *tar | tr e E &gt;&gt; ls_log.txt]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[An Introduction to Linux Permission and Some Basics Usages]]></title>
    <url>%2F2017%2F08%2F03%2Funix-permission%2F</url>
    <content type="text"><![CDATA[. IntroductionLinux is a multi-user OS that is based on the Unix concepts of file ownership and permissions to provide security, at the file system level. About UsersLinux is a multi-user system. We must understand the basics of Linux users and groups before we can talk about ownership and permissions, because they are the entities that the ownership and permissions apply to. In Linux, there are two types of users: system users. system users are used to run non-interactive or background processes on a system. regular users. regular users used for logging in and running processes interactively. When you first log in to a Linux system, you may notice that it starts out with many system users that run the services that the OS depends on–this is completely normal. An easy way to view all of the users on a system is to look at the contents of the /etc/passwd file. Each line in this file contains information about a single user, starting with its user name (the name before the first :). Print the passwd file with this command. We have the output below:123456789101112&gt;&gt; cat /etc/passwdroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/bin/shbin:x:2:2:bin:/bin:/bin/shsys:x:3:3:sys:/dev:/bin/shsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/bin/shman:x:6:12:man:/var/cache/man:/bin/shlp:x:7:7:lp:/var/spool/lpd:/bin/shmail:x:8:8:mail:/var/mail:/bin/shnews:x:9:9:news:/var/spool/news:/bin/shuucp:x:10:10:uucp:/var/spool/uucp:/bin/sh SuperuserIn addition to the two user types, there is the superuser, or root user, that has the ability to override any file ownership and permission restrictions. In practice, this means that the superuser has the rights to access anything on its own server. It is also possible to configure other user accounts with the ability to assume “superuser rights”. In fact, creating a normal user that has sudo privileges for system administration tasks is considered to be best practice. About GroupsGroups are collections of zero or more users. A user belongs to a default group, and can also be a member of any of the other groups on a server. An easy way to view all the groups and their members is to look in the /etc/group file on a server. Viewing Ownership and PermissionsIn Linux, each and every file is owned by a single user and a single group, and has its own access permissions. The most common way to view the permissions of a file is to use ls with the long listing option, e.g., ls -l myfile. Below is an example screen shot of what the output might look like, with labels of each column of output: Note that each file’s mode (which contains permissions), owner, group, and name are listed. Aside from the Mode column, this listing is fairly easy to understand. Understanding ModeLet’s take a look at this closeup of the mode of the first file in the example above: File TypeIn Linux, there are two basic types of files: normal and special.The file type is indicated by the first character of the mode of a file. Normal files can be identified by files with a hyphen (-) in their file type fields. Normal files are just plain files that can contain data. They are called normal, or regular, files to distinguish them from special files. Special files can be identified by files that have a non-hyphen character, such as a letter, in their file type fields, and are handled by the OS differently than normal files. The character that appears in the file type field indicates the kind of special file a particular file is. A directory, which is the most common kind of special file, is identified by the d character that appears in its file type field. Permissions ClassesFrom the diagram, we know that Mode column indicates the file type, followed by three triads, or classes, of permissions: user (owner), group, and other. Let’s look at which users belong to each permissions class: User: The owner of a file belongs to this class Group: The members of the file’s group belong to this class Other: Any users that are not part of the user or group classes belong to this class. Reading Symbolic PermissionsIn each triad, read, write, and execute permissions are represented in the following way: Read: Indicated by an r in the first position Write: Indicated by a w in the second position Execute: Indicated by an x in the third position. In some special cases, there may be a different character here. A hyphen (-) in the place of one of these characters indicates that the respective permission is not available for the respective class. For example, if the group triad for a file is r--, the file is “read-only” to the group that is associated with the file. Understanding Read, Write, Execute Read: For a normal file, read permission allows a user to view the contents of the file. For a directory, read permission allows a user to view the names of the file in the directory. Write: For a normal file, write permission allows a user to modify and delete the file. For a directory, write permission allows a user to delete the directory, modify its contents (create, delete, and rename files in it), and modify the contents of files that the user can read. Execute For a normal file, execute permission allows a user to execute a file (the user must also have read permission). As such, execute permissions must be set for executable programs and shell scripts before a user can run them. For a directory, execute permission allows a user to access, or traverse, into (i.e. cd) and access metadata about files in the directory (the information that is listed in an ls -l). Examples of Modes -rw-------: A file that is only accessible by its owner. -rwxr-xr-x: A file that is executable by every user on the system. A “world-executable” file. -rw-rw-rw-: A file that is open to modification by every user on the system. A “world-writable” file. drwxr-xr-x: A directory that every user on the system can read and access. drwxrwx---: A directory that is modifiable (including its contents) by its owner and group. drwxr-x---: A directory that is accessible by its group. As you may have noticed, the owner of a file usually enjoys the most permissions, when compared to the other two classes.Typically, you will see that the group and other classes only have a subset of the owner’s permissions (equivalent or less). Another thing to note is that even though many permissions combinations are possible, only certain ones make sense in most situations. For example, write or execute access is almost always accompanied by read access, since it’s hard to modify, and impossible to execute, something you can’t read. Modifying Ownership and PermissionsLinux permissions allow a file or directory owner to restrict access based on the accessor’s relationship to each file. This allows for control schemes that provide varying levels of access to different people. The umask command is used to determine the default permissions assigned to files created by each user.It can be modified to provide strict security restrictions or relaxed permissions for file sharing scenarios, depending on the needs of the system and user. Octal NotationThe more concise, but slightly less intuitive way of representing permissions is with octal notation. Using this method, each permissions category (owner, group owner, and other) is represented by a number between 0 and 7. We arrive at the appropriate number by assigning each type of permission a numerical value: 4 = read permissions 2 = write permissions 1 = execute permission We add up the numbers associated with the type of permissions we would like to grant for each category. This will be a number between 0 and 7 (0 representing no permissions and 7 representing full read, write, and execute permissions) for each category. For example, if the file owner has read and write permissions, this would be represented as a 6 in the file owner’s column. If the group owner requires only read permissions, then a 4 can be used to represent their permissions. Using the chmod to change the permission.Setting Defualt Permissions with UmaskThe umask command defines the default permissions for newly created files based on the “base” permissions set defined for files and directories. Files have a base permissions set of 666, or full read and write access for all users. Execute permissions are not assigned by default because most files are not made to be executed (assigning executable permissions also opens up some security concerns). Directories have a base permissions set of 777, or read, write, and execute permissions for all users. Umask operates by applying a subtractive “mask” to the base permissions shown above. We will use examples to demonstrate how this works. Example 1If we want the owner and members of the owner group to be able to write to newly created directories, but not other users, we would want to assign the permissions to 775. We need the three digit number that would express the difference between the base permissions and the desired permissions. That number is 002. 1234 777- 775------ 002 This resulting number is the umask value that we would like to apply.Coincidently, this is the default umask value for many systems. We can define a different umask using the umask command, and see Example 2. Example 2If we want to secure our system more, we can say that by default, we want users who are not the file owner to have no permissions at all. This can be accomplished with the 077 umask: 12345umask 077touch restrictedls -l restricted-rw------- 1 demouser demouser 0 Jul 10 18:33 restricted Example 3If we have a process that creates shared content, we may want give full permissions to every file and directory that it creates: 12345umask 000touch openfilels -l openfile-rw-rw-rw- 1 demouser demouser 0 Jul 10 18:36 openfile Effect of UmaskBy default, the settings you assign to umask will only apply to the current shell session. When you log in next time, any new files and directories will be give the original settings chosen by your distribution. If you would like to make your umask settings persist across sessions, you can define the umask settings in your .bashrc file umask 022.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to use casting iron pan]]></title>
    <url>%2F2017%2F07%2F24%2Fhow-to-use-casting-iron-pan%2F</url>
    <content type="text"><![CDATA[. 铸铁锅的好处 铸铁锅本身的特色是厚、重，用在烹饪过程中的好处就是导热和受热比较均匀，而且保温性比较好。同时既可以上明火，又可以进烤箱。对于习惯烤箱烹饪的老外来说这一点也挺重要的，所以铸铁锅在国外比较流行也是有原因的，直接在火上煎一下牛排之后再连锅端进烤箱烤，那个感觉还是挺爽的。 铸铁锅的密封性好，主要体现在煲汤不容易流失水分，这样能保证更加原汁原味。 另外保温性好这一点我也很喜欢，试想连锅端上桌的时候还是非常温热状态的菜肴，还是比较让人有胃口的。而且在做菜的时候也不需要一直熬煮特别久，可以利用保温性好这个特性来做一些节能的操作，比如煮一下然后关火焖一下之类的。 铸铁锅的另一个优势是锅壁厚，保热性好，同样在火上炖着一锅汤的不锈钢锅和铸铁锅，后者很少将热量散失到空气中，厨房也不至于因为炖个汤就热气腾腾。风靡欧美的免揉面包利用的正是这类铸铁锅强大的保热性：在高热的作用下，面团当中的空气急速膨胀，将面包顶高，同时形成美妙的焦脆外壳，面团中的各类麦粉也在美拉德反应下焦化释放出迷人的香气。烹饪也好，烘焙也好，都是热量和时间促成的美妙魔法。 何为锅气锅气说到底就是美拉德反应，西餐中类似的说法是patina：食物中的蛋白质脂肪等在高温下焦化形成美妙的香气和焦色的外壳，只有足够高的温度才能实现，这就需要将锅具烧热到高温；部分食材如完整的禽类、切成厚片或块状的肉类等更需要在进入锅之后锅本身保持温度不下降太多，炖煮也需要锅保持一个稳定的温度，将灶火的热能最大限度地传递给食材，加快食物的烹饪速度，而这是材质较薄的锅具无法实现的。 决定食物的质地味道的无非瞬时热量和持久温度这两个要素，铸铁锅在这两方面非常有优势。使用砂锅或者铸铁锅的人大概都有这种经验：一口不锈钢锅／薄铁锅在炉灶上加热，不需要靠很近就能感受到锅散发出来的热，大夏天里用不锈钢锅炖汤，整个厨房的温度会把做饭的人热成狗，而用铸铁锅就没有这种问题，铸铁锅的初用者不习惯这种差异，很容易烫到手，因为即使把手靠近锅，也几乎感觉不到散发出来的热量，这在别的锅来说是不可能的。这意味着炉火的热量能够最大效率地传递给锅内的食物，而不是像其他锅那样散失了，从这个角度上来说，也是很节能的。 做饭tips及厨具煎煎的食物要想保持内部丰富的汁水不在烹饪过程中流失，操作的要诀就是高温短时煎熟外皮，将汁水锁在食材內，这就需要锅具能够达到高温。 相对于汤汤水水的煲汤和炖粥的“水”类料理，煎这种料理方式是一种偏向“油”的做法，烹饪过程中锅内并不会长时间浸水和汤汁，不用担心锅内的铁质与食物发生反应，这对铁锅来说是比较有利的，因为减少了与水的接触，就降低了生锈的可能性，所以这类平底煎锅我推荐购买无涂层的纯铸铁锅，虽然新锅在开锅之后的头几次料理可能会粘，但正确养护的锅在这之后通常会越用越顺手。 炒快炒需要锅底圆滑保证食物能够顺利翻炒快熟减少水分流失，这几年一些西式锅具品牌也出了适合中餐快炒的wok，无涂层的圆底生铁锅（cast iron wok）大概是我们最熟悉的铸铁锅了。 无论是生铁锅还是熟铁锅，都只适合汤水较少的中式快炒，如果做汤的话就不推荐这类锅了，材质太薄对炖汤来说容易受热不均，如果长期炖煮各类酸性食材（酸菜、醋、番茄等）也容易破坏锅内生成的不粘层，炖藕和山药这类食材也容易变黑，影响成品美观。这两类锅的养护方式同上述的平底煎锅，基本原则就是不适宜长时间炖汤或储存隔夜汤汁，也有一类浅汤锅，如braiser和soup pot，这两类锅常见的内壁是黑白珐琅，这类铸铁锅的用法和养护都更接近下述的深汤锅dutch oven。 炖dutch oven其实并不单指铸铁材质，基本上所有的平底＋双把手的中小型的汤锅都可以称为dutch oven。在西式料理当中，一口铸铁锅就可以完成煎炒到炖煮的全过程，那道非常刷逼格的经典法式料理红酒牛肉，就是在这种锅当中先放油把生牛肉煎出焦脆外壳，再翻炒洋葱胡萝卜番茄等发散出菜的香气，最后加入红酒高汤，小火炖上几个小时。中式料理当中的各种红烧菜，如红烧肉、麻辣猪手、红烧排骨等，也很适合用这类锅。只要一开始炒的时候火候不出错（中火即可）就绝对不会糊锅，就算锅底有一些焦色，只需要加入一些料酒或者酒醋用木铲稍刮一下就可以去除，这样deglazing更可以把炒出来的香味和颜色都融入汤里。而这些正是薄底的各类不锈钢汤锅无法实现的。 其他铸铁锅的使用方法跟普通不锈钢锅类似，因为储热效果非常好且导热均匀，所以大部分时间只要开节能的中小火即可。可以做的菜也很丰富，比如各类杂粮甜粥、粤式咸粥糖水、各类荤素热汤、红烧、盐焗烟熏、蒸煮烩烤和煎炸菜等，除了常规的煎牛排、红酒烩牛肉、奶油蘑菇汤这类西餐菜之外，盐焗虾、咖喱鸡、啤酒鸭、红烧肉、糖醋排骨、鲫鱼豆腐汤、雪梨银耳羹、皮蛋瘦肉粥、蒸荷叶鸡、绿豆汤、红豆沙、茶香鸭、煎黄鱼、烤猪手、腊味饭等等，统统不在话下，我还见到有人用这种铸铁锅做焦糖爆米花、新疆馕和贴锅玉米饼子的……真的是没有做不到只有想不到。 先说铸铁锅子吧：特别结实厚重，带来的性能上的优点是储热性能好，预热时间比一般炒菜锅子长许多，但预热完成后能够保持稳定热度，放入生鲜食物后不会温度骤降，比较适合用来做需要极高温烹调的食物或者极小火炖煮类。比如，有道名菜叫焦黑鲶鱼就是用烧到白热化的生铸铁锅，可以快速做出焦黑的酥皮，但内里仍然鲜嫩。铸铁牛排锅子煎牛排同理。也有许多面包达人用铸铁锅代替石板来烤欧式面包，在预热好的铸铁锅中放入面团，再一起放入烤箱，能够让烤箱保持高温，面筋在高温下快速茁壮成长，可以形成理想的面包组织。至于小火的么，最常用的就是慢炖类的菜，也有人用来贴玉米饼。拿来贴玉米饼的话，感觉就和山东杂粮煎饼、天津煎饼的大铁盖子，上海生煎的厚平底锅，西北烙锅盔的厚底锅如出一辙了。 使用如何开锅打开包装后，移除产品上的标签。用热水冲洗后晾干。在锅内刷上薄薄一层植物油。用小火加热数分钟，然后用布抹去残余的油。在使用初期可多次重复这个步骤。 如果是黑珐琅，装7-8分满的水，放在炉火上中小火加热到沸腾。将锅里的沸水倒掉，锅子降温后用温水再冲一次。接着将锅里外擦干净，放回炉上用最小火加热，待果子温温热时，倒入少许菜油，用厨房纸抹净，然后小火加热到油被吸进去即可。 如何保养日常使用不能让锅内外温差太大。比如从冰箱取出后，直接加热，或者热锅冲冷水冲洗。珐琅会因为热胀冷缩而容易出现龟裂，进而会让铸铁外露产生生锈的情况。所以冷锅冷油中小火慢慢加热，烹煮后的热锅稍微放凉后用温热水清洗，以及炉火不大过锅底。 切记不能干烧或者过度加热锅，不但容易导致珐琅脱落龟裂，也容易让锅内的食物沾锅。 养成习惯中用中小火热锅跟烹调。因为铸铁的材质储热效果佳，通过可以在锅内食物煮滚后，将火关小，中小火即可达到最均匀的加热和最佳的烹调效果。有时候也可以在锅内食物已保持微微沸腾的状态时，不开盖然后关火，不但会有闷烧的效果，还可以减排。 黑珐琅预热2-3分钟后加热油，再加上适当的养锅，就有不沾的效果。白珐琅冷锅倒入冷油才开始加热，之后才开始料理。 养锅清洗 使用温水配合清洁剂，以及非研磨性质的海绵或塑料刷来清洗。 如果产品上残留任何食物残渣，不要使用磨蚀性产品，去污粉，或者钢丝球，仅需在热水中浸泡，或者在产品中加热少量含清洁剂的水，即可去除残留。 用干净的抹布擦拭锅具，确保在存放前其已完全晾干。 黑珐琅一般不需要清洁剂，使用后稍微用水冲干净，再用热水浸泡片刻，接着用海绵刷洗即可。 对于粘在锅底的锅巴，我们有如下处理方式： 沾在锅底不易清洗的锅巴，先浸泡温热的小苏打水然后静置数小时，是沾黏物或烧焦物软化后，用海绵刷洗就可以了。 清除锅巴的锅底通常会带点焦黑泛黄的颜色，这时候将一颗柠檬对切，然后放入装有7分满水的锅中，中小火煮沸。接着倒干净再用海绵及温热水擦出清洁。 硅胶铲勺／木勺（必需品）金属铲勺容易刮伤珐琅层，虽然有些品牌宣称可以直接用金属铲子做菜，但真的把几百上千块的铸铁锅买回家我相信你会很乐于顺手买一把木铲来爱护锅子的。不推荐一些尼龙塑料材质的铲子，不耐热也不耐用，超市里的木铲竹铲就很好用，不小心烫黑了也不会出来奇怪的臭味。 安全锅垫（必需品）因为铸铁锅真的非常烫，直接放在木桌上会烫坏桌面，热锅放在大理石台面上也容易伤锅。一些品牌也有出高大上的铸铁磁铁锅垫，价格也很高大上。质量够好的杂货店超市价位的木头竹子硅胶垫就够用了，一定要足够耐热，曾经铸铁锅烫坏了我一副从大创买的棉线棉花手套，普通质量的硅胶手套也烫软过。 隔热手套（必需品）做好一锅菜的铸铁锅徒手根本无法拿，在家烘焙的人应该都有这种烤箱用的隔热手套。要省钱就上抹布。不过真把铸铁锅买回家你就会觉得用厨房里那块油腻腻的抹布来垫把手真的太暴殄天物了。苹果手机都买了，咋还用在地摊买的几块钱一个的手机壳呢是吧。 如何做菜做饭水滚了之后开小火，煮25分钟后关火，再焖10-15分钟，中途不要掀锅盖。煮出来的饭真的很香很香。]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Cooking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python, how to pass variable by reference]]></title>
    <url>%2F2017%2F07%2F21%2Fpython-how-to-pass-variable-by-reference%2F</url>
    <content type="text"><![CDATA[.]]></content>
      <categories>
        <category>Job</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python, class and object]]></title>
    <url>%2F2017%2F07%2F21%2Fpython-class-object%2F</url>
    <content type="text"><![CDATA[From blog. Everything is An ObjectWhat is a class?Simply a logical grouping of data and functions (the latter of which are frequently referred to as “methods” when defined within a class). logical grouping:A class can contain any data we’d like it to, and can have any functions (methods) attached to it that we please. Rather than just throwing random things together under the name “class”, we try to create classes where there is a logical connection between things. Many times, classes are based on objects in the real world.Other times, classes are based on concepts in our system. Regardless, classes are a modeling technique; a way of thinking about programs. When you think about and implement your system in this way, you’re said to be performing Object-Oriented Programming. “Classes” and “objects” are words that are often used interchangeably, but they’re not really the same thing. So Everything Has A Class?Classes can be thought of as blueprints for creating objects. We have the example code below: 12345678910111213141516171819202122232425262728class Customer(object): """A customer of ABC Bank with a checking account. Customers have the following properties: Attributes: name: A string representing the customer's name. balance: A float tracking the current balance of the customer's account. """ def __init__(self, name, balance=0.0): """Return a Customer object whose name is *name* and starting balance is *balance*.""" self.name = name self.balance = balance def withdraw(self, amount): """Return the balance remaining after withdrawing *amount* dollars.""" if amount &gt; self.balance: raise RuntimeError('Amount greater than available balance.') self.balance -= amount return self.balance def deposit(self, amount): """Return the balance remaining after depositing *amount* dollars.""" self.balance += amount return self.balance The class Customer(object) line does not create a new customer. That is, just because we’ve defined a Customer doesn’t mean we’ve created one; we’ve merely outlined the blueprint to create a Customer object. To do so, we call the class’s __init__ method with the proper number of arguments. So, to use the “blueprint” that we created by defining the class Customer, we call the class name alomst as if it were a function:1jeff = Customer(&apos;Jeff Knupp&apos;, 1000.0) The jeff object, known as an instance, is the realized version of the Customer class.Before we called Customer(), no Customer object existed. selfself is the instance of the Customer that withdraw is being called on. We have def withdraw(self, amount):, and jeff.withdraw(100.0) is just shorthand for Customer.withdraw(jeff, 100.0), which is perfectly valid (if not often seen) code. __init__When we call __init__, we’re in the process of creating an object. Python allows us to extend the self pattern to when objects are constructed as well, even though it doesn’t exactly fit.Just imagine that jeff = Customer(&#39;Jeff Knupp&#39;, 1000.0) is the same as calling jeff = Customer(jeff, &#39;Jeff Knupp&#39;, 1000.0); the jeff that’s passed in is also made the result. Be careful what you __init__:we need to ensure the instancejeff is a fully-initialized object.The rule of thumb is, don’t introduce a new attribute outside of the __init__ method, otherwise you’ve given the caller an object that isn’t fully initialized.This is part of a larger concept of object consistency: there shouldn’t be any series of method calls that can result in the object entering a state that doesn’t make sense. Invariants should hold both when a method is entered and when it is exited. It should be impossible for an object to get into an invalid state just by calling its methods. It goes without saying, then, that an object should start in a valid state as well, which is why it’s important to initialize everything in the __init__ method. Instance Attributes and MethodsAn function defined in a class is called a “method”. Methods have access to all the data contained on the instance of the object; they can access and modify anything previously set on self.Because they use self, they require an instance of the class in order to be used. For this reason, they’re often referred to as instance methods. There are other types of methods as well. Static MethodsClass attributes are attributes that are set at the class-level, as opposed to the instance-level.Normal attributes are introduced in the __init__ method, but some attributes of a class hold for all instances in all cases. We have example below:12345678910111213class Car(object): wheels = 4 def __init__(self, make, model): self.make = make self.model = modelmustang = Car(&apos;Ford&apos;, &apos;Mustang&apos;)print mustang.wheels# 4print Car.wheels# 4 A Car always has four wheels, regardless of the make or model. Instance methods can access these attributes in the same way they access regular attributes: through self (i.e. self.wheels). There is a class of methods, though, called static methods, that don’t have access to self. Just like class attributes, they are methods that work without requiring an instance to be present.Since instances are always referenced through self, static methods have no self parameter. The following would be a valid static method on the Car class for its sound.No matter what kind of car we have, it always makes the same sound.1234class Car(object): ... def make_car_sound(): print &apos;VRooooommmm!&apos; To make it clear that this method should not receive the instance as the first parameter (i.e. self on “normal” methods), the @staticmethod decorator is used, turning our definition into:12345class Car(object): ... @staticmethod def make_car_sound(): print &apos;VRooooommmm!&apos; Class MethodsA variant of the static method is the class method. Instead of receiving the instance as the first parameter, it is passed the class. It, too, is defined using a decorator:12345class Vehicle(object): ... @classmethod def is_motorcycle(cls): return cls.wheels == 2 Class methods may not make much sense right now, but that’s because they’re used most often in connection with our next topic: inheritance. InheritanceInherticance is the process by which a “child” class derives the data and behavior of a “parent” class. One of the most important rules of programming (in general, not just when dealing with objects) is “DRY” or “Don’t Repeat Yourself”. And by using inheritance, we can avoid most of this. Abstract ClassesAbstract Base Classes (ABC) are classes that are only meant to be inherited from; you can’t create instance of an ABC. So how do we make a class an ABC? The abc module contains a metaclass called ABCMeta.Setting a class’s metaclass to ABCMeta and making one of its methods virtual makes it an ABC.A virtual method is one that the ABC says must exist in child classes, but doesn’t necessarily actually implement. We have an example below:1234567891011121314151617181920212223from abc import ABCMeta, abstractmethodclass Vehicle(object): __metaclass__ = ABCMeta base_sale_price = 0 def sale_price(self): """Return the sale price for this vehicle as a float amount.""" if self.sold_on is not None: return 0.0 # Already sold return 5000.0 * self.wheels def purchase_price(self): """Return the price for which we would pay to purchase the vehicle.""" if self.sold_on is None: return 0.0 # Not yet sold return self.base_sale_price - (.10 * self.miles) @abstractmethod def vehicle_type(): """"Return a string representing the type of vehicle this is.""" pass Since vehicle_type is an abstractmethod, we can’t directly create an instance of Vehicle.As long as other class inherit from Vehicle and define vehicle_type, we can instantiate those classes just fine. Inheritance and the LSP]]></content>
      <categories>
        <category>Job</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A summary of Bit Manipulation]]></title>
    <url>%2F2017%2F07%2F19%2Fbit-manipulation%2F</url>
    <content type="text"><![CDATA[From leetcode Bit manipulation is the act of algorithmically manipulating bits or other pieces of data shorter than a word.We have bitwise operations: AND, OR, XOR, NOT, and bit shifts. Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel, but the code can become more difficult to write and maintain. DetailsBasicsAt the heart of bit manipulation are the bit-wise operators &amp; (and), | (or), ~ (not) and ^ (exclusive-or, xor) and shift operators a &lt;&lt; b and a &gt;&gt; b. There is no boolean operator counterpart to bitwise exclusive-or, but there is a simple explanation. The exclusive-or operation takes two inputs and returns a 1 if either one or the other of the inputs is a 1, but not if both are. That is, if both inputs are 1 or both inputs are 0, it returns 0. Bitwise exclusive-or, with the operator of a caret, ^, performs the exclusive-or operation on each pair of bits. Exclusive-or is commonly abbreviated XOR. Set union A | B Set intersection A &amp; B Set negation ALL_BITS ^ A or ~A Set subtraction A &amp; ~B Set bit A | (1 &lt;&lt; bit) Clear bit A &amp; ~(1 &lt;&lt; bit) Test bit (A &amp; 1 &lt;&lt; bit) != 0 Extract last bit A &amp; -A or A &amp; ~(A - 1) or A ^ ( A &amp; (A - 1) ) Remove last bit A &amp; (A - 1) ExamplesCount the number of ones in the binary representation of the given number: 1234567def count_one(n): count = 0 while n: # remove last bit. n = n &amp; (n - 1) count += 1 return count Is power of four (actually map-checking, iterative and recursive methods can do the same): 123def is_power_of_four(n): # check the 1-bit location return ! (n &amp; (n - 1)) and (n &amp; 0x55555555) # 5 =&gt; 0101 Tricks^ tricksUse ^ to remove even exactly same numbers and save the odd, or save the distinct bits and remove the same. ExamplesSum of Two Integers: Use ^ and &amp; to add two integers 12def get_sum(a, b): return a if b == 0 else get_sum(a ^ b, (a &amp; b) &lt;&lt; 1) Missing Number: Given an array containing n distinct numbers taken from 0, 1, 2, ..., n, find the one that is missing from the array. For example, Given nums = [0, 1, 3] return 2. (Of course, you can do this by math.) 123456def missing_number(nums): ret = 0 for ind, num in enumerate(nums): ret ^= ind ret ^= num return ret ^= len(nums) | tricksKeep as many 1-bits as possible. ExamplesFind the largest power of 2 (most significant bit in binary form), which is less than or equal to the given number N. 12345678def largest_power(N): # changing all right side bits to 1. N = N | (N &gt;&gt; 1) N = N | (N &gt;&gt; 2) N = N | (N &gt;&gt; 4) N = N | (N &gt;&gt; 8) N = N | (N &gt;&gt; 16) return (N + 1) &gt;&gt; 1 Reverse bits of a given 32 bits unsigned integer. 12345678910111213141516171819def reverse_bits_1(n): res = 0 mask = 1 &lt;&lt; 31 for i in range(32): if (n &amp; 1): res |= mask mask &gt;&gt;= 1 n &gt;&gt;= 1 return resdef reverse_bits_2(n): ret = 0 mask = 1 for i in range(32): ret &lt;&lt;= 1 if (mask &amp; n): ret |= 1 mask &lt;&lt;= 1 return ret &amp; tricksJust selecting certain bits ExamplesReversing the bits in integer (confused.) 12345x = ((x &amp; 0xaaaaaaaa) &gt;&gt; 1) | ((x &amp; 0x55555555) &lt;&lt; 1)x = ((x &amp; 0xcccccccc) &gt;&gt; 2) | ((x &amp; 0x33333333) &lt;&lt; 2)x = ((x &amp; 0xf0f0f0f0) &gt;&gt; 4) | ((x &amp; 0x0f0f0f0f) &lt;&lt; 4)x = ((x &amp; 0xff00ff00) &gt;&gt; 8) | ((x &amp; 0x00ff00ff) &lt;&lt; 8)x = ((x &amp; 0xffff0000) &gt;&gt; 16) | ((x &amp; 0x0000ffff) &lt;&lt; 16) Bitwise AND of Numbers Range: Given a range [m, n] where 0 &lt;= m &lt;= n &lt;= 2147483647, return the bitwise AND of all numbers in this range, inclusive. For example, given the range [5, 7], you should return 4. 1234567def range_bitwise_and(m, n): a = 0 while m != n: m &gt;&gt;= 1 n &gt;&gt;= 1 a += 1 return m &lt;&lt; a Number of 1 Bits: Write a function that takes an unsigned integer and returns the number of 1 bits it has (also known as the Hamming weight). 123456789101112131415def hamming_weight_1(n): count = 0 while n: n = n &amp; (n - 1) count += 1 return countdef hamming_weight_2(n): mask = 1 count = 0 for i in range(32): if mask &amp; n: count += 1 mask &lt;&lt;= 1 return count]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How the size of batch size impact on the learning effect.]]></title>
    <url>%2F2017%2F07%2F18%2Fimpact-of-batch-size%2F</url>
    <content type="text"><![CDATA[From Zhihu. Batch 的选择，首先决定的是下降的方向。如果数据集比较小，可以采用全数据集(Full Batch Learning)，这样有两个好处： 由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。 这样理论上是可以得到全局收敛的 可以用一些加速收敛算法，比如L-BFGS之类的 便于并行计算但是同样存在缺点：如果数据集过大，训练会很慢的 但对于更大的数据，以上2个好处又变成两个坏处： 随着数据集的海量增加和内存限制，一次性载入所有的数据进来变得越来越不可行。 收敛速度是比较快，但比较容易陷入局部最小情况。太大的batch size 容易陷入sharp minima，泛化性不好。 既然Full Batch Learning 并不适用大数据，那么我们走向了另一个极端，即，每次只训练一个样本，即Batch Size = 1，即online learning。他有如下优点： 每个采样上的参数修正方向会与整体最优的方向有出入。这条看似是个缺点，实际上，DNN因为是非线性模型，有很多参数，现有目标函数会有很多局部极值，这就会导致模型不精确。 Full Batch Learning方法每次修正依赖于现有模型和所有数据，很难跳出这些局部极值，所以Full Batch Learning方法是一种很依赖于初始模型的方法。 Online learning方法基于每个采样去修正，修正幅度大了以后，就容易跳出这些局部极值，避免过拟合发生。该方法一般不依赖于初始模型，所以可以用来训练初始的神经网络。 速度比Full Batch Learning快。 但同时又有如下缺点： 难以并行计算 因为每次更新基于单个采样，很容易导致难以收敛。这个发生原因和优点1 是一样的。这种现象有时是优点有时也是缺点，主要取决于学习率的选择。 线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元，非线性网络，在具备依然近似是抛物面。使用在线学习，每次修正方向以各自样本的梯度方向修正，横冲直撞，难以达到收敛。 于是我们选择了一个适中的Batch Size (Mini-batches Learning)。如果数据集足够充分，那么用部分数据训练得出的梯度与用全部数据训练出来的梯度几乎是一样的。 在合理范围内，增大Batch Size有如下好处： 内存利用率提高了，大矩阵乘法的并行化效率提高。 跑完一次epoch (全数据集)所需的迭代次数减少，对于相同数据量的处理速度进一步加快。 在一定范围内，一般来说，Batch Size 越大，其确定的下降方向越准，引起训练震荡越小。 批训练的引入最大好处是针对非凸损失函数来做的，毕竟非凸的情况下，全样本就算工程上算的动，也会卡在局部优上，批表示了全样本的部分抽样实现，相当于人为引入修正梯度上的采样噪声，使“一路不通找别路”更有可能搜索最优值。 小batch size引入的随机性会更大些，有时候能有更好的效果，但是收敛速度比较慢。 盲目增大Batch Size 有何坏处？ 内存利用率提高了，但是内存容量可能撑不住了。 跑完一次epoch所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。 Batch Size增大到一定程度，其确定的下降方向已经基本不再变化。 但值得注意的是：随着batch normalization的普及，收敛速度已经不像前bn时代一样需要比较玄学的调参，现在一般还是采用大batch size。但bn的坏处就是不能用太小的batch size，不然mean和variance就偏了。 Tradeoff batch size v.s. number of iterationsRef 1From On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima. The stochastic gradient descent method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, usually 32–512 data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a significant degradation in the quality of the model, as measured by its ability to generalize. The paper presents ample numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions – and that sharp minima lead to poorer generalization.In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. These minimizers are characterized by large positive eigenvalues in ∇^2 f(x) and tend to generalize less well. In contrast, small-batch methods converge to flat minimizers characterized by small positive eigenvalues of ∇^2 f(x). We have observed that the loss function landscape of deep neural networks is such that large-batch methods are almost invariably attracted to regions with sharp minima and that, unlike small batch methods, are unable to escape basins of these minimizers. Ref 2Some good insights from Ian Goodfellow answering to why do not use the whole training set to compute the gradient? on Quora: The size of the learning rate is limited mostly by factors like how curved the cost function is. You can think of gradient descent as making a linear approximation to the cost function, then moving downhill along that approximate cost. If the cost function is highly non-linear (highly curved) then the approximation will not be very good for very far, so only small step sizes are safe. Please check the Chapter 4 of the deep learning textbook for more details. When you put m examples in a minibatch, you need to do O(m) computation and use O(m) memory, but you reduce the amount of uncertainty in the gradient by a factor of only O(sqrt(m)). In other words, there are diminishing marginal returns to putting more examples in the minibatch. Please check the Chapter 8 of the deep learning textbook for more details. Also, if you think about it, even using the entire training set doesn’t really give you the true gradient. The true gradient would be the expected gradient with the expectation taken over all possible examples, weighted by the data generating distribution. Using the entire training set is just using a very large minibatch size, where the size of your minibatch is limited by the amount you spend on data collection, rather than the amount you spend on computation. Ref 3We are talk about ‘reducing the batch size in a mini batch stochastic gradient descent algorithm’ V.S. ‘larger batch sizes requiring fewer iterations’. Let’s take the two extremes cases: Each gradient descent step is using the entire dataset. You’re computing the gradients for every sample. In this case you know exactly the best directly towards a local minimum. You don’t waste time going the wrong direction. So in terms of numbers gradient descent steps, you’ll get there in the fewest. A batch size of just 1 sample. The gradient of that sample may take you completely the wrong direction. But the cost of computing the one gradient was quite trivial. As you take steps with regard to just one sample you “wander” around a bit, but on the average you head towards the same local minimum as in full batch gradient descent. In terms of computational power, while the single-sample stochastic GD process takes many many more iterations, you end up getting there for less cost than the full batch mode, “typically.” We might realize that: modern BLAS libraries make computing vector math quite efficient, so computing 10 or 100 samples at once, presuming you’ve vectorized your code properly, will be barely more work than computing 1 sample (you gain memory call efficiencies as well as computational tricks built into most efficient math libraries). averaging over a batch of 10, 100, 1000 samples is going to produce a gradient that is a more reasonable approximation of the true, full batch-mode gradient. our steps are now more accurate, meaning we need fewer of them to converge, and at a cost that is only marginally higher than single-sample GD. Ref 4: batch size related to hardwareOpinion 1: In general GPUs offer the best performance when they are computing matrix operations over large contiguous matrices. Larger batch sizes yield larger input/data matrices and thus better performance. There is nothing special about powers of two for batchsizes. You can use the maximum batchsize that fits on your GPU/RAM to train it so that you utilize it to the fullest. The entire point of batchwise training is that the training is fast and minibatch noise is added to SGD, both of these have no relation to “powers of two” batch size. Note that image resized to power of two makes sense (because pooling is generally done in 2X2 windows), but that’s a different thing altogether. Opinion 2: The deep learning book indicates that some kinds of harware achieve better runtime with sepcific size of arrays. Especially when using GPUs, it is common for power of 2 batch sizes to offer better runtime. Someone indicates that powers of 2 have some advantages with regards to vectorized operations in certain packages.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python, member of a class]]></title>
    <url>%2F2017%2F07%2F11%2Fpython-member-of-a-class%2F</url>
    <content type="text"><![CDATA[. Example 1Code: 1234567891011121314151617181920class Listener: artists = [] def __init__(self, id): self.id = id def addArtist(self, artist, plays): print self.id # debugging... print &quot;pre: &quot;, self.artists self.artists.append(artist) print &quot;post: &quot;, self.artistsdef debug(): listeners = &#123;&#125; listeners[&quot;0&quot;] = Listener(&quot;0&quot;) listeners[&quot;1&quot;] = Listener(&quot;1&quot;) listeners[&quot;0&quot;].addArtist(&quot;The Beatles&quot;, 10) listeners[&quot;0&quot;].addArtist(&quot;Lady Gaga&quot;, 4) listeners[&quot;1&quot;].addArtist(&quot;Ace of Base&quot;, 5) Results: 1234567890pre: []post: [&apos;The Beatles&apos;]0pre: [&apos;The Beatles&apos;]post: [&apos;The Beatles&apos;, &apos;Lady Gaga&apos;]1pre: [&apos;The Beatles&apos;, &apos;Lady Gaga&apos;]post: [&apos;The Beatles&apos;, &apos;Lady Gaga&apos;, &apos;Ace of Base&apos;] Example 2If you don’t want the members declared inside the class, but just set in the __init__ method: 12345678910class Listener: def __init__(self, id): self.id = id self.artists = [] def addArtist(self, artist, plays): print self.id # debugging... print &quot;pre: &quot;, self.artists self.artists.append(artist) print &quot;post: &quot;, self.artists If you have a class like12class A: x=5 Then x is a member of the class and not a member of instances of that class. This can be confusing, since python lets you access class members through the instance:123456789101112&gt;&gt;&gt; a=A()&gt;&gt;&gt; print a.x5&gt;&gt;&gt; print A.x5&gt;&gt;&gt; a1=A()&gt;&gt;&gt; a2=A()&gt;&gt;&gt; a1.x=6&gt;&gt;&gt; print a1.x6&gt;&gt;&gt; print a2.x5 but what has actually happened is that you’ve put a new x into the a1 instance, which will be printed instead of the class member, which still has its original value:12&gt;&gt;&gt; print A.x5 You only start to see a difference when you have something that can be changed, like a list:12345678910111213141516class A: l=[]&gt;&gt;&gt; a1=A()&gt;&gt;&gt; print a1.l[]&gt;&gt;&gt; a2=A()&gt;&gt;&gt; print a2.l[]&gt;&gt;&gt; a1.l.append(5)&gt;&gt;&gt; print a1.l[5]&gt;&gt;&gt; print a2.l[5]&gt;&gt;&gt; print A.l[5]]]></content>
      <categories>
        <category>Job</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to control overfitting]]></title>
    <url>%2F2017%2F06%2F18%2Fhow-to-control-overfitting%2F</url>
    <content type="text"><![CDATA[organized from 机器学习中用来防止过拟合的方法有哪些？. what is overfitting过拟合是指在模型参数拟合过程中的问题，由于训练数据包含抽样误差，训练时，复杂的模型将抽样误差也考虑在内，将抽样误差也进行了很好的拟合。 具体的表现就是最终模型在训练集上效果好;在训练集上效果差。模型泛化能力差。 why we need to address overfitting我们拟合的模型一般是用来预测未知的结果，过拟合虽然在训练集上效果好，但在实际使用时效果差。同时，在很多问题上，我们无法穷尽所有状态，不可能将所有情况都包含在训练集上。所以必须要解决过拟合问题。 why it is common in Machine Learning?机器学习算法为了满足尽可能复杂的人物，其模型的拟合能力一般远远高于问题复杂度。也就是说，机器学习算法具有你何处正确规则的情况下，进一步拟合噪声的能力。 而传统的函数拟合问题，一般通过经验，物理，数学推导出一个含参模型，模型复杂度确定了，只需要调整个别参数即可。 how to address overfitting 获得更多数据 只要给足够多的数据，让模型看见尽可能多的例外情况，他就会不断修正自己，从而得到更好的结果。 如何获得更多数据： 从数据源头获取更多的数据 根据当前数据集估计数据分布参数，使用该分布产生更多数据 数据增强(data augmentation): 通过一定规则扩充数据 使用合适的模型 过拟合主要由两个原因造成：数据太少，以及模型太复杂。我们可以通过使用合适复杂度的模型来防止过拟合问题，让其足够拟合真正的规则，同时又不至于拟合太多抽样误差。 如何限制网络能力： 网络结构 early stopping: 当网络权值较小时，神经元的激活函数工作在线性区，此时神经元的拟合能力较弱。初始化网络时，一般使用较小的权值。训练时间越长，部分网络的权值就可能越大。如果在合适的时间停止训练，就可以将网络的能力限制在一定范围内。 weight-decay,本质是regularization 增加噪声 在输入中加噪声。 在输入中加入高斯噪声，会在输出中生成\sum_i \sigma_i^2 w_i^2的干扰项。训练时，见效误差，同时也会对噪声产生的干扰项进行惩罚，达到减小权值的平方的目的，达到L2 regularization 类似的效果。 在权值上加噪声 在初始化网络的时候，用0均值的高斯分布作为初始化 使用多种模型 训练多种模型，以每个模型的平均输出作为结果。从N个模型里随机选择一个作为输出的期望误差&lt;[t - y_i]^2&gt;,会比所有模型的平均输出的误差&lt;[t-\bar{y}]^2&gt;大。 方法们: Bagging： 用不同的模型拟合不同部分的训练集。 Boosting Dropout: 相当于随即从2^H的模型中采样选择模型。此外，由于每个网络只见过一个训练数据（每次都是随即的新网络），所以类似bagging的做法。此外，不同模型之间权值共享，相当于一种权值正则方法，实际效果比L2 regularization更好。]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[single-cpu and multi-cpu in multi-threads programs]]></title>
    <url>%2F2017%2F06%2F14%2Fsingle-cpu-and-multi-cpu-in-multi-threads-programs%2F</url>
    <content type="text"><![CDATA[. 多线程在单核和多核CPU上的执行效率问题的讨论* 多线程在单cpu中其实也是顺序执行的，不过系统可以帮你切换那个执行而已，其实并没有快(反而慢)。多个cpu的话就可以在两个cpu中同时执行了.............. * 单核CPU上运行的多线程程序, 同一时间只能一个线程在跑, 系统帮你切换线程而已, 系统给每个线程分配时间片来执行, 每个时间片大概10ms左右, 看起来像是同时跑, 但实际上是每个线程跑一点点就换到其它线程继续跑。效率不会有提高的，切换线程反倒会增加开销。 * 一般没有必要的话，尤其在单核CPU的时候，不推荐使用多线程。单核CPU时使用多线程，通常是有线程要处于等待状态。而对于普通的进度条更新类的，能够简单控制的（比如：在循环里面手动处理消息）就简单控制，一般不使用线程，这样可以提高程序的性能。并且避免掉不必要的线程同步问题。 * 算法同样时，CPU占用率达到100%的最小线程数效率最高，如果是cpu占率率高的运算单核单线程，双核双线程，四核四线程是最适合的。但为什么有时候线程数超过CPU内核数会更快呢？原因是这种程序的单个线程运算量不足以占满CPU一个内核（比如存在大量IO操作，IO比较慢，是程序瓶颈）。 * 多线程的用处在于，做某个耗时的操作时，需要等待返回结果，这时用多线程可以提高程序并发程度。如果一个不需要任何等待并且顺序执行能够完成的任务，用多线程简直是浪费。 * 线程必然不是越多越好，线程切换也是要开销的，当你增加一个线程的时候，增加的额外开销要小于该线程能够消除的阻塞时间，这才叫物有所值。 什么时候该使用多线程呢？这要分四种情况讨论： 多核CPU——计算密集型任务。此时要尽量使用多线程，可以提高任务执行效率，例如加密解密，数据压缩解压缩（视频、音频、普通数据），否则只能使一个核心满载，而其他核心闲置。 单核CPU——计算密集型任务。此时的任务已经把CPU资源100%消耗了，就没必要也不可能使用多线程来提高计算效率了；相反，如果要做人机交互，最好还是要用多线程，避免用户没法对计算机进行操作。 单核CPU——IO密集型任务，使用多线程还是为了人机交互方便。 多核CPU——IO密集型任务，这就更不用说了，跟单核时候原因一样。 程序员需要掌握的技巧/技术 减少串行化的代码用以提高效率。 单一的共享数据分布化：把一个数据复制很多份，让不同线程可以同时访问。 负载均衡，分为静态的和动态的两种。]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Parallel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dilated conv example in Tensorflow]]></title>
    <url>%2F2017%2F06%2F14%2Ftensorflow-dilated-conv-example%2F</url>
    <content type="text"><![CDATA[. FunctionThe following content presents an example of how to do dilated convolution in Tensorflow.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263def conv1d_s(input, output_channels, filter_width, num_layer): """1d convolution (zero-pad k-1 elements on the right of input). Use pad to ensure convolution will not read future feature. Args: input: [batch_size, in_width, in_channels] """ batch_size, in_width, in_channels = input.get_shape().as_list() w = get_scope_variable( 'conv_&#123;&#125;'.format(num_layer), 'w', shape=[filter_width, in_channels, output_channels], initializer=tf.contrib.layers.variance_scaling_initializer( factor=4.0, uniform=False) ) b = get_scope_variable( 'conv_&#123;&#125;'.format(num_layer), 'b', shape=output_channels, initializer=tf.random_uniform_initializer() ) return tf.nn.conv1d(input, w, stride=1, padding='SAME') + bdef time_to_batch(value, dilation): with tf.name_scope('time_to_batch'): batch_size, in_width, in_channels = value.get_shape().as_list() pad_elements = dilation - 1 - (in_width + dilation - 1) % dilation padded = tf.pad(value, [[0, 0], [0, pad_elements], [0, 0]]) reshaped = tf.reshape(padded, [-1, dilation, in_channels]) transposed = tf.transpose(reshaped, perm=[1, 0, 2]) return tf.reshape(transposed, [batch_size * dilation, -1, in_channels])def batch_to_time(value, dilation): with tf.name_scope('batch_to_time'): batch_size, in_width, in_channels = value.get_shape().as_list() prepared = tf.reshape(value, [dilation, -1, in_channels]) transposed = tf.transpose(prepared, perm=[1, 0, 2]) return tf.reshape(transposed, [batch_size / dilation, -1, in_channels])def dilated_conv_with_pad( input, output_channels, dilation, num_layer, filter_width=1, causal=False): """dilated convolution.""" batch_size, in_width, in_channels = input.get_shape().as_list() if causal: padding = [[0, 0], [(filter_width - 1) * dilation, 0], [0, 0]] padded = tf.pad(input, padding) else: padding = [ [0, 0], [(filter_width-1)*dilation/2, (filter_width-1)*dilation/2], [0, 0]] padded = tf.pad(input, padding) if dilation &gt; 1: transformed = time_to_batch(padded, dilation) conv = conv1d_s( transformed, output_channels, filter_width, num_layer) restored = batch_to_time(conv, dilation) else: restored = conv1d_s( padded, output_channels, filter_width, num_layer) result = tf.slice(restored, [0, 0, 0], [-1, in_width, -1]) return result ExampleAlso, the following example shows how function like time_to_batch() and batch_to_time() work in practice when dilation size equals to 2. Assume we have12[[1, 2, 3, 4],[5, 6, 7, 8]] Then, in time_to_batch() function, we first let reshaped = tf.reshape(padded, [-1, dilation, in_channels]), where we have1234[[1, 2],[3, 4],[5, 6],[7, 8]] We then do the transposed = tf.transpose(reshaped, perm=[1, 0, 2]), where12[[1, 3, 5, 7],[2, 4, 6, 8]] After that, we do the reshape again tf.reshape(transposed, [batch_size * dilation, -1, in_channels]), and get the result:1234[[1, 3],[5, 7],[2, 4],[6, 8]] We will then do 1-d convolution operation on this result,1234[[1&apos;, 3&apos;],[5&apos;, 7&apos;],[2&apos;, 4&apos;],[6&apos;, 8&apos;]] After that, we move to batch_to_time() function and have the following transformation:1234567891011# prepared = tf.reshape(value, [dilation, -1, in_channels])[[1&apos;, 3&apos;, 5&apos;, 7&apos;],[2&apos;, 4&apos;, 6&apos;, 8&apos;]]# transposed = tf.transpose(prepared, perm=[1, 0, 2])[[1&apos;, 2&apos;],[3&apos;, 4&apos;],[5&apos;, 6&apos;],[7&apos;, 8&apos;]]# tf.reshape(transposed, [batch_size / dilation, -1, in_channels])[[1&apos;, 2&apos;, 3&apos;, 4&apos;],[5&apos;, 6&apos;, 7&apos;, 8&apos;]]]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Weight Initializer in Tensorflow]]></title>
    <url>%2F2017%2F06%2F13%2Ftensorflow-initializer%2F</url>
    <content type="text"><![CDATA[From Tensorflow API tf.random_normal_initializerInitializer that generates tensors with a normal distribution. 123456__init__( mean=0.0, stddev=1.0, seed=None, dtype=tf.float32) tf.truncated_normal_initializerInitializer that generates a truncated normal distribution. These values are similar to values from a random_normal_initializer except that values more than two standard deviations from the mean are discarded and re-drawn. 123456__init__( mean=0.0, stddev=1.0, seed=None, dtype=tf.float32) The benefit of using the truncated normal distribution is to prevent generating ‘’dead neurons’’ due to the relu_logits being used, which is explained here One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients. Since we’re using ReLU neurons, it is also good practice to initialize them with a slightly positive initial bias to avoid ‘’dead neurons’’. tf.random_uniform_initializerInitializer that generates tensors with a uniform distribution. 123456__init__( minval=0, maxval=None, # defaults to 1 for float types. seed=None, dtype=tf.float32) tf.uniform_unit_scaling_initializerInitializer that generates tensors without scaling variance. When initializing a deep network, it is in principle advantageous to keep the scale of the input variance constant, so it does not explode or diminish by reaching the final layer.If the input is x and the operation x * W, and we want to initialize W uniformly at random, we need to pick W from 1[-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)] to keep the scale intact, where dim = W.shape[0] (the size of the input). A similar calculation for convolutional networks gives an analogous result with dim equal to the product of the first 3 dimensions. When nonlinearities are present, we need to multiply this by a constant factor. 12345__init__( factor=1.0, seed=None, dtype=tf.float32) tf.contrib.layers.xavier_initializerReturns an initializer performing “Xavier” initialization for weights. 12345xavier_initializer( uniform=True, seed=None, dtype=tf.float32) This initializer is designed to keep the scale of the gradients roughly the same in all layers: In uniform distribution this ends up being the range: x = sqrt(6. / (in + out)); [-x, x] For normal distribution a standard deviation of sqrt(3. / (in + out)) is used. An simple example from Stackoverflow: 123456789101112131415161718192021222324def xavier_init(n_inputs, n_outputs, uniform=True): &quot;&quot;&quot;Set the parameter initialization using the method described. This method is designed to keep the scale of the gradients roughly the same in all layers. Xavier Glorot and Yoshua Bengio (2010): Understanding the difficulty of training deep feedforward neural networks. International conference on artificial intelligence and statistics. Args: n_inputs: The number of input nodes into each output. n_outputs: The number of output nodes for each input. uniform: If true use a uniform distribution, otherwise use a normal. Returns: An initializer. &quot;&quot;&quot; if uniform: # 6 was used in the paper. init_range = math.sqrt(6.0 / (n_inputs + n_outputs)) return tf.random_uniform_initializer(-init_range, init_range) else: # 3 gives us approximately the same limits as above since this repicks # values greater than 2 standard deviations from the mean. stddev = math.sqrt(3.0 / (n_inputs + n_outputs)) return tf.truncated_normal_initializer(stddev=stddev) tf.contrib.layers.variance_scaling_initializerReturns an initializer that generates tensors without scaling variance. 1234567variance_scaling_initializer( factor=2.0, mode=&apos;FAN_IN&apos;, uniform=False, # Whether to use uniform or normal distributed random initialization. seed=None, dtype=tf.float32) When initializing a deep network, it is in principle advantageous to keep the scale of the input variance constant, so it does not explode or diminish by reaching the final layer. This initializer use the following formula: 123456789101112if mode=&apos;FAN_IN&apos;: # Count only number of input connections. n = fan_inelif mode=&apos;FAN_OUT&apos;: # Count only number of output connections. n = fan_outelif mode=&apos;FAN_AVG&apos;: # Average number of inputs and output connections. n = (fan_in + fan_out) / 2.0if uniform: limit = math.sqrt(3.0 * factor / n) return tf.random_uniform(shape, -limit, limit)else: return tf.truncated_normal(shape, 0.0, stddev=sqrt(factor / n)) To get Delving Deep into Rectifiers, use (Default): factor=2.0 mode=&#39;FAN_IN&#39; uniform=False. To get Convolutional Architecture for Fast Feature Embedding: factor=1.0 mode=&#39;FAN_IN&#39; uniform=True To get Understanding the difficulty of training deep feedforward neural networks: factor=1.0 mode=&#39;FAN_AVG&#39; uniform=True]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[distributional representation and distributed representation]]></title>
    <url>%2F2017%2F06%2F13%2Fdistributional-representation-and-distributed-representation%2F</url>
    <content type="text"><![CDATA[from 聊聊文本的分布式表示： Distributional Representation和Distributed Representation的区别. 文本表示首先，我们先来看下什么是文本表示。文本表示，也可以称为语言表示，是对人类语言的一种描述或约定，是认知科学和人工智能等多个领域共同存在的问题。在认知科学里，语言表示是语言在人脑中的表现形式，关系到人类如何理解和产生语言。 语言具有一定的层次结构，并且可以划分为不同的语言粒度（比如，词、短语、句子、段落以及篇章）。这些不同的粒度文本都有相对应的表示。 文本分布式表示Distributional RepresentationDistributional Representation是从 分布式假设（即如果两个词的上下文相似，那么这两个词也是相似的）的角度，利用共生矩阵来获取词的语义表示，可以看成是一类获取词表示的方法。这里的“分布”带有统计上分布的意思。我们可以构建一个大小为W×C的共现矩阵F，其中W是词典大小，C是上下文数量。上下文的类型可以为相邻词、所在句子或所在的文档等。共现矩阵的每一行可以看作对应词的向量表示。基于共现矩阵，有很多方法来得到连续的词表示，比如潜在语义分析模型（Latent Semantic Analysis, LSA）、潜在狄利克雷分配模型（Latent Dirichlet Allocation，LDA）、随机索引（random indexing）等。 Distributed RepresentationDistributed Representation中的distributed 没有统计上的’’分布’’含义，而是’’分散’’、’’分配’’的意思。一段文本的语义分散在一个低维空间的不同维度上，相当于将不同的文本分散到空间中不用的区域。Distributed Representation是文本的一种表示形式，具体为稠密、低维、连续的向量。向量的每一维都表示文本的某种潜在的语法或语义特征。Distributed Representation翻译为分散式表示可能理解起来会更明确些。 我经常会以下面这幅围棋棋盘来说明是什么是Distributed Representation。以词为例，如果我们有100个词，相当于100个棋子。如果用onehot方式来表示，我们需要建立100维的空间。但是现在，我们只需要建立一个二维的空间，在里划分很多格子（格子数量大于100个），然后把这些棋子（词）分散地放在不同的格子上。格子的坐标代表了相应的棋子（词）的向量表示。这样就相当于在两维的空间中表示了100个棋子（词）。 区分这里需要强调一点的是，这种’’分散式表示’’只要在低维的空间中能够区分出两个词的不同就够了。不一定非得要求意义相近的词距离也相近。因为上层的神经网络可以具有高度非线性，完全可以将原始的表示空间高度扭曲。 从Distributed Representation本身来讲，我们不要给它附加太多的意义，比如要满足man-woman \simeq king - queen之类的。 Distributed Representation就是将文本分散在低维空间中的很多点上，只要这些点有一定区分性就够了。说得极端一点，我们的词向量都是随机产生的稠密向量，这也是一种distributed表示，不需要有语义上解释（比如分布式假设）。只要后续的模型足够强大，一样可以做的很好。 总之，Distributional Representation指的是一类获取文本表示的方法，而Distributed Representation指的是文本表示的形式，就是低维、稠密的连续向量。 但这两个并不对立。比如Skip-Gram、CBOW和glove等模型得到词向量，即是Distributional Representation，又是Distributed Representation。]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[One by One [ 1 x 1 ] Convolution - counter-intuitively useful]]></title>
    <url>%2F2017%2F05%2F30%2Fone-by-one-convolution%2F</url>
    <content type="text"><![CDATA[. Check the blog.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21 essential command line interface tools for Data Scientists]]></title>
    <url>%2F2017%2F05%2F24%2Fessential-cmd-for-data-scientist%2F</url>
    <content type="text"><![CDATA[The content below is borrowed from 21 essential command line interface tools for Data Scientists. Network TunnelTunnel from the network into the world V.S. Tunnel of the world into a network12345# Tunnel from the network into the worldssh -f -N -R 22:192.168.0.1:22 username@1.1.1.1# Tunnel of the world into a networkssh -f -N -L 80:192.168.0.1:80 username@1.1.1.1 -N: do not run a command remotely. It is used only when forwarding ports. -f: go to the background mode immediately after registration on the remote system. -R: perform remote redirection. When you call on the port of the remote machine, a SSH-tunnel will be set up, and the connection will be forwarded to the specified host port. -L: execute a local port forwarding. When you call the port of the local machine, then the host port of specified host will be created on the tunnel port. The difference: Tunnel from the network into the world: enter on the host 1.1.1.1 and gain access to the host 192.168.0.1. A very useful way to use ssh tunnels is this traffic encryption. For example, if you are using an open network, but you don’t want someone could intercept your data. Tunnel of the world into a network: enter the cmd on your host http://localhost:80 and gain access to a web host 192.168.0.1, which is located behind the host 1.1.1.1 Tunnel from the world into a network (reverse tunnel) is used in the situation, when you need to get on the machine, protected by a firewall or located behind NAT. The principle of operation is that the connection is initiated by the remote machine, and we fall back on ready-mix already. In such a tunnel, you can send any traffic, not only ssh. File SystemWork with files and foldersToo simple to omit. Permissions ls -al: view an access and ownership of all files / folders in the directory. chmod 777 file.sh: execute permissions of the file. chmod -R 777 dir_name: set access 777 recursively for all files in the folder. Owner / Group chown ubuntu:ubuntu file.txt: set an owner and group of the file file.txt. chown -R ubuntu:ubuntu dir_name: set an owner and group folders recursively. View disk space df -h: view space of all sections. du -sh dir_name/: get folder size. du -h dir_name/*: get folder size and the size of subdirectories. du -h filename: get the file size. File operation cat file_name: file output content. cat file_name1 file_name2 &gt; file_name3: file_name1 file_name2 merge into one file_name3 cat file_name* &gt; file_name_end: combine multiple files at the beginning of the file_name cat some_dir*/file_name* &gt; file_name_end: combine multiple files at the beginning of the file_name enclosed in a lot of directories beginning with some_dir. ./some_script.sh &gt; /paht/to/file.txt: redirecting output to overwrite file ./some_script.sh &gt;&gt; /path/to/file.txt: redirect output to append to a file some command &gt; /dev/null 2&gt;&amp;1: output the standard output (STDOUT) and the error stream (STDERR) in /dev/null Other useful commandsawkAnother useful tool for the text analysis of the files is awk. With its help, you can easily cope with any text files structure. Awk is a command of contextual search and text, e.g.,we can use awk to see when users connect and include via ssh using command: 1awk &apos;/sshd/ &amp;&amp; /pam_unix/ &#123;print ($1,$2,$3,$8,$11)&#125;&apos; /var/log/auth.log sed]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NCHW or NHWC Data Format in Tensorflow]]></title>
    <url>%2F2017%2F05%2F16%2Ftensorflow-NCHW-or-NHWC%2F</url>
    <content type="text"><![CDATA[. NCHW and NHWCCurrently Tensorflow supports NCHW and NHWC.Many of the Ops support both formats. That being said, the docs say: The best practice is to build models that work with both NCHW and NHWC as it is common to train using NCHW on GPU, and then do inference with NHWC on CPU. This requires the user to have to do some “wrangling” (e.g. loading the checkpoint of weights and re-buidling graph in Python) to map from one image format to another. TL; DR Many data scientists just want to write CNNs without thinking about tensor layouts. What is NCHW and NHWCGiven that convolutions (and other common image operations such as gradients) operate channel-wise, we prefer the memory to be contiguous with respect to pixels within a channel. Given that Python/numpy/C-style arrays use a default memory layout of row-major this means that the ‘correct’ memory layout is CHW for an image. Furthermore, if you want to include batches, it makes sense that the memory for an image would remain contiguous and thus the batches become the first axis to keep the image memory contiguous -&gt; NCHW. As an aside, if column-major/fortran ordering had ‘won out’ as the default layout as is common in Matlab, for example, the correct ordering would be HWC as is commonly seen in most image loading software. tl;dr Image memory needs to be contiguous within channels -&gt; GPU software expects this so it optimised for this use case.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduce to learning from demonstration]]></title>
    <url>%2F2017%2F04%2F19%2Fintroduce-to-learning-from-demonstration%2F</url>
    <content type="text"><![CDATA[. Robot Learning from Demonstration (LfD) is a paradigm for enabling robots to autonomously perform new tasks.The aim is for robot capabilities to be more easily extended and adapted to novel situations, even by users without programming ability. PrincipleThe main principle of robot is that end-users can teach robots new tasks without programming. In a traditional programming scenario, a human programmer would have to reason in advance and code a robot controller that is capable of responding to any situation the robot may face, no matter how unlikely. This process may involve breaking down the task into 100s of different steps, and thoroughly testing each step. If errors or new circumstances arise after the robot is deployed, the entire costly process may need to be repeated, and the robot recalled or taken out of service while it is fixed. In contrast, LfD allows the end-user to ‘program’ the robot simply by showing it how to perform the task - no coding required. Then, when failures occur, the end-user needs only to provide more demonstrations, rather than calling for professional help. Key issues in Programming by Demonstration What to imitate? (addressed) How to imitate? (addressed) When to imitate? Whom to imitate? What to imitateWhat to imitate relates to the problem of determining which aspects of the demonstration should be imitated. For a given task, certain observable or affectable properties of the environment may be irrelevant and safely ignored. Key to determining what is and is not important is understanding the metric by which the robot’s behavior is being evaluated. How to Imitate and the Notion of CorrespondenceHow to imitate consists in determining how the robot will actually perform the learned behaviors to maximize the metric found when solving the What to Imitate problem. This issue is closely related to that of the Correspondence Problem. Robots and humans, while inhabiting the same space and interacting with the same objects, and perhaps even superficially similar, still perceive and interact with the world in fundamentally different ways. To evaluate the similarity between the human and robot behaviors, we must first deal with the fact that the human and the robot may occupy different state spaces, of perhaps different dimensions. Perceptual equivalence Due to differences between human and robot sensory capabilities, the same scene may appear very different to each. Physical equivalence Due to differences between human and robot embodiments, humans and robots may perform different actions to accomplish the same physical effect.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Computer Vision</tag>
        <tag>Robotics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Difference between tf.nn.softmax and tf.nn.softmax_cross_entropy_with_logits]]></title>
    <url>%2F2017%2F03%2F27%2Fdifference-between-tf-nn-softmax-and-tf-nn-softmax-cross-entropy-with-logits%2F</url>
    <content type="text"><![CDATA[It is borrowed from stackoverflow. Suppose you have two tensors, where y_hat contains computed scores for each class and y_true contains one-hot encoded true labels. 12y_hat = ... # predicted label, e.g., y=tf.matmul(X, W) + b.y_true = ... # true label, one-hot encoded. If you interpret the scores in y_hat as unnormalized log probabilities, then they are logits. The total cross-entropy loss computed in this manner: 12y_hat_softmax = tf.nn.softmax(y_hat)total_loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), axis=1)) is essentially equivalent to the total cross-entropy loss computed with the function softmax_cross_entropy_with_logits(): 1total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true)) What is cross entropyIs the probability distribution in y_hat_softmax close to the probability distribution in y_true?We use cross-entropy loss to measure the error, where $H(p, q) = \sum_x p(x) \log q(x) = \E_p [- \log q] = H(p) + D_{KL}(p || q)$.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to use tensorboard on a remote server]]></title>
    <url>%2F2017%2F03%2F15%2Fuse-tensorboard-on-a-remote-server%2F</url>
    <content type="text"><![CDATA[From Stackoverflow. ssh into the remote through the following cmd: 1ssh -L 16006:127.0.0.1:6006 $&#123;HOST&#125; Then then launch tensorboard on the remote machine using a standard tensorboard --logdir &lt;log-dir&gt; with the default 6006 port. On your local machine, go to http://127.0.0.1:16006 and enjoy the remote tensorboard.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Why autoencoder-based method may fail when generating realistic sentences]]></title>
    <url>%2F2017%2F02%2F16%2Fwhy-autoencoder-based-method-may-fail-when-generating-realistic-sentences%2F</url>
    <content type="text"><![CDATA[. Autoencoder-based methods may fail when generating realistic sentences from arbitrary latent representations. The reason behind thisis that when mapping sentences to their hidden representations using an autoencoder, the representations of these sentences may often occupy a small region inthe hidden space. Thereby, most of regionsin the hidden space do not necessarily maps to a realistic sentence. Consequently, using a randomly generated hidden representation from a prior distribution would usually leads to implausible sentences. The paper Generating Sentences from a Continuous Space attempt to use a variational auto-encoding framework to ameliorate this problem, however in principle the posterior of the hidden variables would not cover the hidden space, rendering difficulties to randomly produce sentences.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What is the difference between 'SAME' and 'VALID' padding in TensorFlow]]></title>
    <url>%2F2017%2F01%2F04%2Fdifference-between-valid-padding-and-same-padding%2F</url>
    <content type="text"><![CDATA[. VALID = without padding: 123inputs: 1 2 3 4 5 6 7 8 9 10 11 (12 13) |______________| dropped |_______________| SAME = with zero padding: 12345 pad| |padinputs: 0 |1 2 3 4 5 6 7 8 9 10 11 12 13|0 0 |______________| |_______________| |_____________| In this case, we have: Input width = 13 Filter width = 6 Stride = 5 Notes: VALID only ever drops the right-most columns (or bottom-most rows). SAME tries to pad evenly left and right, but if the amount of columns to be added is odd, it will add the extra column to the right.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[recipe-menu]]></title>
    <url>%2F2016%2F12%2F26%2Frecipe-menu%2F</url>
    <content type="text"><![CDATA[.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Convert pdf to word in Ubuntu]]></title>
    <url>%2F2016%2F12%2F09%2Fubuntu-pdf2word%2F</url>
    <content type="text"><![CDATA[. Download Abiword from Ubuntu Software Center or you can install it by typing following command in terminal: 1sudo apt-get install abiword Then perform the conversion:1abiword --to=doc example.pdf]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Why use SGD in Deep Learning]]></title>
    <url>%2F2016%2F12%2F02%2Fwhy-use-sgd-in-deep-learning%2F</url>
    <content type="text"><![CDATA[Collect from In deep learning, why don’t we use the whole training set to compute the gradient?, nostly by the first answer. The size of the learning rate is limited mostly by factors like how curved the cost function is. You can think of gradient descent as making a linear approximation to the cost function, then moving downhill along that approximate cost. If the cost function is highly non-linear (highly curved) then the approximation will not be very good for very far, so only small step sizes are safe. You can read more about this in Chapter 4 of the deep learning textbook, on numerical computation. When you put m examples in a minibatch, you need to do O(m) computation and use O(m) memory, but you reduce the amount of uncertainty in the gradient by a factor of only O(sqrt(m)). In other words, there are diminishing marginal returns to putting more examples in the minibatch. You can read more about this in Chapter 8 of the deep learning textbook, on optimization algorithms for deep learning. Also, if you think about it, even using the entire training set doesn’t really give you the true gradient. The true gradient would be the expected gradient with the expectation taken over all possible examples, weighted by the data generating distribution. Using the entire training set is just using a very large minibatch size, where the size of your minibatch is limited by the amount you spend on data collection, rather than the amount you spend on computation.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Principle of Research Code]]></title>
    <url>%2F2016%2F11%2F22%2Fprinciple-of-research-code%2F</url>
    <content type="text"><![CDATA[From the blog,written by Charles Sutton. Principles of Research CodeProgramming for research is very different than programming for industry. There are several reasons for this, which I will call Principles of Research Code. These principles underly all of the advice in Ali’s post and in this post. These principles are: As a researcher, your product is not code. Your product is knowledge. Most of your research code you will completely forget once your paper is done. “Unless you hit it big. If your paper takes off, and lots of people read it, then people will start asking you for a copy of your code. You should give it to them, and best to be prepared for this in advance. You need to be able to trust your results. You want to do enough testing that you do not, e.g., find a bug in your baselines after you publish. A small amount of paranoia comes in handy. You need a custom set of tools. Do not be afraid to write infrastructure and scripts to help you run new experiments quickly. But don’t go overboard with this. Reproducability. Ideally, your system should be set up so that five years from now, when someone asks you about Figure 3, you can immediately find the command line, experimental parameters, and code that you used to generate it. Principle 1 implies that the primary thing that you need to optimise for in research code is your own time. You want to generate as much knowledge as possible as quickly as possible. Sometimes being able to write fast code gives you a competitive advantage in research, because you can run on larger problems. But don’t spend time optimising unless you’re in a situation like this. Also, I have some more practical suggestions to augment what Ali has said. These are Version control: Ali doesn’t mention this, probably because it is second nature to him, but you need to keep all of your experimental code under version control. To not do this is courting disaster. Good version control systems include SVN, git, or Mercurial, etc. I now use Mercurial, but it doesn’t really matter what you use. Always commit all of your code before you run an experiment. This way you can reproduce your experimental results by checking out the version of your code form the time that you ran an experiment. Random seeds: Definitely take Ali’s advice to take the random seed as a parameter to your methods. Usually what I do is pick a large number of random seeds, save them to disk, and use them over and over again. Otherwise debugging is a nightmare. Parallel option sweeps: It takes some effort to get set up on a cluster like ECDF, but if you invest this, you get some nice benefits like the ability to run a parameter sweep in parallel. Figures list. The day after I submit a paper, I add enough information to my notebook to meet Principle 5. That is, for every figure in the paper, I make a note of which output directory and which data file contains the results that made that figure. Then for those output directories, I make sure to have a note of which script and options generated those results. Data preprocessing. Lots of times we have some complicated steps to do data cleaning, feature extraction, etc. It’s good to save these intermediate results to disk. It’s also good to use a text format rather than binary, so that you can do a quick visual check for problems. One tip that I use to make sure I keep track of what data cleaning I do is to use Makefiles to run the data cleaning step. I have a different Makefile target for each intermediate result, which gives me instant documentation.]]></content>
      <categories>
        <category>Research</category>
      </categories>
      <tags>
        <tag>publication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[convert the format of nef to jpg]]></title>
    <url>%2F2016%2F10%2F18%2Fconvert-nef-to-jpg%2F</url>
    <content type="text"><![CDATA[. conver them in parallel. 1parallel convert &#123;&#125; &#123;.&#125;.jpg ::: *NEF]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git merge between branches]]></title>
    <url>%2F2016%2F10%2F13%2Fgit-merge-between-branches%2F</url>
    <content type="text"><![CDATA[. Merge some filesHow do you merge selective files with git-merge? How do I merge a sub directory in git? Change the current branch to master in git12345git checkout better_branchgit merge --strategy=ours master # keep the content of this branch, # but record a mergegit checkout mastergit merge better_branch # fast-forward master up to the merge If you want your history to be a little clearer, I’d recommend adding some information to the merge commit message to make it clear what you’ve done. Change the second line to: 12git merge --strategy=ours --no-commit mastergit commit # add information to the template merge message Delete local and remote branchDelete local branch1git branch -d branch_name The -d option is an alias for --delete, which only deletes the branch if it has already been fully merged in its upstream branch. You could also use -D, which is an alias for --delete --force, which deletes the branch ‘’irrespective of its merged status.’’ Delete Remote BranchAs of Git v1.7.0, you can delete a remote branch using1git push origin --delete &lt;branch_name&gt;]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rule for Capitalization in Title of Articles]]></title>
    <url>%2F2016%2F09%2F20%2Frule-for-capitalization-in-title-of-articles%2F</url>
    <content type="text"><![CDATA[If you have a look at the title of this article you will seethat some letters are capitalized and some are not.Although the capitalization of titles can sometimes depend on the particular style of a writer or publication, there are some general rules to remember. General Rule: Title CaseCapitalize the first, last, and any important words in a title, which is known as Title Case or Headline Style. In Titles: Do CapitalizeGenerally, these parts of speech are capitalized in titles. Nouns (man, bus, book) Adjective (angry, lovely, small) Verbs (run, eat, sleep) Adverbs (slowly, quickly, quietly) Pronouns (he, she, it) Subordinating conjunctions (as, because, that) In Title: Do not CapitalizeAs you have probably noticed “short” words, those with less than five letters, are generally lowercase in titles, unless they are the first or last words in a title. Generally, we do not capitalize: Articles: a, an, the Coordinating Conjunctions: and, but, or, for, nor, etc. Prepositions (fewer than five letters): on, at, to, from, by, etc. When in doubt and you do not have a reference guide in front of you, here is one general rule to remember recommended byThe U.S. Government Printing Office Style Manual: “Capitalize all words in titles of publications and documents, except a, an, the, at, by, for, in, of, on, to, up, and, as, but, or, and nor.”]]></content>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow, difference between name_scope and variable_scope]]></title>
    <url>%2F2016%2F09%2F11%2Ftensorflow-difference-between-name-scope-and-variable-scope%2F</url>
    <content type="text"><![CDATA[From stackoverflow When you create a variable with tf.get_variable instead of tf.Variable, Tensorflow will start checking the names of the vars created with the same method to see if they collide. If they do, an exception will be raised. If you created a var with tf.get_variable and you try to change the prefix of your variable names by using the tf.name_scope context manager, this won’t prevent the Tensorflow of raising an exception. Only tf.variable_scope context manager will effectively change the name of your var in this case. Or if you want to reuse the variable you should call scope.reuse_variables() before creating the var the second time. In summary, tf.name_scope just add a prefix to all tensor created in that scope (except the vars created with tf.get_variable), and tf.variable_scope add a prefix to the variables created with tf.get_variable.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cut and cat]]></title>
    <url>%2F2016%2F08%2F11%2Funix-cut-and-cat%2F</url>
    <content type="text"><![CDATA[. cutSelect Column of CharactersSelect Specific Column of CharactersTo extract only a desired column from a file use -c option. The example displays 2nd character from each line:$ cut -c2 test.txt. Select Column of Characters using RangeRange of characters can also be extracted from a file by specifying start and end position delimited with -. The example extracts first 3 characters of each line:cut -c1-3 test.txt. Select Column of Characters using either Start or End PositionEither start position or end position can be passed to cut command with -c option. The example extracts from 3rd character to end of each line:cut -c3- test.txt. The entire line would get printed when you don’t specify a number before or after the -: cut -c- test.txt. Select FieldSelect a Specific Field from a FileIf you like to extract a whole field, you can combine option -f and -d.The -f specifies which field you want to extract,and -d specifies what is the field delimiter that is used in the input file. The example displays only first field of each lines from /etc/passwd file using the field delimiter:. Select Multiple Fields from a FileBelow example displays username and home directory of users who has the login shell as /bin/bash: grep &quot;/bin/bash&quot; /etc/passwd | cut -d&#39;:&#39; -f1,6. To display the range of fields specify start field and end field as shown below:grep &quot;/bin/bash&quot; /etc/passwd | cut -d&#39;:&#39; -f1-4,6,7 Select Fields Only When a Line Contains the DelimiterThe following example specify the delimiter as |, and cut command simply displays the whole line, even when it doesn’t find any line that has | as delimiter: grep &quot;/bin/bash&quot; /etc/passwd | cut -d&#39;|&#39; -f1. It is possible to filter and display only the lines that contains the specified delimiter using -s option: grep &quot;/bin/bash&quot; /etc/passwd | cut -d&#39;|&#39; -s -f1. Select All Fields Except the Specified FieldsIn order to complement the selection field list use option --complement. The following example displays all the fields from /etc/passwd file except field 7: grep &quot;/bin/bash&quot; /etc/passwd | cut -d&#39;:&#39; --complement -s -f7. Change Output Delimiter for DisplayTo change the output delimiter use the option --output-delimiter as shown below: grep &quot;/bin/bash&quot; /etc/passwd | cut -d&#39;:&#39; -s -f1,6,7 --output-delimiter=&#39;#&#39; Change Output Delimiter to NewlineEach and every field of the cut command output is displayed in a separate line: grep bala /etc/passwd | cut -d&#39;:&#39; -f1,6,7 --output-delimiter=$&#39;\n&#39; catDisplay the contents of a fileIt can display one or more than one files’ contents: cat file1 file2 Create a New FileUsing cat command, the lines received from stdin can be redirected to a new file using redirection symbols. When you type simply cat command without any arguments, it just receives the stdin content and displays it in the stdout. You can also redirect the stdout to a new file as shown below:TODO Copy File ContentRedirection symbols in unix plays an important role in processing the standard file descriptor contents. The example below copy the contents of one file into another: cat test1&gt;test2 Concatenate Contents of Multiple FilesWe can concatenate contents of more than one file into a new file through cat:cat test1 test2 &gt; test_all. Display Line numbersTo display the contents of a file with the line number in front of each line, use option -n: cat -n test. And even the empty lines are numbered, in the case of numbering only nonempty lines, use option -b as follows: cat -b test. Concatenate File Contents along with Input from StdinThere is a possibility to read lines from stdin along with concatenation of other files. Hence the user can type his own content whenever its required. cat - test1 test2 test_all where we can insert a few lines (from stdin) in the beginning while combining files together. As seen above, - is the place where you can read from stdin, accordingly 1 line from stdin has been inserted into the beginning of a new file called test_all with the latter contents from test1 and test2 files. Don’t Display Repeated Empty Output Linescat command provides an option called -s which will suppress consecutive empty output lines into one and displays: cat -sn test. Display End of Line and TAB charactersYou can make the cat to display the $ character at end of every line. Normally by listing file contents, users can identify whitespaces at the end of each lines, by using the cat -e option. Moreover, Use option -T to display the tab characters, and it displays ^I for TAB character.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Usage of Itertools in Python]]></title>
    <url>%2F2016%2F08%2F11%2Fpython-itertools-usage%2F</url>
    <content type="text"><![CDATA[The module standardizes a core set of fast, memory efficient tools that are useful by themselves or in combination. Together, they form an iterator algebra making it possible to construct specialized tools succinctly and efficiently in pure Python. Check the API documentfor more details.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python, numpy genfromtxt produces array of what looks like tuples, not 2D array]]></title>
    <url>%2F2016%2F08%2F02%2Fpython-numpy-genfromtxt-produces-array%2F</url>
    <content type="text"><![CDATA[From the stackoverflow. What is returned is called a structured ndarray, see eg. This is because your data are not homogeneous, i.e. not all elements have the same type: the data contain both strings (the first two columns) and floats.Numpy arrays have to be homogeneous. The structured arrays ‘solve’ this constraint of homogeneity by using tuples for each record or row, that’s the reason the returned array is 1D: one series of tuples, but each tuple (row) consists of several data, so you can regard it as rows and columns.The different columns are accessible as a[‘nameofcolumn’].]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What is the difference between theorem, lemma, corollary...]]></title>
    <url>%2F2016%2F07%2F27%2Fwhat-is-the-difference-between-theorem-lemma-corollary%2F</url>
    <content type="text"><![CDATA[. DefinitionA precise and unambiguous description of the meaning of a mathematical term. It characterizes the meaning of a word by giving all the properties and only those properties that must be true. TheoremA mathematical statement that is proved using rigorous mathematical reasoning. In a mathematical paper, the term theorem is often reserved for the most important results. LemmaA minor result whose sole purpose is to help in proving a theorem. It is a stepping stone on the path to proving a theorem. Very occasionally lemmas can take on a life of their own (Zorn’s lemma, Urysohn’s lemma, Burnside’s lemma, Sperner’s lemma). CorollaryA result in which the (usually short) proof relies heavily on a given theorem (we often say that “this is a corollary of Theorem A”). PropositionA proved and often interesting result, but generally less important than a theorem. ConjectureA statement that is unproved, but is believed to be true (Collatz conjecture, Goldbach conjecture, twin prime conjecture). ClaimAn assertion that is then proved. It is often used like an informal lemma. Axiom/PostulateA statement that is assumed to be true without proof. These are the basic building blocks from which all theorems are proved (Euclid’s five postulates, Zermelo-Fraenkel axioms, Peano axioms). IdentityA mathematical expression giving the equality of two (often variable) quantities (trigonometric identities, Euler’s identity). ParadoxA statement that can be shown, using a given set of axioms and definitions, to be both true and false. Paradoxes are often used to show the inconsistencies in a flawed theory (Russell’s paradox). The term paradox is often used informally to describe a surprising or counterintuitive result that follows from a given set of rules (Banach-Tarski paradox, Alabama paradox, Gabriel’s horn).]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Mathematics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Find the size of a directory/free disk space]]></title>
    <url>%2F2016%2F07%2F27%2Funix-find-the-size-of-a-directory-and-free-disk-space%2F</url>
    <content type="text"><![CDATA[. du - Finding the size of a directory du &lt;dir&gt;: return a list of directories that exist in the &lt;dir&gt; directory along with their sizes. The last line of the output gives you the total size of the &lt;dir&gt; including its subdirectories. du -ah &lt;dir&gt;: display in its output, not only the directories but also all the files that are present in the &lt;dir&gt;. Note that du always counts all files and directories while giving the final size in the last line. the -a displays the filenames along with the directory names in the output. -h is once again human readable format. du -ch &lt;dir&gt;: This gives you a grand total as the last line of the output. du -ch &lt;dir&gt; | grep total: This would have only one line in its output that displays the total size of the current directory including all the subdirectories. du --exculde=mp3: The above command would display the size of the &lt;dir&gt; along with all its subdirectories, but it would exclude all the files having the given pattern present in their filenames. df - finding the disk free space / disk usage df -h: outputs a human readable table consisting of 6 columns]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elegant ngram generation in Python]]></title>
    <url>%2F2016%2F07%2F22%2Fpython-elegant-ngram-generation-in-Python%2F</url>
    <content type="text"><![CDATA[Solving how to compactly and elegantly generate n-grams from your favorite iterable. An obvious way1234567input_list = [&apos;all&apos;, &apos;this&apos;, &apos;happened&apos;, &apos;more&apos;, &apos;or&apos;, &apos;less&apos;]def find_bigrams(input_list): bigram_list = [] for i in range(len(input_list)-1): bigram_list.append((input_list[i], input_list[i+1])) return bigram_list Slicing and ZippingWe can take advantage of python’s zip builtin to build our bigrams. Zip takes a list of iterables and constructs a new list of tuples where the first list contains the first elements of the inputs, the second list contains the second elements of the inputs, and so on. GeneralizingIf we write out what our zip() invocation looks like for various n-grams, we see a pattern: 123456# Bigramszip(input_list, input_list[1:])# Trigramszip(input_list, input_list[1:], input_list[2:])# and so onzip(input_list, input_list[1:], input_list[2:], input_list[3:]) And now we have all our ingredients organized for our general find_ngram method. 1234input_list = [&apos;all&apos;, &apos;this&apos;, &apos;happened&apos;, &apos;more&apos;, &apos;or&apos;, &apos;less&apos;]def find_ngrams(input_list, n): return zip(*[input_list[i:] for i in range(n)])]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Email Usage]]></title>
    <url>%2F2016%2F07%2F13%2Femail-usage%2F</url>
    <content type="text"><![CDATA[. Here is a summary for some excellent email usage. Ask people for help (Send you a document) At your convenience, would you please send me… Thank you for your assistance. Ask for Advice Our team would appreciate your insights/input on…Due to the short time frame for this proposal, prompt reply is greatly appreciated. Cancel the conference/meeting I want to be mindful of your time and we don’t have any updates at this point; therefore I suggest that we cancel/reschedule today’s meeting. If you disagree or need assistance, please let me know. My apologies for the late notice, but I need to reschedule tomorrow’s call. There remain a few open items we need to address, therefore I will send out a new invite once we agree upon a time When others send you an email for question. Add the following sentence when you’ve provided your answer. Hope this answers your question. Let me know if further detail/explanation would be helpful. Summary the conference Thank you for making time on a very busy Friday afternoon to join our discussion. I hope we were able to provide clarity on…Attached is a summary of what we discussed today. apologies My sincere apology for this unfortunate situation; I will address to my team immediately.Again, please accept my most sincere aplogy. Share the progress of the project, and ask for call invite. Once these final steps are finished, I would suggest having a brief call to discuss our findings and recommendations for next steps. Would you please provide a few times the week of xxx that work within your schedule and I will send the calendar invite. Ask the prof to review your draft document. Attached is the drafted xx file. It is still a work in process but I would like to see if anything immediately stood out to you as odd or worthy of follow up. automatic reply. Template1:Thank you for your email. I will be out of the office on vacation from xxx-xxx with no access to emails. I apologize for any delay in responce to your email. I will respond to your email as quickly as I can when I return to the office on Monday, xxxx. Thanks. Template2:Thank you for your email. I am out of the office in meetings on xxx and xxx with limited access to email. If you need immediate assisatance, please contact me via my mobile phone. Thank you! give directions Thank you for preparing the xxx. I made the following updates to the question responses. We can discuss my thought process when I am in the office on Monday. xxx, great job! I have reviewed the xxx documents and have the following review comments:1…2… Say Hello! I hope that your week is off to great start. Hope you had a great weekend. Hope you’re well/Hope you are doing well I hope this message finds you well.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Writing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Find things in Linux]]></title>
    <url>%2F2016%2F06%2F28%2Funix-find-things-in-linux%2F</url>
    <content type="text"><![CDATA[How to find things in Linux. findBasicBasic format1find &lt;dir&gt; &lt;conditions&gt; &lt;actions&gt; Find files with specific name under a specific directory.1find . -name &quot;*summary*&quot; Find files with specific paths and show their detailed information1find . -name &apos;*summary*&apos; -ls Find some files that updated within 10 minutes.1find . -type -f -mmin -10 It will return regular files that were last modified 10 minutes ago. If their is no -type f, then it will return regular files, special files and directories. Execute arguments with the -exec option for each match it finds.delete the found files.1find . -name &quot;.git&quot; -exec rm -r &quot;&#123;&#125;&quot; \; It is equivatent to use the following cmd that seems to be easiler. But it cannot delete non-empty folder. 1find . -name &quot;.git&quot; -delete We can also just find the directories named .git by adding a -type d check: 1find . -name &quot;.svn&quot; -type d -exec rm -r &quot;&#123;&#125;&quot; \; We can use rmdir to remove empties directories and give errors fordirectories with contents. If we don’t want to see the errors,redirect the STDERR to /dev/null. 1find . -name &quot;.svn&quot; -type d -exec rmdir &quot;&#123;&#125;&quot; \; 2&gt; /dev/null grepIt searches the named input FILEs for lines containing a match to the given PATTERN. If no files are specified, or if the file - is given, grep searches standard input. By default, grep prints the matching lines. BasicWe here make a simple example. 1grep -Hri function_name . the trailing . stands for current directory -i: case-insensitive -r: recursive -H: print the file name for each match -l: suppress normal output; instad print the name of each input file from which output would normally have been printed. If you want only the path: grep -ril function_name . ackthis tool will avoid searching in .svn, .cvs, .git dirs and such. It is designed to search code. Basic ack -r &lt;path&gt; &lt;term&gt;: will print out file path and the corresponding information. ack -rl &lt;path&gt; &lt;term&gt; will only show the file path ack --ignore-dir=&lt;path&gt; &lt;term&gt; locateIt is much faster than find since it will search a database /var/lib/locatedb. Linux system build the database automatically and update it everyday. Before using locate, we should updatedb. BasicwhereisIt can be used to search binary file (-b), man file (-m) and source code (-s) Basicwhereis grep whichIt returns the pathnames of the files (or links) which would be executed in the current environment, had its arguments been given as commands in a strictly POSIX-conformant shell.It does this by searching the PATH for executable files matching the names of the arguments.It does not follow symbolic links.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Using docker without sudo]]></title>
    <url>%2F2016%2F06%2F27%2Funix-using-docker-without-sudo%2F</url>
    <content type="text"><![CDATA[Demonstrate how to use docker without sudo. Relate to user permission. Add the docker group if it doesn’t already exist: 1sudo groupadd docker Add the connected user “${USER}” to the docker group. Change the user name to match your preferred user: 1sudo gpasswd -a $&#123;USER&#125; docker Restart the Docker daemon: 1sudo service docker restart Log out and log in. Done.]]></content>
  </entry>
  <entry>
    <title><![CDATA[How to setup development environmnet of windows]]></title>
    <url>%2F2016%2F06%2F14%2Fwindows-how-to-setup-develop-environmnet-on-windows%2F</url>
    <content type="text"><![CDATA[. Basic setupInstall CygwinGo to the link, and download 64-bit versionto the Desktop. Install the downloaded exe package to the following pathC:\Program Files\cygwin. Install Reguired Cygwin PackagesOpen the Command Prompt by entering the cmd,and navigate to the folder where the Cygwin installer is located,and run the following command: 1C:\cygwin64&gt;setup-x86_64.exe -q -P wget -P gcc-g++ -P make -P diffutils -P libmpfr-devel -P libgmp-devel -P libmpc-devel -P git -P python -P curl -P zip -P unzip Download, Build and Install the Latest GCCOpen a Cygwin terminal, and do the following things. download and extract the latest GCC source code 12$ wget http://ftpmirror.gnu.org/gcc/gcc-4.9.2/gcc-4.9.2.tar.gz$ tar xf gcc-4.9.2.tar.gz configure and build GCC in another directory outside gcc-4.9.2 123$ mkdir build-gcc$ cd build-gcc$ ../gcc-4.9.2/configure --program-suffix=-4.9.2 --enable-languages=c,c++ --disable-bootstrap --disable-shared build the new GCC compiler suite, including C, C++ and the standard C++ library. 1make -j4 install the new compiler 12$ make install$ cd .. Download pip for python development.Open a Cygwin terminal, and go to the link to download the file get-pip.py. Then, install it by running the command python get-pip.py.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Configure-Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Top Conferences and Journals of Machine Learning and Artifical Intelligence]]></title>
    <url>%2F2016%2F06%2F13%2Ftop-conference-for-ml-ai%2F</url>
    <content type="text"><![CDATA[Data from the Internet. Microsoft AcademicThe link of Microsoft Academic Search. From QuoraConferencesTop Conferences: ICML KDD NIPS These three are the flagship machine learning conferences.They are the largest by attendance, attract researchers from across virtuallyall areas of machine learning, and have high visibility in industryand other computational fields. Compared to ICML and NIPS, KDD is a bit more focused on new applicationsand less focused on basic methodology. Smaller Conferences: AISTATS UAI These two conferences typically span a wide range of topics in machine learning,although not quite as wide as the aforementioned three.They are also significantly smaller than the top 3, which makes them lessvisible to researchers outside the machine learning community.However, in terms of dissemination within the machine learning community,these conferences are just as good as the top 3. Niche Conferences: ICLR COLT These two conferences are called niche conferences because they focus on a verynarrow set of topics (from a machine learning perspective). ICLR is a recently created conference organized by the deep learning folks.The focus of ICLR is to study how to learn representations of data,which is basically what deep learning does. COLT is the conference on learning theory, and so is primarily focused ontheoretical aspects of machine learning.Both conferences are great for their respective topics,and you get a more focused audience for your work. Regional Conferences: ECML ACML There are some regional conferences as well. I’d attend ECML (resp. ACML)if I wanted to network with Europeans (resp. Asians). Other Conferences:Many conferences of other fields have machine learning papers or even a machinelearning track.For instance, conferences focusing on vision, natural language processing,or information retrieval have the majority of their papers using machinelearning in some fashion, and also have many papers that propose newmachine learning techniques. Hence, I often skim through the proceedings of the following conferences fromother computational fields: CVPR ICCV ECCV SIGIR CIKM WSDM ACL EMNLP SDM ICDM WWW Finally, there are conferences that are so broad that you could even call themunfocused. But they do have a fair amount of machine learning papers. AAAI IJCAI Journals:The two main machine learning journals are Machine Learning and JMLR.Both contain top quality content.Other journals that are broader than Machine Learning are TKDE and JAIR.Both also contain some great machine learning papers as well. Note that JMLR and JAIR are completely open access, so they are free to browse.TKDE and Machine Learning are behind paywalls, however authors retaincertain copyrights so you can usually find the papers on Google Scholar orthe authors’ home pages.]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python, Accessing an attribute by using a variable]]></title>
    <url>%2F2016%2F06%2F07%2Fpython-accessing-an-attribute-using-a-variable%2F</url>
    <content type="text"><![CDATA[. The example is below: 1234def get_info(lines_class, v): return set([getattr(line, v) for line in lines_class])get_info(lines_class, &quot;category&quot;) Assume category is one of the attributes of the line class in thelist of lines_class.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gcloud Usage Tutorial]]></title>
    <url>%2F2016%2F05%2F30%2Fgcloud-usage%2F</url>
    <content type="text"><![CDATA[. GCloud TutorialBasic Usage of CloudLogin123gcloud compute ssh &lt;instance_name&gt;# orgcloud compute --project &quot;test&quot; ssh --zone &quot;us-central1-c&quot; &quot;&lt;instance_name&gt;&quot; Copycopy the files or folders into the instance:1gcloud compute copy-files &lt;localfile&gt; &lt;instance_name&gt;:&lt;/whateverfolder&gt; --project &quot;test&quot; --zone &quot;us-central1-c&quot; Mount DiskSmall Tips lsblk get the condition of the disk. Use the df -h command to verify the condition of disk. 1df -h /dev/disk/by-id/google-datatype read-write modeIf the disk is empty or the data is not important, then we can use the following command: 12345sudo mkfs.ext4 -F /dev/disk/by-id/google-data-epflsudo mkdir /data-epflsudo mount -o discard,defaults /dev/sdb /data-epfl# orsudo /usr/share/google/safe_format_and_mount /dev/sdb /data-epfl If the disk is not empty and we need to reserve the data, then we can use the following command: 1sudo mount -o /dev/disk/by-id/google-data-epfl /data-epfl read-only modeUse the following command (it works), inspired by the link. Use the following command: sudo mount -o ro,noexec,noload /dev/sdb /data-epfl Some Tips: The /dev/sdb is determined by the command lsblk, which can help us to figure out the umount disk. We can use df -h to check to the status of disk. Update Instances with TagsUse the following command to update the tags of the instance which connect with the firewall rule. 12gcloud compute instances describe rstudio-epflgcloud compute instances add-tags rstudio-epfl --tags rstudio Modify the permission of that foldersudo chown -Rv hali /datadisk Modify the Zone of the Compute Engine Instance Change the configuration gcloud config set compute/zone europe-west1-c Move the instance between zones gcloud compute instances move example-instance --zone us-central1-a --destination-zone us-central1-f]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>GCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Finding all cycles in graph]]></title>
    <url>%2F2016%2F05%2F23%2Ffinding-all-cycles-in-graph%2F</url>
    <content type="text"><![CDATA[Many algorithms are related to this problem.Some of them are listed in this article:On Algorithms for Enumerating All Circuits of a Graph. Johnson’s algorithm is the fastest one.]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[using sed to find and replace]]></title>
    <url>%2F2016%2F05%2F18%2Funix-using-sed-to-find-and-replace%2F</url>
    <content type="text"><![CDATA[. sed is stream editor, but can edit files directly too, with the following: 1sed -i -e &apos;s/foo/bar/g&apos; filename s is used to replace the found expression &quot;foo&quot; with &quot;bar&quot; g stands for “global”, meaning to do this for the whole line. If you leave off the g and “foo” appears twice on the same line, only the first “foo” is changed to “bar”. -i option is used to edit in place on filename. -e option indicates a command to run.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Use linux to merge pdf file]]></title>
    <url>%2F2016%2F05%2F12%2Funix-use-linux-to-merge-pdf%2F</url>
    <content type="text"><![CDATA[. 1pdfjoin a.pdf b.pdf all.pdf]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detect if a graph is cyclic or not]]></title>
    <url>%2F2016%2F05%2F11%2Fpython-detect-if-graph-is-cyclic%2F</url>
    <content type="text"><![CDATA[From the web. 123456789101112131415161718192021222324def is_cyclic(g): """Return True if the directed graph g has a cycle. g must be represented as a dictionary mapping vertices to iterables of neighbouring vertices. For example: &gt;&gt;&gt; cyclic(&#123;1: (2,), 2: (3,), 3: (1,)&#125;) True &gt;&gt;&gt; cyclic(&#123;1: (2,), 2: (3,), 3: (4,)&#125;) False """ path = set() visited = set() def visit(vertex): if vertex in visited: return False visited.add(vertex) path.add(vertex) for neighbour in g.get(vertex, ()): if neighbour in path or visit(neighbour): return True path.remove(vertex) return False return any(visit(v) for v in g)]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh loginin without password]]></title>
    <url>%2F2016%2F04%2F28%2Funix-ssh-login-without-password%2F</url>
    <content type="text"><![CDATA[. 1234ssh-keygen -t rsassh b@B mkdir -p .sshcat .ssh/id_rsa.pub | ssh b@B &apos;cat &gt;&gt; .ssh/authorized_keys&apos;ssh b@B]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Difference between Java between python]]></title>
    <url>%2F2016%2F04%2F27%2Finterview-difference-between-java-between-python%2F</url>
    <content type="text"><![CDATA[Based on the blog. BeginningFinally, it is important to note that asserting that a programmer can be more productive in Python than in Java, is not the same as asserting that one ought always to use Python and never to use Java. Programming languages are tools, and different tools are appropriate for different jobs. Java vs. Python Productivity – an OverviewThere are three main language characteristics that make programmers more productive with Python than with Java. Java: statically typedIn Java, all variable names (along with their types) must be explicitly declared. Attempting to assign an object of the wrong type to a variable name triggers a type exception.That’s what it means to say that Java is a statically typed language. Java container objects (e.g. Vector and ArrayList) hold objects of the generic type Object, but cannot hold primitives such as int. To store an int in a Vector, you must first convert the int to an Integer. When you retrieve an object from a container, it doesn’t remember its type, and must be explicitly cast to the desired type. Python: dynamically typedIn Python, you never declare anything. An assignment statement binds a name to an object, and the object can be of any type. If a name is assigned to an object of one type, it may later be assigned to an object of a different type. That’s what it means to say that Python is a dynamically typed language. Python container objects (e.g. lists and dictionaries) can hold objects of any type, including numbers and lists. When you retrieve an object from a container, it remembers its type, so no casting is required. Java: verboseabounding in words; using or containing more words than are necessary Python: conciseexpressing much in a few words. Implies clean-cut brevity, attained by excision of the superfluous More detailsDifference 1Java: Each top-level public class must be defined in its own file. If your application has 15 such classes, it has 15 files. Python: Multiple classes can be defined in a single file. If your application has 15 classes, the entire application could be stored in a single file, although you would probably want to partition it sensibly into perhaps 4, 5, or 6 files. Difference 2In your application, method A calls B calls C calls D calls E calls F. You discover that F must throw exception SpecialException, and it must be caught by A. Java: You must throw SpecialException in F, and catch it in A.andYou must add “throws SpecialException” to the signatures of methods B, C, D, E, and F. Python: You must raise SpecialException in F, and catch it in A.Exceptions will propagate upward automatically; there is nothing more that you must do. The reason for this is that Java, virtually alone among object-oriented programming languages, uses checked exceptions — exceptions that must be caught or thrown by every method in which they might appear, or the code will fail to compile. Difference 3Your application has an Employee class. When an instance of Employee is created, the constructor may be passed one, two, or three arguments. If you are programming in Java, this means that you write three constructors, with three different signatures. If you are programming in Python, you write only a single constructor, with default values for the optional arguments. Difference 4Java’s string-handling capabilities are surprisingly weak. Difference 5Verbosity is not just a matter of increasing the number of characters that must be typed — it is also a matter of increasing the number of places where mistakes can be made. The Java code on the left has 5 control characters: (, ), {, }, ; where the corresponding Python code has only one control character, the colon.]]></content>
      <categories>
        <category>Job</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Python</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-threading-difference-between-notify-and-notifyAll]]></title>
    <url>%2F2016%2F04%2F26%2Fjava-threading-difference-between-notify-and-notifyAll%2F</url>
    <content type="text"><![CDATA[From the Stackoverflow Clearly, notify wakes (any) one thread in the wait set, notifyAll wakes all threads in the waiting set. The following discussion should clear up any doubts. notifyAll should be used most of the time. If you are not sure which to use, then use notifyAll.Please see explanation that follows. Read very carefully and understand. Please send me an email if you have any questions. Look at producer/consumer (assumption is a ProducerConsumer class with two methods). IT IS BROKEN (because it uses notify) - yes it MAY work - even most of the time, but it may also cause deadlock - we will see why: 123456789101112131415161718public synchronized void put(Object o) &#123; while (buf.size()==MAX_SIZE) &#123; wait(); // called if the buffer is full (try/catch removed for brevity) &#125; buf.add(o); notify(); // called in case there are any getters or putters waiting&#125;public synchronized Object get() &#123; // Y: this is where C2 tries to acquire the lock (i.e. at the beginning of the method) while (buf.size()==0) &#123; wait(); // called if the buffer is empty (try/catch removed for brevity) // X: this is where C1 tries to re-acquire the lock (see below) &#125; Object o = buf.remove(0); notify(); // called if there are any getters or putters waiting return o;&#125; Why do we need a while loop surrounding the wait? We need a while loop in case we get this situation: Consumer 1 (C1) enter the synchronized block and the buffer is empty, so C1 is put in the wait set (via the wait call). Consumer 2 (C2) is about to enter the synchronized method (at point Y above), but Producer P1 puts an object in the buffer, and subsequently calls notify. The only waiting thread is C1, so it is woken and now attempts to re-acquire the object lock at point X (above). Now C1 and C2 are attempting to acquire the synchronization lock. One of them (nondeterministically) is chosen and enters the method, the other is blocked (not waiting - but blocked, trying to acquire the lock on the method). Let’s say C2 gets the lock first. C1 is still blocking (trying to acquire the lock at X). C2 completes the method and releases the lock. Now, C1 acquires the lock. Guess what, lucky we have a while loop, because, C1 performs the loop check (guard) and is prevented from removing a non-existent element from the buffer (C2 already got it!). If we didn’t have a while, we would get an IndexArrayOutOfBoundsException as C1 tries to remove the first element from the buffer! NOW, Ok, now why do we need notifyAll? In the producer/consumer example above it looks like we can get away with notify. It seems this way, because we can prove that the guards on the wait loops for producer and consumer are mutually exclusive. That is, it looks like we cannot have a thread waiting in the put method as well as the get method, because, for that to be true, then the following would have to be true: buf.size() == 0 AND buf.size() == MAX_SIZE (assume MAX_SIZE is not 0) HOWEVER, this is not good enough, we NEED to use notifyAll. Let’s see why … Assume we have a buffer of size 1 (to make the example easy to follow). The following steps lead us to deadlock. Note that ANYTIME a thread is woken with notify, it can be non-deterministically selected by the JVM - that is any waiting thread can be woken. Also note that when multiple threads are blocking on entry to a method (i.e. trying to acquire a lock), the order of acquisition can be non-deterministic. Remember also that a thread can only be in one of the methods at any one time - the synchronized methods allow only one thread to be executing (i.e. holding the lock of) any (synchronized) methods in the class. If the following sequence of events occurs - deadlock results: STEP 1: P1 puts 1 char into the buffer STEP 2: P2 attempts put - checks wait loop - already a char - waits STEP 3: P3 attempts put - checks wait loop - already a char - waits STEP 4: C1 attempts to get 1 char C2 attempts to get 1 char - blocks on entry to the get method C3 attempts to get 1 char - blocks on entry to the get method STEP 5: C1 is executing the get method - gets the char, calls notify, exits method The notify wakes up P2 BUT, C2 enters method before P2 can (P2 must reacquire the lock), so P2 blocks on entry to the put method C2 checks wait loop, no more chars in buffer, so waits C3 enters method after C2, but before P2, checks wait loop, no more chars in buffer, so waits STEP 6: NOW: there is P3, C2, and C3 waiting! Finally P2 acquires the lock, puts a char in the buffer, calls notify, exits method STEP 7: P2’s notification wakes P3 (remember any thread can be woken) P3 checks the wait loop condition, there is already a char in the buffer, so waits. NO MORE THREADS TO CALL NOTIFY and THREE THREADS PERMANENTLY SUSPENDED! SOLUTION: Replace notify with notifyAll in the producer/consumer code (above).]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Difference between implement runnable and extends thread]]></title>
    <url>%2F2016%2F04%2F23%2Fjava-threading-difference-between-implement-runnable-and-extends-thread%2F</url>
    <content type="text"><![CDATA[Collect answers from the Quora There are two obvious ways to create a thread in Java: Implementing the Runnable class and extending the Thread class. 12345public class MyWork implements Runnable &#123; public void run() &#123; // your work here ... &#125;&#125; and then you can do new Thread(new MyWork).start(). Here, you are using object composition to define a has-a relationship between threads and work. A thread has a MyWork that it executes. The latter: 12345678public class MyThread extends Thread &#123; public MyThread() &#123; super("MyThread"); &#125; public void run() &#123; // your work here ... &#125;&#125; and then you do a MyThread.start(). Here, you are using inheritance to create a new type of thread that performs your specific work. MyThread is a Thread that happens to execute your work. If it isn’t obvious yet, “implements Runnable” is the superior object oriented pattern: Composition, not inheritance, more accurately defines the relationships between your objects. There are several other reasons to prefer “implements Runnable:” Other APIs in Java accept work as Runnable and not specializations of the Thread class. Defining your work as Runnable doesn’t wed your work to the Thread object. In the future, you might want to hand your work to some other execution abstraction. Java doesn’t support multiple inheritance, so if your class already extends an object, you can’t also extend Thread. By implementing Runnable, multiple threads can share an instance of your work. If you extended Thread, you’d have to create a new instance of your work for each thread.]]></content>
      <categories>
        <category>Job</category>
      </categories>
      <tags>
        <tag>Interview</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What is Big Data and Data Mining]]></title>
    <url>%2F2016%2F04%2F23%2Fwhat-is-big-data-and-data-mining%2F</url>
    <content type="text"><![CDATA[摘自知乎各种回答，仅用于个人整理 IntroductionHow to describe Data 数据量很大: Massive data 数据非常多样: Heterogeneous Data 数据既多样，又量大: Massive Heterogeneous Data What is Data Mining Data mining = KDD(Knowledge Discovery and Data Mining) 一个从未经处理过的数据中提取信息的过程，重点是找到相关性和模式分析。 而从单纯无序杂乱的数据里面提取出有用的信息，首先要规范化数据，然后根据想要回答的问题选择相应的方法，可以建立模型预测未来，可以对当前数据聚类，也可以是单纯的从数据中找寻规律等等。 What is Big Data 由于Web技术的发展，web用户产生的数据自动保存、传感器也在不断收集数据，以及移动互联网的发展，数据自动收集、存储的速度在加快，全世界的数据量在不断膨胀，数据的存储和计算超出了单个计算机(小型机和大型机)的能力，这给Data Mining的实施提出了挑战。 Big Data: Big in Volume, Velocity, Variety. 但是大数据的大的标准是在计算机计算能力发展的情况下不断变化的。 个人觉得，有个对大数据的总结做的很好，具体如下： 我以为大数据有2层意思：首先是万物皆可数据化。数据化不等于数字化，数据化指的是将对象量化成可分析的数据，可以是结构化的，也可以是非结构化的。 援引来自2013年4月19号《东方早报》的文章《比你更了解你——大数据时代的汽车生活》中的一段：再来说一个例子，你可能永远也想不到你开车时的坐姿可以防止汽车被盗，这听起来简直不可思议，但这就是现实存在的事，日本某工业研究所通过在汽车座椅下安装360个压力传感器来测量人对座椅各部分施加压力的方式，并且通过0-256个数值范围进行量化，这样，每个乘坐者都将产生一份专属的数据资料，这个系统可以根据人对座位的压力差异识别出乘坐者的身份，准确率高达98%，这项技术作为汽车防盗系统装在车上时，汽车就会知道驾驶者是不是车主，如果不是，汽车就会自动熄火，另外也可以根据坐姿数据来判断司机是否正处于疲劳驾驶，系统可以通过自动减速或刹车来控制可能带来的危险。 第二层意思是大数据的“样本即总体”。 这个观点来自于舍恩伯格的《大数据时代》。以前的定量调查和分析的数据，受限于技术、资金等条件，总是从整体中抽取一部分样本，针对这些样本进行调查。但是大数据不一样，大数据分析的数据是整体。 Differences And Relationship大数据是一种属性，而数据挖掘是方法，或者说是方法的集合。Google提出了分布式存储文件系统，发展出后来的云存储和云计算的概念。一系列Big Data技术的出现，使得数据挖掘的未来不再是针对少量或是样本化，随机化的精准数据，而是海量，混杂的大数据。 但值得注意的是：大数据概念本身强调的是处理大数据的能力和技术，他主要是一种思路： 1.不使用抽样的数据，而采用全部的数据：这里我指的全部的数据是完全所有的数据，包括正确的和不正确的数据都要采用。噪声和错误数据同样包含着有用的信息。 2.不关心为什么，只关心是什么：因为我们有了海量的数据 ，因此我们通过大数据统计出的结果应该是具有相当程度的普适性的。所以把这种现象-结果拿去套就行了。如果探究和证明因果关系的话，通常是极为困难的。一个例子就是经典的啤酒和尿布，从数据中获得这种结果很简单，把它们放在一起就能增加销量从而达到沃尔玛的目的，而去查明原因则费事的多。 3.相比数据分析方法而言更注重数据获取：换一种说法就是数据为先。因为现在计算机太牛逼了，所以只要我们想到办法，它就能替我们干相应的活。基于此，我们要做的就是获取更多的，更全面的数据来让计算机分析。例如国外快递公司在车上装传感器来帮助快递调度，劳斯莱斯公司在飞机发动机上装传感器并通过历史数据和实时数据预先预测潜在故障并提前检修的例子。大数据思维模式中，数据为我们提供最多的可能和最大的价值，所以着重获取数据。 说了这么多，我想说的就是数据挖掘可以概括为：在我们掌握的数据多了以后，把数据交给计算机分析的方法的集合。而大数据则是跳出我们的传统数据分析和处理方法框架的一种新思维。一种思维和一类技术比起来，确实是要虚很多，而且思维要付诸实现，必然是要以技术为基础的。但是正是由于思维方式的不同，我们可以从数据中获得更多的东西，比如对之前认为没有价值的噪声和错误数据的分析，或者对现象的重视而意外发现的一些有意思的结果等等。 Data Mining without Big Data V.S. Data Mining with Big Data.有些人认为，data mining跟big data存在若干区别，如： Data Mining还是基于用户假设了因果，然后进行验证；而Big Data则重点在找出关联关系，A的变化会影响到B的变化幅度； 传统的方法只是从内部数据库数据提取，分析数据； Big Data则从更多途径，采用更多非结构化的数据； 处理时间上，传统的对时间要求不高； Big Data强调的是实时性，数据在线即用； 传统的方式，重点还是从数据中挖掘出残值； 而Big Data是从数据中找出新的内容，创新的价值； Data mining是从大量的历史信息中总结出有用的知识; Big Data是海量数据环境下如何还能保持对某个访问会话的快速响应。 Data Mining原则上是可以不需要Big Data的，因为它对响应速度并无要求，它看重的是挖掘出来的知识的效用。 但个人认为，这些区别应该仅是 data mining without big data V.S. data mining with big data，即传统的数据挖掘跟大数据时代下数据挖掘的区别。 同样的，大数据时代给数据挖掘很多挑战，如：现在基础技术无法满足需求。比如传统上我们觉得一个亚线性时间算法不错，可是拿到大数据上，亚线性时间也不行了，这就是数据量的增长对于整个计算机科学界提出的挑战，你说你有一个O(log(n))的算法，那放到大数据身上也是不管用的（指的是不能分布计算的场景，能分布计算的话只要多搞几台机器（像MapReduce那样），分散开来变成“小数据”之后也就不叫大数据了）。由此给数据挖掘带来的问题就是很多数据挖掘算法即使在传统概念上的时间复杂度很低，现在也不能满足要求了。 Application of Big Data/Data MiningDemo123456789101112131415161718192021222324252627某披萨店的电话铃响了，客服人员拿起电话。客服：您好，请问有什么需要我为您服务？顾客：你好，我想要一份……客服：先生，烦请先把您的会员卡号告诉我。顾客：342623***。客服：陈先生，您好！您是住在安澜路一号12楼1205室，您家电话是6333***，您公司电话是2888***，您的手机是1390553****。请问您想用哪一个电话付费？顾客：你为什么知道我所有的电话号码？客服：陈先生，因为我们联机到CRM系统。顾客：我想要一个海鲜比萨……客服：陈先生，海鲜比萨不适合您。顾客：为什么？客服：根据您的医疗记录，你的血压和胆固醇都偏高。顾客：那你们有什么可以推荐的？客服：您可以试试我们的低脂健康比萨。顾客：你怎么知道我会喜欢吃这种的？客服：您上星期一在国家图书馆借了一本《低脂健康食谱》。顾客：好。那我要一个家庭特大号比萨，要付多少钱？客服：99元，这个足够您一家六口吃了。但您母亲应该少吃，她上个月刚刚做了心脏搭桥手术，还处在恢复期。顾客：那可以刷卡吗？客服：陈先生，对不起。请您付现款，因为您的信用卡已经刷爆了，您现在还欠银行4807元，而且还不包括房贷利息。顾客：那我先去附近的提款机提款。客服：陈先生，根据您的记录，您已经超过今日提款限额。顾客：算了，你们直接把比萨送我家吧，家里有现金。你们多久会送到？客服：大约30分钟。如果您不想等，可以自己骑车来。顾客：为什么？客服：根据我们CRM全球定位系统的车辆行驶自动跟踪系统记录。您登记有一辆车号为SB-748的摩托车，而目前您正在铁山路右侧骑着这辆摩托车。顾客：当即晕倒…… Summary大数据被运用的最多的场景，我们认为目前为止是这五个领域：大数据的探索、360度全方位客户视图、运维及运营的分析、数据仓库能力的扩展和增强，以及安全和风险能力增强。 目前数据源比较成熟的，主要包括社交数据（包括社交网站、论坛等来源）、搜索数据和位置数据。 社交数据：关注分析。分析用户在发布会展相关的内容的时候，其他关联词汇的热度。例如伴随“水果+会展”出现频率最高的是“农药”、“安全”一类的词汇，那可能会帮助水果展销会的站台和服务设置，例如增加绿色水果展位，或者采摘服务展位。 社交数据：用户态度分析。社交网站如果能开放用户的详细信息的话，你也可以分析哪些人对哪类会展持正面态度，哪些人持负面态度。 搜索数据：跟社交数据类似，分析关联搜索热词，判断用户关注什么和态度。 位置数据：分析参加展会（非受邀的）的人来自何处、去向哪里，以便下一次展会重点在哪里投放广告和推广。 大数据挖掘商业价值的方法主要分为四种： 顾客群体细分，然后对每个群体量体裁衣般地采取独特的行动。 模拟实际环境，发掘新的需求同时提高投入的回报率。 加强各部门联系，提高整个管理链条和产业链条的投入回报率。 发现隐藏线索，进行产品和服务的创新。 Techniques (Big Data/Data Mining Pipeline) 数据采集：ETL工具负责将分布的、异构数据源中的数据如关系数据、平面数据文件等抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础。 数据存取：关系数据库、NOSQL、SQL等。 基础架构：云存储、分布式文件存储等。 数据处理：自然语言处理(NLP，NaturalLanguageProcessing)是研究人与计算机交互的语言问题的一门学科。处理自然语言的关键是要让计算机”理解”自然语言，所以自然语言处理又叫做自然语言理解(NLU，NaturalLanguage Understanding)，也称为计算语言学(Computational Linguistics。一方面它是语言信息处理的一个分支，另一方面它是人工智能(AI, Artificial Intelligence)的核心课题之一。 统计分析：假设检验、显著性检验、差异分析、相关分析、T检验、方差分析、卡方分析、偏相关分析、距离分析、回归分析、简单回归分析、多元回归分析、逐步回归、回归预测与残差分析、岭回归、logistic回归分析、曲线估计、因子分析、聚类分析、主成分分析、因子分析、快速聚类法与聚类法、判别分析、对应分析、多元对应分析（最优尺度分析）、bootstrap技术等等。 数据挖掘：分类 （Classification）、估计（Estimation）、预测（Prediction）、相关性分组或关联规则（Affinity grouping or association rules）、聚类（Clustering）、描述和可视化、Description and Visualization）、复杂数据类型挖掘(Text, Web ,图形图像，视频，音频等) 模型预测：预测模型、机器学习、建模仿真。 结果呈现：云计算、标签云、关系图等。 Examples(1).第一产业 孟山都（Monsanto | A Sustainable Agriculture Company），农业孟山都是一家美国的跨国农业生物技术公司，其生产的旗舰产品抗农达，即年年春（Roundup）是全球知名的嘉磷塞除草剂，长期占据市场第一个位置。该公司目前也是基因改造（GE）种子的领先生产商，占据了多种农作物种子70%–100%的市场份额，而在美国本土，更占有整个市场的90%。已经统治了生物工程种子业务超过十年。 孟山都首先发起“Green Data Revolution”运动，建立农业数据联盟(Open Ag Data Alliance)来统一数据标准，让农民不用懂“高科技”也能享受大数据的成果。典型的应用如农场设备制造商John Deere与DuPont Pioneer当前联合提供“决策服务(Decision Services)”，农民只需在驾驶室里拿出平板电脑，收集种子监视器传来的数据，然后将其上传给服务器，最终服务器返回化肥的配方到农场拖拉机上。 天气意外保险公司（The Climate Corporation），农业The Climate Corporation为农民提供Total Weather Insurance (TWI)——涵盖全年各季节的天气保险项目。利用公司特有的数据采集与分析平台，每天从250万个采集点获取天气数据，并结合大量的天气模拟、海量的植物根部构造和土质分析等信息对意外天气风险做出综合判断，然后向农民提供农作物保险。前不久从Google Ventures、Founders Fund等多家公司获得超过5000万美元的风险投资。 2013年被孟山都收购。 土壤抽样分析服务商（Solum, Inc），农业Solum目标是实现高效、精准的土壤抽样分析，以帮助种植者在正确的时间、正确的地点进行精确施肥。农户既可以通过公司开发的No Wait Nitrate系统在田间进行分析即时获取数据；也可以把土壤样本寄给该公司的实验室进行分析。2012年获得Andreessen Horowitz 领投的1700万美元投资后，已累计融资近2000万美元。 (2).第二产业 第三方认证机构（TÜV NORD GROUP），工业德国汉德技术监督服务有限公司的前身是德国锅炉检验协会（简称DÜV）早在1869年，德国锅炉检验协会就承担了德国国内所有锅炉运行安全的检验工作，保证了锅炉生产的安全。渐渐的，德国锅炉检验协会取得了德国政府的授权，开展对其他产品的检验工作，从采矿，电力系统开始，到压力容器，机动车辆，医疗设备，环境保护，宇航工业，医疗产品等等，现在的德国汉德技术监督服务有限公司已经成为了许许多多产品的安全代号。主要体系认证包括企业质量管理体系，生产环境体系，生产碳排放方案等。DÜV当前从建筑绿色标准体系方面提出了对于大数据能源管理的探索，以微软新总部，蒂森克虏伯电梯总部为例，在整个项目实施中引入大数据能源管理，在建筑的设计规划阶段、施工阶段、运营阶段等多个阶段通过数据化的能源管理系统，实现建筑的低碳、绿色、智能。 工业自动化软件商（Wonderware ），工业Wonderware作为系统软件涉及的专业企业，对于大数据的计算和运用是从比较“IT”的角度出发的。Wonderware 的实时数据管理软件能够提供一个工厂所需要的从建立到报废的所有实时数据。目前已经退出移动版本，工程总监在手机上就能够随时随地监控设备的运行状况。目前全球超过三分之一的工厂应用Wonderware公司的软件解决方案。 能源产业 智能电网现在欧洲已经做到了终端，也就是所谓的智能电表。在德国，为了鼓励利用太阳能，会在家庭安装太阳能，除了卖电给你，当你的太阳能有多余电的时候还可以买回来。通过电网收集每隔五分钟或十分钟收集一次数据，收集来的这些数据可以用来预测客户的用电习惯等，从而推断出在未来2~3个月时间里，整个电网大概需要多少电。有了这个预测后，就可以向发电或者供电企业购买一定数量的电。因为电有点像期货一样，如果提前买就会比较便宜，买现货就比较贵。通过这个预测后，可以降低采购成本。 维斯塔斯风力系统，依靠的是BigInsights软件和IBM超级计算机，然后对气象数据进行分析，找出安装风力涡轮机和整个风电场最佳的地点。利用大数据，以往需要数周的分析工作，现在仅需要不足1小时便可完成。 (3).第三产业 健康与医疗： Fitbit® Official Site: Flex, One and Zip Wireless Activity and Sleep Trackers的健身腕带可以收集有关我们走路或者慢跑的数据，例如行走步数、卡路里消耗、睡眠时长等数据与健康记录来改善我们的健康状况。 Early Detection of Patient Deterioration等公司正在开发床垫监测传感器，自动监测和记录心脏速率、呼吸速率、运动和睡眠活动。该传感器收集的数据以无线方式被发送到智能手机和平板电脑，进行进一步分析。 美国公共卫生协会（APHA: American Public Health Association）开发Flu Near You用来的症状，通过大数据分析生成报告显示用户所在地区的流感活动。 Seton Healthcare是采用IBM最新沃森技术医疗保健内容分析预测的首个客户。该技术允许企业找到大量病人相关的临床医疗信息，通过大数据处理，更好地分析病人的信息。 在加拿大多伦多的一家医院，针对早产婴儿，每秒钟有超过3000次的数据读取。通过这些数据分析，医院能够提前知道哪些早产儿出现问题并且有针对性地采取措施，避免早产婴儿夭折。 它让更多的创业者更方便地开发产品，比如通过社交网络来收集数据的健康类App。也许未来数年后，它们搜集的数据能让医生给你的诊断变得更为精确，比方说不是通用的成人每日三次一次一片，而是检测到你的血液中药剂已经代谢完成会自动提醒你再次服药。 房地产：针对建设、改造和翻新住宅的“一站式商店”Find Great Remodeling Contractors. Home Improvement Begins with Buildzoom.拥有约250万承包商、5万以上客户意见信息，来帮助50万用户带来更多客观性和透明度的决策意见。智能电视和机顶盒能够追踪你正在看的内容，看了多长时间，甚至能够识别多少人坐在电视机前，来确定这个频道的流行度。 交通：每天坐公交，智能手机会为我们预测公共汽车到达的时间车来了；开车的时候发送位置信息以及速度，然后结合实时交通信息为我们提供最佳路线，从而避免堵车。WNYC开发的Transit Time NYC让纽约人可以点击纽约市的五个区域来获取地铁或火车的时间。他们从开源行程平台OpentripPlanner获取数据，并将这些数据域公开下载的地铁时间表结合来创造400万虚拟旅程。实时车辆交通数据采集商INRIX速 Traffic可以帮助你避开堵车，每位用户在使用过程中会给服务器发送实时数据，比如走的多快，走到哪里，这样每个客户都是探测器。 购物： Decide帮助人们做购买决策，预测产品的价格趋势，告诉消费者什么时候买东西最便宜，做法是通过在全球各大网站上搜集数以十亿计的数据进行分析。 “我们的某个客户，是一家领先的专业时装零售商，通过当地的百货商店、网络及其邮购目录业务为客户提供服务。公司希望向客户提供差异化服务，如何定位公司的差异化，他们通过从 Twitter 和 Facebook 上收集社交信息，更深入的理解化妆品的营销模式，随后他们认识到必须保留两类有价值的客户：高消费者和高影响者。希望通过接受免费化妆服务，让用户进行口碑宣传，这是交易数据与交互数据的完美结合，为业务挑战提供了解决方案。”Informatica的技术帮助这家零售商用社交平台上的数据充实了客户主数据，使他的业务服务更具有目标性。 零售企业也监控客户的店内走动情况以及与商品的互动。它们将这些数据与交易记录相结合来展开分析，从而在销售哪些商品、如何摆放货品以及何时调整售价上给出意见，此类方法已经帮助某领先零售企业减少了17%的存货，同时在保持市场份额的前提下，增加了高利润率自有品牌商品的比例。 政治：奥巴马在总统竞选中使用大数据分析来收集选民的数据，让他可以专注于最有可能投他的选民，谷歌执行董事长Eric Schmidt当时向奥巴马的大数据分析团队投资数百万美元并聚拢核心成员成立了Civis Analytics咨询公司，该公司将会将在奥巴马连任竞选中所获得的经验应用到企业和非营利行业中去。 金融： ZestFinance | Big Data Underwriting 是由是Google的前任 CIO—Douglas Merrill创立金融数据分析服务提供商，使用机器学习算法和大数据为放款者提供承保模式，旨在为那些个人信用不良或者不满足传统银行贷款资格的个人提供服务。公司使用分析模型对每位信贷申请人的上万条原始信息数据进行分析，只需几秒时间便可以得出超过十万个行为指标。这家公司经历了近 4年的成长，能够分析的数据量比有资格进行次级信贷的美国人的数量的 2 倍还多，其违约率也比行业平均水平低 60%左右。 另外不得不提到风险管理信用技术的先驱者FICO | Predictive Analytics, Big Data Analytics and FICO Credit Scores，通过大数据分析为银行和信用卡发卡机构、保险、医疗保健、政府和零售行业提供服务。FICO 信用分计算的基本思想是：把借款人过去的信用历史资料与数据库中的全体借款人的信用习惯相比较，检查借款人的发展趋势跟经常违约、随意透支、甚至申请破产等各种陷入财务困境的借款人的发展趋势是否相似。FICO 已经为三分之二的世界 100 强银行提供服务，提高了客户忠诚度和盈利率、减少欺诈损失、管理信贷风险、满足监管与竞争要求并快速获取市场份额。 电信： 美国T-mobiles采用Informatica - The Data Integration Company平台开展大数据工作，通过集成数据综合分析客户流失的原因，根据分析结果优化网络布局为客户提供了更好的体验，在一个季度内将流失率减半； 韩国 SK telecom新成立一家公司SK Planet，通过大数据分析用户的使用行为，在用户做出决定之前推出符合用户兴趣的业务防止用户流失。 美国AT&amp;T - 4G LTE, 公司将记录用户在Wifi网络中的地理位置、网络浏览历史记录以及使用的应用等数据销售给广告客户。比如当用户距离商家很近时，就有可能收到该商家提供的折扣很大的电子优惠券。 英国BT - Broadband公司发布了新的安全数据分析服务Assure Analytics—BT news releases，帮助企业收集、管理和评估大数据集，将这些数据通过可视化的方式呈现给企业，帮助企业改进决策。 XO Communications通过使用IBM SPSS预测分析软件，减少了将近一半的客户流失率。XO现在可以预测客户的行为，发现行为趋势，并找出存在缺陷的环节，从而帮助公司及时采取措施，保留客户。 IBM新的Netezza网络分析加速器，将通过提供单个端到端网络、服务、客户分析视图的可扩展平台，帮助通信企业制定更科学、合理决策。 电信业者透过数以千万计的客户资料，能分析出多种使用者行为和趋势，卖给需要的企业，这是全新的资料经济。 中国移动通过大数据分析，对企业运营的全业务进行针对性的监控、预警、跟踪。系统在第一时间自动捕捉市场变化，再以最快捷的方式推送给指定负责人，使他在最短时间内获知市场行情。 NTT docomo把手机位置信息和互联网上的信息结合起来，为顾客提供附近的餐饮店信息，接近末班车时间时，提供末班车信息服务。]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Data-Mining</tag>
        <tag>Big-Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduce to mongo]]></title>
    <url>%2F2016%2F04%2F22%2Fintroduce-to-mongo%2F</url>
    <content type="text"><![CDATA[. IntroductionMongoDB ShellNormal usage find dbs. show dbs use dbs. use &#39;db1&#39; insert documents to db db.COLLECTION_NAME.insert(document) to query data from MongoDB, use MongoDB’s find() method. db.COLLECTION_NAME.find() To display the results in a formated way db.COLLECTION_NAME.find().pretty() The size of the collection. db.COLLECTION_NAME.find().size() Using syntax in find check the link update document into a collection by using update() and save() remove document from the collection by remove() remove all documents: db.COLLECTION_NAME.remove() remove documents based on DELETION_CRITERIA: db.COLLECTION_NAME.remove(DELLETION_CRITTERIA) remove one document based on DELETION_CRITERIA: db.COLLECTION_NAME.remove(DELLETION_CRITTERIA, 1) do projection by find() Advanced usageUnix ShellBackup and Restore MongoBackupEntire backupNormal approach: 123456# output all dbsmongodump --out=/data/dump/# output a specific dbmongodump --db mydb --out=/data/dump/# output a specific collectionmongodump --db mydb --collection mycollection --out=/data/dump/ Using mongodump and bsondump to dump an entire MongoDB as json. 1234# Dump the entire database to BSON files:mongodump --db mydb --out=/data/dump/# Convert each BSON file to JSON file:for f in /data/dump/mydb/*.bson; do bsondump &quot;$f&quot; &gt; &quot;$f.json&quot;; done Partial backup12# output a specific collection with json format.mongoexport -d mydb -c mycollection --pretty --out /data/myfile.json Restore12# Restore the &apos;mydb&apos; database to a new database called &apos;mydb2&apos;mongorestore --db mydb2 dump/mydb]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>mongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Count number of files in a directory]]></title>
    <url>%2F2016%2F04%2F21%2Funix-count-number-of-files-in-a-directory%2F</url>
    <content type="text"><![CDATA[. basic usage12ls -al target_dir | wc -lls -al | grep &quot;xxx&quot; | wc -l advance usageexclude subdirectories1find target_dir -maxdepth 1 -type f | wc -l -type f ensures that the find command only returns regular files for counting (no subdirectories).]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduce to social and information network analysis I]]></title>
    <url>%2F2016%2F04%2F15%2Fintroduce-social-and-information-network-analysis-1%2F</url>
    <content type="text"><![CDATA[From the course materials of Stanford CS224W. Basic notionsCentrality indegree outdegree betweenness how many pairs of individuals would have to go in order to reach another in the minimum number of hops. C_B(i) = \sum \limit_{j &lt; k} g_{jk}(i) / g_{jk}, where g_{jk} = number of shortest paths connecting jk; g_{jk}(i) = the number that actor i is on. Normalized version: C_B^’(i) = C_B(i) / [(n - 1)(n - 2) / 2] closeness. the length of the average shortest path between a node and all other nodes in the network. C_c(i) = [\sum_{j = 1}^N d(j, i)]^{-1} Normalized version: C_C^’(i) = C_C(i) / (N - 1) Normalization: divide degree by the max. possible, i.e., (N - 1) centralization: skew distribution.C_D = \frac{\sum_{i=1}^g [C_D(n) - C_D(i)]}{(N - 1)(N - 2)} Eigenvector centralityC(i) = W_{ji} \cdot C(j) + W_{ki} \cdot C(k) + W_{li} \cdot C(l)]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Social Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Simple way to query connected usb devices info in python]]></title>
    <url>%2F2016%2F04%2F12%2Fpython-query-connected-usb-devices-info%2F</url>
    <content type="text"><![CDATA[. On Linux/OS-X, but no Windows.From stackoverflow.123456789101112131415import reimport subprocessdef list_usb_devices(): device_re = re.compile("Bus\s+(?P&lt;bus&gt;\d+)\s+Device\s+(?P&lt;device&gt;\d+).+ID\s(?P&lt;id&gt;\w+:\w+)\s(?P&lt;tag&gt;.+)$", re.I) df = subprocess.check_output("lsusb", shell=True) devices = [] for i in df.split('\n'): if i: info = device_re.match(i) if info: dinfo = info.groupdict() dinfo['device'] = '/dev/bus/usb/%s/%s' % (dinfo.pop('bus'), dinfo.pop('device')) devices.append(dinfo) return devices Using pySerial12from serial.tools import list_portslist_ports.comports()]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Interview preparation for JAX]]></title>
    <url>%2F2016%2F04%2F11%2Finterview-preparation-for-jax%2F</url>
    <content type="text"><![CDATA[The preparation for the interview of JAX. Take away messageQTL &amp; QTL MappingQTLQTL = quantitative trait locus QTL = a section of DNA (the locus) that correlates with variation[^1] in a phenotype (the quantitative trait) QTL = a gene or chromosomal region that affects a quantitative trait. The QTL typically is linked to, or contains, the genes that control that phenotype. QTLs are mapped by identifying which molecular markers (such as SNPs or AFLPs) correlate with an observed trait. This is often an early step in identifying and sequencing the actual genes that cause the trait variation. Quantitative traits are phenotypes (characteristics) that vary in degree and can be attributed to polygenic[^2] effects, i.e., the product of two or more genes, and their environment. QTL MappingData: Phenotypes: y_i = trait value for mouse i Genotype: x_{ij} = 1/0 (i.e., A/H) of mouse i at marker j; need two dummy variables for inter-cross. genetic map: locations of markers. Goals: Identify the (or at least one) genomic region, calledquantitative trait locus = QTL, that contributes to variation in the trait. Form confidence intervals for the QTL location. Estimate QTL effects. More detailed explains: For organisms, whose genomes are known, one might now try to exclude genes in the identified region whose function is known with some certainty not to be connected with the trait in question. the genome is not available, it may be an option to sequence the identified region and determine the putative functions of genes by their similarity to genes with known function, usually in other genomes. Determine the complexity of the genetic architecture underlying a phenotypic trait, e.g., whether a phenotype is shaped by many independent loci. This can provide information on how the phenotype may be evolving. GWASA genome-wide association study. PheWASPhenome-wide association studies (PheWAS) == reverse GWAS. Phenome-wide association studies (PheWAS) analyze many phenotypes compared to a single genetic variant (or other attribute). PheWAS explore or identify gene-disease associations. Mediation More references Quantitative Trait Locus (QTL) Mapping [^1]: Variation, in biology, any difference between cells, individual organisms, or groups of organisms of any species caused either by genetic differences (genotypic variation) or by the effect of environmental factors on the expression of the genetic potentials (phenotypic variation). [^2]: have allelic variation. An allele (short for allelomorph) is a variant of a gene were the DNA sequence differs between two or more variants. Allelic variation the presence or number of different allele forms at a particular locus (locus or loci = place) on a chromosome allelic variation is sometimes used more loosely to describe the overall diversity present.]]></content>
      <categories>
        <category>Job</category>
      </categories>
      <tags>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash, input variable from terminal]]></title>
    <url>%2F2016%2F04%2F11%2Funix-bash-input-variable-from-terminal%2F</url>
    <content type="text"><![CDATA[Input variables from terminal 12345678910111213141516for i in &quot;$@&quot;docase $i in -u=*|--ui=*) FILE_UI=&quot;$&#123;i#*=&#125;&quot; ;; -m=*|--main=*) FILE_MAIN=&quot;$&#123;i#*=&#125;&quot; ;; *) ;;esacdon]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to compress and extract the file/folder in linux]]></title>
    <url>%2F2016%2F04%2F08%2Funix-how-to-compress-and-extract-file-or-folder-in-linux%2F</url>
    <content type="text"><![CDATA[. zipCompress a directory1zip -r archive_name.zip directory_to_compress Extract1unzip archive_name.zip tar.gzCompress1tar -zcvf archive-name.tar.gz directory-name where: -z: Compress archive using gzip program -c: Create archive -v: Verbose i.e display progress while creating archive -f: Archive File name Extract1tar -zxvf archive-name.tar.gz where: -x: Extract files Or more accurate case: 1234# if target_dir existtar xv -C target_dir -f source_dir/archive.tar.gz# if target_dir not existmkdir -p target_dir; tar xv -C target_dir -f source_dir/archive.tar.gz with -p option mkdir doesn’t complain in case the directory already exists. tarTar is probably the Linux/UNIX version of zip – quick and dirty. Compress1tar -cvf archive_name.tar directory_to_compress Extract1tar -xvf archive_name.tar.gz]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduce the basic parallel computing in R]]></title>
    <url>%2F2016%2F04%2F07%2Fintroduce-basic-parallel-computing-in-R%2F</url>
    <content type="text"><![CDATA[Based on the on-line tutorials and documents, make a note relate to parallel computing in R. parallel packageBasic usage: parLapply1234567891011121314library(parallel)# Calculate the number of coresno_cores &lt;- detectCores() - 1# Initiate clustercl &lt;- makeCluster(no_cores)# call the parallel version of lapply, parLapplyparLapply(cl, 2:4, function(exponent)&#123;2^exponent&#125;)# Once we are done we need to close the cluster,# so that resources such as memory are returned to the operating system.stopCluster(cl) variable scopeOn Mac/Linux you have the option of using makeCluster(no_core, type=&quot;FORK&quot;) that automatically contains all environment variables. Basic usage: parSapplySometimes we only want to return a simple value and directly get it processed as a vector/matrix. Then, we can use it as sapply. Load balancingA slightly different model is to split the task into M1 &gt; M chunks, send the first M chunks to the workers, then repeatedly wait for any worker to complete and send it the next remaining task. foreach package and doParallel packageThe idea behind the foreach package is to create ‘a hybrid of the standard for loop and lapply function’ and its ease of use has made it rather popular. Basic introductionThe doParallel package is a “parallel backend” for the foreach package, otherwise it will throw a warning as follow: 12Warning message:executing %dopar% sequentially: no parallel backend registered. The following code block show some basic examples. 1234567891011121314151617181920212223242526272829303132333435363738s1 &lt;- function(iter)&#123; t &lt;- list() for(i in 1: iter)&#123; t[i] &lt;- sqrt(i) &#125; return(t)&#125;# user system elapsed# 36.740 0.000 36.543system.time(s1(100000))s2 &lt;- function(iter)&#123; return(lapply(1: iter, function(x)&#123;sqrt(x)&#125;))&#125;# user system elapsed# 0.000 0.000 0.113system.time(s2(100000))s3 &lt;- function(iter)&#123; t &lt;- foreach(i = 1: iter) %do% sqrt(i) return(t)&#125;# user system elapsed# 37.928 0.000 37.762system.time(s3(100000))library(foreach)library(doParallel)cl &lt;- makeCluster(10)registerDoParallel(cl)p1 &lt;- function(iter)&#123; t &lt;- foreach(i = 1: iter) %dopar% sqrt(i) return(t)&#125;# user system elapsed# 55.992 2.852 59.918system.time(p1(100000)) And we can notice that this is not a practical use of doParallel, and don’t expect it to run faster than a sequential for loop. With small tasks, the overhead of scheduling the task and returning the resultcan be greater than the time to execute the task itself, resulting in poor performance. But we can witness that it is very simple to load doParallel with all of its dependencies (foreach, iterators, parallel, etc), and to register it. After using the cluster, we should close it by stopImplicitCluster(). Some advanced usageMore information about the parallel backend.To find out how many workers foreach is going to use: getDoParWorkers() To get the name and version of the currently registered backend: getDoParName() variable scopeVariable within the same local environment are by default available, while variables from a parent environment will not be available. We can use .export option. An example is as follow: 12345678910111213base &lt;- 2cl&lt;-makeCluster(2)registerDoParallel(cl)base &lt;- 4test &lt;- function (exponent) &#123; foreach(exponent = 2:4, .combine = c, .export = "base") %dopar% base^exponent&#125;test()stopCluster(cl)]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pyqt for beginner]]></title>
    <url>%2F2016%2F03%2F21%2Fpyqt-for-beginner%2F</url>
    <content type="text"><![CDATA[A tutorial of how to begin the programming of PyQt (for Ubuntu). Knowledge comes from the following blog/links. PyQt: Getting started with PyQt and Qt Designer Beginning Install sudo apt-get install python-qt4 pyqt4-dev-tools qt4-designer Good Demo play with threading PyQt: Threading Basics Tutorial]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mass rename/copy/link tool]]></title>
    <url>%2F2016%2F03%2F09%2Funix-mass-rename-tools%2F</url>
    <content type="text"><![CDATA[. mmvExample: mmv \*.JPG \#1.jpg The first pattern matches anything with a “.JPG” and renames each file (the “#1” matches the first wildcard) to “.jpg”. Each time you use a (wildcard) you can use a #x to get that wildcard. Where x is a positive number starting at 1. renamerename is a perl script which can be used to mass rename files according to a regular expression. An example for renaming all .JPG files to .jpg is: rename &#39;s/\.JPG$/.jpg/&#39; *.JPG Bash scriptingExample 1123for i in *.JPG;do mv $i `basename $i JPG`jpg;done The first line says find everything with the “.JPG” extension (capitals only, because the UNIX system is case sensitive). The second line uses basename (type man basename for more details) with the ‘$i’ argument. The ‘$i’ is a string containing the name of the file that matches. The next portion of the line removes the JPG extension from the end and adds the jpg extention to each file. The command mv is run on the output. Example 2123for i in *.JPG;do mv $i $&#123;i%%.JPG&#125;.jpg;done]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to mirror local and remote directories]]></title>
    <url>%2F2016%2F03%2F04%2Funix-how-to-mirror-local-and-remote-directories%2F</url>
    <content type="text"><![CDATA[Based on the blog Install lsyncd12sudo apt-get updatesudo apt-get install lsyncd Setup environmentwe can create a log directory and some files for lsyncd to use: 12sudo mkdir /var/log/lsyncdtouch /var/log/lsyncd/lsyncd.&#123;log,status&#125; Then, we can create the lsyncd configuration directory by sudo mkdir /etc/lsyncd and create a configuration file inside of this directory called “lsyncd.conf.lua”, with vi: 1sudo vi /etc/lsyncd/lsyncd.conf.lua How to Sync Two Local Folders with lsyncdEdit the lsyncd.conf.lua file as follows: 12345678910111213141516settings = &#123; logfile=&quot;/var/log/lsyncd/lsyncd.log&quot;, statusFile=&quot;/var/log/lsyncd/lsyncd.status&quot;&#125;sync &#123; default.rsync, source=&quot;/home/tlin/Data/Knowledge/&quot;, target=&quot;/home/tlin/Data/Dropbox/Backup/Knowledge&quot;, delete=&quot;true&quot;, rsync=&#123; archive=true, -- use the archive flag in rsync perms=true, -- Keep the permissions owner=true -- Keep the owner &#125;&#125; Then, we can use the following command to start the lsynacd 12service lsyncd startlsyncd -rsync ~/Data/Knowledge ~/Data/Dropbox/Backup/Knowledge]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Operations]]></title>
    <url>%2F2016%2F02%2F24%2Fgit-operations%2F</url>
    <content type="text"><![CDATA[. Basic UsageStashing To push a new stash onto your stack: git stash To see which stashes you’ve stored: git stash list To apply one of the older stashes: git stash apply stash@{0} To git stash drop with the name of the stash to remove: git stash drop stash@{0}]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atom Usage Tutorial]]></title>
    <url>%2F2016%2F02%2F24%2Fatom-usage-tutorial%2F</url>
    <content type="text"><![CDATA[See a more detailed Tutorial IntroductionInstall on Ubuntu Download atom-amd64.deb from the Atom releases page. Run sudo dpkg --install atom-amd64.deb on the downloaded package. Launch Atom using the installed atom command. Install Atom Package Open a Settings by Ctrl and ,, and simply click “packages” on the left. How to remember Shortcut Open by Ctrl, Shift and P, and type the function/command that you want. Open file from terminalBy atom &lt;file&gt; we can open a specific file; or atom &lt;folder1&gt; &lt;folder2&gt;, we can open them at the same time. Moving in atom Ctrl + g: enter a row: column to go to Ctrl + r: jump to a symbol such as a method definition Ctrl + t: search by symbol across your project Editing and Deleting Text cmd-shift-D: Duplicate the current line ctrl-shift-K: Delete current line Ctrl-L: select line Finding and Replace Ctrl-F: search within a buffer Ctrl-Shift-F: search the entire Advance UsagePackagesLatexscriptatom-terminalmarkdown-related package: markdown-preview-plus package: markdown-preview-plus-opener Or we can use the shortcut Ctrl, Shift and m to active/inactive a live markdown window.]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Atom</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Configure My Thinkpad T450s]]></title>
    <url>%2F2016%2F02%2F24%2Fconfigure-my-thinkpad-t450s%2F</url>
    <content type="text"><![CDATA[. HardwareHow to replace 16 GB NGFF SSD by 128 GB NGFF SSDSoftwareStartersUpdate Systemsudo apt-get update &amp;&amp; sudo apt-get upgrade mount disk and change the permissionmount the two disk, i.e., Data and Cloud to the home/tlin/, and change their permission by sudo chown -Rv tlin /home/tlin/Cloud or sudo chown -Rv tlin /home/tlin/Data Install gitsudo apt-get install build-essential libssl-dev libcurl4-gnutls-dev libexpat1-dev gettext unzip setup git12git config --global user.name &quot;Tao Lin&quot;git config --global user.email &quot;lintaog3@gmail.com&quot; avoid to enter the password every time.Disable Unity Dash online search featureSystem setting -&gt; Security &amp; Privacy -&gt; Search -&gt; turn it off Enable WorkspacesSystem setting -&gt; Appearance -&gt; Enable workspaces Install proper graphics driversSystem setting -&gt; Software &amp; Updates -&gt; Additional Drivers Install Ubuntu Tweak Toolsudo apt-get install unity-tweak-tool gnome-tweak-tool Get themesAdd the necessary ppa:sudo sh -c &quot;echo &#39;deb http://download.opensuse.org/repositories/home:/Horst3180/xUbuntu_15.10/ /&#39; &gt;&gt; /etc/apt/sources.list.d/arc-theme.list&quot; Download the repository key with the command:wget http://download.opensuse.org/repositories/home:Horst3180/xUbuntu_15.10/Release.key Add the key with the command:sudo apt-key add - &lt; Release.key Update apt with the command: sudo apt-get update Install the theme with the command:sudo apt-get install arc-theme Install VLC Media Playersudo apt-get install vlc Install additional media codecssudo apt-get -y install gstreamer0.10-plugins-ugly gxine libdvdread4 icedax tagtool easytag id3tool lame nautilus-script-audio-convert libmad0 mpg321 gstreamer1.0-libav Install SkypeFirst go to System setting -&gt; Software &amp; Updates -&gt; Other Software -&gt; check first box. sudo apt-get install skype Install Dropbox12wget -O dropbox.deb https://www.dropbox.com/download?dl=packages/ubuntu/dropbox_2015.10.28_amd64.debsudo dpkg -i dropbox.deb Install Archive management appssudo apt-get install unace unrar zip unzip p7zip-full p7zip-rar sharutils rar uudeview mpack arj cabextract file-roller Install Javasudo apt-get install openjdk-8-jdk Install VirtualBoxInstalled by official link and ubuntu software center. TLP12345sudo add-apt-repository ppa:linrunner/tlpsudo apt-get updatesudo apt-get install tlp tlp-rdw smartmontools ethtoolsudo apt-get install tlp tlp-rdw smartmontools ethtool tp-smapi-dkms acpi-call-dkmssudo tlp start Enhance wifi12345sudo apt-get install git build-essentialgit clone https://github.com/lwfinger/rtlwifi_new.gitcd rtlwifi-newmakesudo make install Install docker1234sudo apt-get install &amp;&amp; sudo apt-get upgradesudo apt-get install docker.iosudo service docker startsudo systemctl enable docker Install zsh and oh-my-zsh123sudo apt-get install zshchsh -s $(which zsh)sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; Install tree, autojump12sudo apt-get install treesudo apt-get install autojump install vimsudo apt-get install vim install spf13-vimcurl http://j.mp/spf13-vim3 -L -o - | sh Install hexo1234curl https://raw.github.com/creationix/nvm/master/install.sh | shnvm install 4npm install -g hexo-clinpm install hexo-deployer-git --save Install Tex12sudo apt-get install texlive-fullsudo apt-get install texmaker Install Atom123Install from the official linkInstall markdown-review-plusinstall markdown-review-plus-opener Install Sublime-text123sudo add-apt-repository ppa:webupd8team/sublime-text-2sudo apt-get updatesudo apt-get install sublime-text]]></content>
      <categories>
        <category>Wiki</category>
      </categories>
      <tags>
        <tag>Unix</tag>
        <tag>Configure-Tool</tag>
      </tags>
  </entry>
</search>
