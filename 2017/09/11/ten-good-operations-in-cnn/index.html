<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Deep Learning,Machine Learning," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="From Zhihu and for study purpose.">
<meta name="keywords" content="Deep Learning,Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Ten Good Operations in CNN">
<meta property="og:url" content="IamTao.github.io/2017/09/11/ten-good-operations-in-cnn/index.html">
<meta property="og:site_name" content="庭草交翠">
<meta property="og:description" content="From Zhihu and for study purpose.">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://pic4.zhimg.com/v2-8391579398bc70428125ff4d2baf8047_b.png">
<meta property="og:image" content="https://pic1.zhimg.com/v2-310612100a51bf849adfa2c46af359fc_b.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/v2-321c3c927ebb79a58ab838415e90a04c_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-492191ce6b3c5bbe9c7621af70b8e83d_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-45d489b52bff50139774e80dce3e2d72_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-6fc1664743c9b73501d059a9010bc6e2_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-ff1b1fe7571a5284e16cf51d97d69142_b.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-4f916a0b75eb237872c428bae001e4ef_b.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/v2-bfda3275067cacc7c22ea4f076d1ce7c_b.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-2abdcd955c91c5131858a13d843f6343_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-b448e1e8b5bbf7ace5f14c6c4d44c44e_b.png">
<meta property="og:image" content="https://pic3.zhimg.com/v2-d749ecec40399b1df794ac8d4354b962_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-04f7acacb6544f70e369ebb659b1453e_b.jpg">
<meta property="og:updated_time" content="2018-09-01T13:04:23.020Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ten Good Operations in CNN">
<meta name="twitter:description" content="From Zhihu and for study purpose.">
<meta name="twitter:image" content="https://pic4.zhimg.com/v2-8391579398bc70428125ff4d2baf8047_b.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="IamTao.github.io/2017/09/11/ten-good-operations-in-cnn/"/>





  <title>Ten Good Operations in CNN | 庭草交翠</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">庭草交翠</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="IamTao.github.io/2017/09/11/ten-good-operations-in-cnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="虫二">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="庭草交翠">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Ten Good Operations in CNN</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-11T10:39:54+02:00">
                2017-09-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Data-Science/" itemprop="url" rel="index">
                    <span itemprop="name">Data Science</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>From <a href="https://zhuanlan.zhihu.com/p/28749411?from=singlemessage" target="_blank" rel="noopener">Zhihu</a> and for study purpose.</p>
<a id="more"></a>
<h1 id="卷积只能在同一组进行吗？-–-Group-Convolution"><a href="#卷积只能在同一组进行吗？-–-Group-Convolution" class="headerlink" title="卷积只能在同一组进行吗？ – Group Convolution"></a>卷积只能在同一组进行吗？ – Group Convolution</h1><p>Group convolution 分组卷积，最早在AlexNet中出现，由于当时的硬件资源有限，训练AlexNet时卷积操作不能全部放在同一个GPU处理，因此作者把feature maps分给多个GPU分别进行处理，最后把多个GPU的结果进行融合。<br><img src="https://pic4.zhimg.com/v2-8391579398bc70428125ff4d2baf8047_b.png" alt=""></p>
<p>分组卷积的思想影响比较深远，当前一些轻量级的SOTA（State Of The Art）网络，都用到了分组卷积的操作，以节省计算量。</p>
<blockquote>
<p>group conv本身应该就大大减少了参数，比如当input channel为<code>256</code>，output channel也为<code>256</code>，kernel size为<code>3*3</code>，不做group conv参数为 <code>256*3*3*256</code>，若group为<code>8</code>，每个group的input channel和output channel均为<code>32</code>，参数为<code>8*32*3*3*32</code>，是原来的八分之一。</p>
</blockquote>
<p>分组卷积最后每一组输出的feature maps应该是以concatenate的方式组合，而不是element-wise add，所以每组输出的channel是 <code>input channels / # groups</code>，这样参数量就大大减少了。</p>
<h1 id="卷积核一定越大越好？-–-3×3卷积核"><a href="#卷积核一定越大越好？-–-3×3卷积核" class="headerlink" title="卷积核一定越大越好？ – 3×3卷积核"></a>卷积核一定越大越好？ – 3×3卷积核</h1><p>AlexNet中用到了一些非常大的卷积核，比如11×11、5×5卷积核，之前人们的观念是，卷积核越大，receptive field（感受野）越大，看到的图片信息越多，因此获得的特征越好。虽说如此，但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低。于是在VGG（最早使用）、Inception网络中，利用2个3x3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1 VS 5×5×1+1）被降低，因此后来3x3卷积核被广泛应用在各种模型中。<br><img src="https://pic1.zhimg.com/v2-310612100a51bf849adfa2c46af359fc_b.jpg" alt=""></p>
<h1 id="每层卷积只能用一种尺寸的卷积核？-–-Inception结构"><a href="#每层卷积只能用一种尺寸的卷积核？-–-Inception结构" class="headerlink" title="每层卷积只能用一种尺寸的卷积核？ – Inception结构"></a>每层卷积只能用一种尺寸的卷积核？ – Inception结构</h1><p>传统的层叠式网络，基本上都是一个个卷积层的堆叠，每层只用一个尺寸的卷积核，例如VGG结构中使用了大量的3×3卷积层。事实上，同一层feature map可以分别使用多个不同尺寸的卷积核，以获得不同尺度的特征，再把这些特征结合起来，得到的特征往往比使用单一卷积核的要好，谷歌的GoogleNet，或者说Inception系列的网络，就使用了多个卷积核的结构:<img src="https://pic1.zhimg.com/v2-321c3c927ebb79a58ab838415e90a04c_b.jpg" alt=""></p>
<p>如上图所示，一个输入的feature map分别同时经过1×1、3×3、5×5的卷积核的处理，得出的特征再组合起来，获得更佳的特征。但这个结构会存在一个严重的问题：参数量比单个卷积核要多很多，如此庞大的计算量会使得模型效率低下。这就引出了一个新的结构:</p>
<h1 id="怎样才能减少卷积层参数量？-–-Bottleneck"><a href="#怎样才能减少卷积层参数量？-–-Bottleneck" class="headerlink" title="怎样才能减少卷积层参数量？ – Bottleneck"></a>怎样才能减少卷积层参数量？ – Bottleneck</h1><p>发明GoogleNet的团队发现，如果仅仅引入多个尺寸的卷积核，会带来大量的额外的参数，受到Network In Network中1×1卷积核的启发，为了解决这个问题，他们往Inception结构中加入了一些1×1的卷积核，如图所示：<br><img src="https://pic2.zhimg.com/v2-492191ce6b3c5bbe9c7621af70b8e83d_b.jpg" alt=""></p>
<p>加入1×1卷积核的Inception结构:<br><img src="https://pic3.zhimg.com/v2-45d489b52bff50139774e80dce3e2d72_b.jpg" alt=""></p>
<p>根据上图，我们来做个对比计算，假设输入feature map的维度为<code>256</code>维，要求输出维度也是<code>256</code>维。有以下两种操作：</p>
<ol>
<li><code>256</code>维的输入直接经过一个<code>3×3×256</code>的卷积层，输出一个<code>256</code>维的feature map，那么参数量为：<code>256×3×3×256 = 589,824</code>.</li>
<li><code>256</code>维的输入先经过一个<code>1×1×64</code>的卷积层，再经过一个<code>3×3×64</code>的卷积层，最后经过一个<code>1×1×256</code>的卷积层，输出256维，参数量为：<code>256×1×1×64 + 64×3×3×64 + 64×1×1×256 = 69,632</code>。足足把第一种操作的参数量降低到九分之一！</li>
</ol>
<p><code>1×1</code>卷积核也被认为是影响深远的操作，往后大型的网络为了降低参数量都会应用上<code>1×1</code>卷积核。</p>
<h1 id="越深的网络就越难训练吗？-–-Resnet残差网络"><a href="#越深的网络就越难训练吗？-–-Resnet残差网络" class="headerlink" title="越深的网络就越难训练吗？ – Resnet残差网络"></a>越深的网络就越难训练吗？ – Resnet残差网络</h1><p><img src="https://pic3.zhimg.com/v2-6fc1664743c9b73501d059a9010bc6e2_b.jpg" alt=""></p>
<p>传统的卷积层层叠网络会遇到一个问题，当层数加深时，网络的表现越来越差，很大程度上的原因是因为当层数加深时，梯度消散得越来越严重，以至于反向传播很难训练到浅层的网络。为了解决这个问题，何凯明大神想出了一个“残差网络”，使得梯度更容易地流动到浅层的网络当中去，而且这种“skip connection”能带来更多的好处，具体参见</p>
<ul>
<li><a href="http://blog.csdn.net/buyi_shizi/article/details/53336192" target="_blank" rel="noopener">ResNet要解决的问题</a></li>
<li><a href="http://blog.csdn.net/malefactor/article/details/67637785" target="_blank" rel="noopener">极深网络（ResNet/DenseNet）: Skip Connection为何有效及其它</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28124810?group_id=883267168542789632" target="_blank" rel="noopener">为什么ResNet和DenseNet可以这么深？一文详解残差块为何有助于解决梯度弥散问题</a></li>
</ul>
<h1 id="卷积操作时必须同时考虑通道和区域吗？-–-DepthWise操作"><a href="#卷积操作时必须同时考虑通道和区域吗？-–-DepthWise操作" class="headerlink" title="卷积操作时必须同时考虑通道和区域吗？ – DepthWise操作"></a>卷积操作时必须同时考虑通道和区域吗？ – DepthWise操作</h1><p><img src="https://pic3.zhimg.com/v2-ff1b1fe7571a5284e16cf51d97d69142_b.jpg" alt=""><br>标准的卷积过程可以看上图，一个2×2的卷积核在卷积时，对应图像区域中的所有通道均被同时考虑，问题在于，为什么一定要同时考虑图像区域和通道？我们为什么不能把通道和空间区域分开考虑？</p>
<p><img src="https://pic4.zhimg.com/v2-4f916a0b75eb237872c428bae001e4ef_b.jpg" alt=""><br>Xception网络就是基于以上的问题发明而来。我们首先对每一个通道进行各自的卷积操作，有多少个通道就有多少个过滤器。得到新的通道feature maps之后，这时再对这批新的通道feature maps进行标准的1×1跨通道卷积操作。这种操作被称为”<strong>DepthWise convolution</strong>“，缩写”DW”。</p>
<p>这种操作是相当有效的，在imagenet 1000类分类任务中已经超过了InceptionV3的表现，而且也同时减少了大量的参数，我们来算一算，假设输入通道数为<code>3</code>，要求输出通道数为<code>256</code>，两种做法：</p>
<ol>
<li>直接接一个<code>3×3×256</code>的卷积核，参数量为：<code>3×3×3×256=6,912</code></li>
<li>DW操作，分两步完成，参数量为：<code>3×3×3+3×1×1×256=795</code>，又把参数量降低到九分之一！</li>
</ol>
<p>因此，一个depthwise操作比标准的卷积操作降低不少的参数量，同时论文中指出这个模型得到了更好的分类效果。</p>
<p><a href="https://arxiv.org/pdf/1608.04337v1.pdf" target="_blank" rel="noopener">Factorized Convolutional Neural Networks</a>是Depthwise和Pointwise的历史工作，而Xception和Mobilenet也引用了这个工作。这篇论文的Depthwise中，每一通道输出的feature map（称为“基层”）可以不止一个，而Xception中的Depthwise separable Convolution正是这篇工作中“单一基层”的情况。可以参见<a href="http://link.zhihu.com/?target=http%3A//blog.csdn.net/shenxiaolu1984/article/details/52266391" target="_blank" rel="noopener">博文介绍</a>.</p>
<h1 id="分组卷积能否对通道进行随机分组？-–-ShuffleNet"><a href="#分组卷积能否对通道进行随机分组？-–-ShuffleNet" class="headerlink" title="分组卷积能否对通道进行随机分组？ – ShuffleNet"></a>分组卷积能否对通道进行随机分组？ – ShuffleNet</h1><p>在AlexNet的Group Convolution当中，特征的通道被平均分到不同组里面，最后再通过两个全连接层来融合特征，这样一来，就只能在最后时刻才融合不同组之间的特征，对模型的泛化性是相当不利的。为了解决这个问题，ShuffleNet在每一次层叠这种Group conv层前，都进行一次channel shuffle，shuffle过的通道被分配到不同组当中。进行完一次group conv之后，再一次channel shuffle，然后分到下一层组卷积当中，以此循环。<br><img src="https://pic1.zhimg.com/v2-bfda3275067cacc7c22ea4f076d1ce7c_b.jpg" alt=""></p>
<p>经过channel shuffle之后，Group conv输出的特征能考虑到更多通道，输出的特征自然代表性就更高。另外，AlexNet的分组卷积，实际上是标准卷积操作，而在ShuffleNet里面的分组卷积操作是depthwise卷积，因此结合了通道洗牌和分组depthwise卷积的ShuffleNet，能得到超少量的参数以及超越mobilenet、媲美AlexNet的准确率！</p>
<p>另外值得一提的是，微软亚洲研究院MSRA最近也有类似的工作，他们提出了一个IGC单元（Interleaved Group Convolution），即通用卷积神经网络交错组卷积，形式上类似进行了两次组卷积，Xception 模块可以看作交错组卷积的一个特例，特别推荐看看这篇文章：<a href="https://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649441412&amp;idx=1&amp;sn=76b8e24616a4cdc07fbf985798ef4942&amp;chksm=82c0ad00b5b724163561a9174f8213d365ca87f5d73c7ec278ac358293b55e7dcb9e488b1eb8&amp;mpshare=1&amp;scene=1&amp;srcid=0731zmN8ulFwvXY4HRh8vpKs#rd" target="_blank" rel="noopener">王井东详解ICCV 2017入选论文：通用卷积神经网络交错组卷积</a>.</p>
<p>要注意的是，Group conv是一种channel分组的方式，Depthwise + Pointwise是卷积的方式，只是ShuffleNet里面把两者应用起来了。因此Group conv和Depthwise +Pointwise并不能划等号。</p>
<h1 id="通道间的特征都是平等的吗？-–-SEnet"><a href="#通道间的特征都是平等的吗？-–-SEnet" class="headerlink" title="通道间的特征都是平等的吗？ – SEnet"></a>通道间的特征都是平等的吗？ – SEnet</h1><p>无论是在Inception、DenseNet或者ShuffleNet里面，我们对所有通道产生的特征都是不分权重直接结合的，那为什么要认为所有通道的特征对模型的作用就是相等的呢？ 这是一个好问题，于是，ImageNet2017 冠军SEnet就出来了。<br><img src="https://pic4.zhimg.com/v2-2abdcd955c91c5131858a13d843f6343_b.jpg" alt=""></p>
<p>一组特征在上一层被输出，这时候分两条路线，第一条直接通过，第二条首先进行Squeeze操作（Global Average Pooling），把每个通道2维的特征压缩成一个1维，从而得到一个特征通道向量（每个数字代表对应通道的特征）。然后进行Excitation操作，把这一列特征通道向量输入两个全连接层和sigmoid，建模出特征通道间的相关性，得到的输出其实就是每个通道对应的权重，把这些权重通过Scale乘法通道加权到原来的特征上（第一条路），这样就完成了特征通道的权重分配。作者详细解释可以看这篇文章：<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650729486&amp;idx=3&amp;sn=5b2b6f0e7443ecf0971d4743d5480bb6&amp;chksm=871b2870b06ca166bc18413060898886db534c2b5ade468f832d3f85d5d75549f15293cea6cd&amp;mpshare=1&amp;scene=1&amp;srcid=0822wk5DEWG7YU89UZr1yEup#rd" target="_blank" rel="noopener">专栏 | Momenta详解ImageNet 2017夺冠架构SENet</a></p>
<h1 id="能否让固定大小的卷积核看到更大范围的区域？-–-Dilated-convolution"><a href="#能否让固定大小的卷积核看到更大范围的区域？-–-Dilated-convolution" class="headerlink" title="能否让固定大小的卷积核看到更大范围的区域？ – Dilated convolution"></a>能否让固定大小的卷积核看到更大范围的区域？ – Dilated convolution</h1><p>标准的3×3卷积核只能看到对应区域3×3的大小，但是为了能让卷积核看到更大的范围，dilated conv使其成为了可能。dilated conv原论文中的结构如图所示：<br><img src="https://pic3.zhimg.com/v2-b448e1e8b5bbf7ace5f14c6c4d44c44e_b.png" alt=""></p>
<p>上图b可以理解为卷积核大小依然是3×3，但是每个卷积点之间有1个空洞，也就是在绿色7×7区域里面，只有9个红色点位置作了卷积处理，其余点权重为0。这样即使卷积核大小不变，但它看到的区域变得更大了。详细解释可以看这个回答：<a href="https://www.zhihu.com/question/54149221" target="_blank" rel="noopener">如何理解空洞卷积（dilated convolution）</a>？</p>
<h1 id="卷积核形状一定是矩形吗？-–-Deformable-convolution-可变形卷积核"><a href="#卷积核形状一定是矩形吗？-–-Deformable-convolution-可变形卷积核" class="headerlink" title="卷积核形状一定是矩形吗？ – Deformable convolution 可变形卷积核"></a>卷积核形状一定是矩形吗？ – Deformable convolution 可变形卷积核</h1><p><img src="https://pic3.zhimg.com/v2-d749ecec40399b1df794ac8d4354b962_b.jpg" alt=""><br>传统的卷积核一般都是长方形或正方形，但MSRA提出了一个相当反直觉的见解，认为卷积核的形状可以是变化的，变形的卷积核能让它只看感兴趣的图像区域 ，这样识别出来的特征更佳。<br><img src="https://pic3.zhimg.com/v2-04f7acacb6544f70e369ebb659b1453e_b.jpg" alt=""></p>
<p>图来自微软亚洲研究院公众号要做到这个操作，可以直接在原来的过滤器前面再加一层过滤器，这层过滤器学习的是下一层卷积核的位置偏移量（offset），这样只是增加了一层过滤器，或者直接把原网络中的某一层过滤器当成学习offset的过滤器，这样实际增加的计算量是相当少的，但能实现可变形卷积核，识别特征的效果更好。详细MSRA的解读可以看这个链接：<a href="https://www.weibo.com/ttarticle/p/show?id=2309404116774126794221" target="_blank" rel="noopener">可变形卷积网络：计算机新“视”界</a>。</p>
<h1 id="启发与思考"><a href="#启发与思考" class="headerlink" title="启发与思考"></a>启发与思考</h1><p>现在越来越多的CNN模型从巨型网络到轻量化网络一步步演变，模型准确率也越来越高。现在工业界追求的重点已经不是准确率的提升（因为都已经很高了），都聚焦于速度与准确率的trade off，都希望模型又快又准。因此从原来AlexNet、VGGnet，到体积小一点的Inception、Resnet系列，到目前能移植到移动端的mobilenet、ShuffleNet（体积能降低到0.5mb！），我们可以看到这样一些趋势：</p>
<ul>
<li><strong>卷积核</strong>方面：<ol>
<li>大卷积核用多个小卷积核代替；</li>
<li>单一尺寸卷积核用多尺寸卷积核代替；</li>
<li>固定形状卷积核趋于使用可变形卷积核；</li>
<li>使用1×1卷积核（bottleneck结构）。</li>
</ol>
</li>
<li><strong>卷积层通道</strong>方面：<ol>
<li>标准卷积用depthwise卷积代替；</li>
<li>使用分组卷积；</li>
<li>分组卷积前使用channel shuffle；</li>
<li>通道加权计算。</li>
</ol>
</li>
<li><strong>卷积层连接</strong>方面：<ol>
<li>使用skip connection，让模型更深；</li>
<li>densely connection，使每一层都融合上其它层的特征输出（DenseNet）</li>
</ol>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/09/11/intuitional-explanation-for-cnn/" rel="next" title="Intuitional Explanation for CNN">
                <i class="fa fa-chevron-left"></i> Intuitional Explanation for CNN
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/10/12/how-to-add-a-gif-file-to-my-latex-file/" rel="prev" title="How to add a gif file to my latex file">
                How to add a gif file to my latex file <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.png"
               alt="虫二" />
          <p class="site-author-name" itemprop="name">虫二</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">80</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://github.com/iamtao" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/iamtaol" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                    
                      Weibo
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积只能在同一组进行吗？-–-Group-Convolution"><span class="nav-number">1.</span> <span class="nav-text">卷积只能在同一组进行吗？ – Group Convolution</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积核一定越大越好？-–-3×3卷积核"><span class="nav-number">2.</span> <span class="nav-text">卷积核一定越大越好？ – 3×3卷积核</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#每层卷积只能用一种尺寸的卷积核？-–-Inception结构"><span class="nav-number">3.</span> <span class="nav-text">每层卷积只能用一种尺寸的卷积核？ – Inception结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#怎样才能减少卷积层参数量？-–-Bottleneck"><span class="nav-number">4.</span> <span class="nav-text">怎样才能减少卷积层参数量？ – Bottleneck</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#越深的网络就越难训练吗？-–-Resnet残差网络"><span class="nav-number">5.</span> <span class="nav-text">越深的网络就越难训练吗？ – Resnet残差网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积操作时必须同时考虑通道和区域吗？-–-DepthWise操作"><span class="nav-number">6.</span> <span class="nav-text">卷积操作时必须同时考虑通道和区域吗？ – DepthWise操作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分组卷积能否对通道进行随机分组？-–-ShuffleNet"><span class="nav-number">7.</span> <span class="nav-text">分组卷积能否对通道进行随机分组？ – ShuffleNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#通道间的特征都是平等的吗？-–-SEnet"><span class="nav-number">8.</span> <span class="nav-text">通道间的特征都是平等的吗？ – SEnet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#能否让固定大小的卷积核看到更大范围的区域？-–-Dilated-convolution"><span class="nav-number">9.</span> <span class="nav-text">能否让固定大小的卷积核看到更大范围的区域？ – Dilated convolution</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积核形状一定是矩形吗？-–-Deformable-convolution-可变形卷积核"><span class="nav-number">10.</span> <span class="nav-text">卷积核形状一定是矩形吗？ – Deformable convolution 可变形卷积核</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#启发与思考"><span class="nav-number">11.</span> <span class="nav-text">启发与思考</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">虫二</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
